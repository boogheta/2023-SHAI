[PAGE]
nom_de_page="Accueil"
url="/"
contenu="""

<img src="https://i.vimeocdn.com/portrait/71432192_640x640" style="width:20%">

<br>
<br>
<br>

# PRISES ,  MÉ.PRISES, EM.PRISES  ,  DÉ.PRISES  ,  RE.PRISES…
# Les formes de participation au développement de l'IA en France


---

![Dessin d'un neurone de Purkinje du cortex cérébelleux du chat par Santiago Ramón y Cajal (fin du 19e siècle). Source : Wikipedia](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-18-a-21-43-05-copy.png) 

**Fin 2020.**
Le cycle médiatique s'emballe sur l’intelligence artificielle, ses promesses et ses problèmes, usant et abusant d’une rhétorique sensationaliste. Des innovations médicales révolutionnaires aux prophéties de la fin de l’humanité, des engagements éthiques des GAFAM aux mauvais calculs de Parcousup, il est difficile de savoir quoi penser de ce phénomène, si ce n’est qu’il semble sur le point d’investir de manière indifférenciée tous les champs de la vie en tout point du globe. 

**Difficile donc de naviguer sur cette mer de discours.**

Dans le cas de l’intelligence artificielle, comme cela arrive de plus en plus à mesure que les systèmes se complexifient et se globalisent, une difficulté majeure tient à la résistance du phénomène à se laisser saisir. On ne sait littéralement pas par où l’attraper : les tentatives paraissent soit insignifiantes, soit totalisantes, soit trop techniques, soit trop sociales, trop résignées ou trop enthousiastes, trop ci, pas assez ça... Il faut donc s’y résoudre, il n’y a pas d’entendement commun au sujet de l’IA, mais une cacophonie dont les sons qui nous parviennent laissent insatisfaits, sinon frustrés. Le seul entendement commun qui tienne est peut-être l’aveu que “quelque chose cloche” et qu’il serait bon de s’en soucier. De consultations en chartes éthiques, cet aveu persiste et signe.

La sociologie des controverses nous a outillés pour décrire les problèmes liés aux innovations technologiques, étudier leur formation et leur circulation, cartographier les acteurs concernés, leurs intérêts et leurs attachements, leurs stratégies d’alliances et d’action. Elle nous a habitués aux objets à la définition fuyante et conflictuelle et aux problèmes mal formulés. Mais le volume du bruit dans le cas de l'intelligence artificielle couplé à une sorte de conflictualité larvée nous force à revisiter cet héritage.

<br>
<br>

**Comment saisir les problèmes de l’IA, distinguer ceux qui méritent qu’on s’en soucie parmi le bruit ? De quelle forme d’attention ou de sensibilité faut-il s’équiper?**

![Images extraites de vidéos réalisées pendant l'enquête](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-20-a-22-49-59.png)

**En faisant le pari de la participation, nous avons cherché à nous réapproprier la problématisation de l'IA à travers une enquête collective qui part des pratiques concrètes. Et c’est d'abord à un équipement de l’attention que nous avons travaillé.** Nous avons élaboré des dispositifs d'enquête pour décrire et éprouver les pratiques de l'IA, du point de vue des praticiens. A partir de ces descriptions coisées, nous avons cherché à en discuter les effets tant sur les situations qu'ils vivent que sur le développement de l'IA en France. De tels dispositifs d’attention agissent en retour sur la trajectoire de son développement d'au moins deux manières. D’une part, héritiers d’une sociologie pragmatique, nous attribuons aux descriptions le potentiel de former des problèmes publics pertinents du point de vue des personnes impliquées dans l’enquête (chercheurs compris). D’autre part, la focale qu’ils placent sur les pratiques et leurs milieux permet l’identification et la mise à l’épreuve de *prises* élaborées par les acteurs pour faire évoluer leur situation — ou au contraire, ils peuvent mettre en lumière la perte progressive de leurs capacités d’action. 

Cette notion de *prise*, au cœur de notre travail, correspond aux opérations concrètes entreprisent par des personnes au sein de leurs activités situées pour transformer celles-ci, pour les faire évoluer. Ces prises sont élaborées dans des systèmes d'activité très divers et interfèrent, parfois tirant dans le même sens, d’autres fois en conflit, tentant d’empêcher certains devenirs. Elles concourent ainsi,de manière distribuée et en résonance, à donner forme à l’IA. À la fois guides et ressources pour l’action, les prises (et leur absence) sont constitutives du devenir des phénomènes socio-techniques.

Cette recherche s'apparente à une sorte d'**observatoire des prises sur l'IA** : elle donne ainsi à voir différentes formes de participation au développement de l'IA et aux problématisations qui en résultent. Avec cet élargissement de la notion de participation, nous espérons contribuer à redistribuer la capacité d’agir sur le développement des technologies d’intelligence artificielle. Ce site restitue les matériaux de l’enquête, dans une version synthétique pour le lecteur curieux, mais également dans une version intégrale pour celles et ceux qui voudraient en explorer les subtilités. 

<br>

![source : Ligue mondiale de surf (WSL)](https://corpora.medialab.sciences-po.fr/contenus/shaivagueartboard-1-copy.png)

**Septembre 2023.**
Une nouvelle séquence médiatique, plus virulente encore que la précédente, vient de s’achever. Au cœur de celle-ci, l’évènement ChatGPT qui pose l’IA générative comme nouvelle réalité. Cette recherche, qui s’est déroulée entre 2021 et 2023, aura donc connu deux cycles médiatiques avec entre les deux, le creux d’une vague. Néanmoins, les matériaux et les analyses restitués ici ne portent pas sur cette deuxième séquence et laissent de côté cette nouvelle figure de l’IA. Si les données du problème ont sensiblement évolué, cela n'invalide pas notre entrée par les prises et les pratiques. Au contraire ! Nous pensons que le partage de ces analyses et des matériaux qui les ont nourries posent des repères solides, précieux pour s’orienter lors de la prochaine déferlante.

<br>


---

<br>

<small>


[Entrer dans le site <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zM4.5 7.5a.5.5 0 0 0 0 1h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 1 0-.708.708L10.293 7.5H4.5z"/></svg>](/ShapingAI/#avoir-prise)


<br>

# SOMMAIRE
Ce site regroupe l'ensemble des contributions conceptuelles, méthodologiques et empiriques de notre recherche. Il est organisé en 5 sections.

![Image extraite de "2001, L'odyssée de l'espace" de Stanley Kubrick, 1968](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-51-27.png>https://mediaproxy.salon.com/width/1200/height/675/https://media.salon.com/2013/07/2001_monolith.jpg) pose la problématique de recherche et l'inscrit dans une brève histoire de la sociologie des controverses. Nous présentons les principaux concepts mobilisés dans ce travail (soucis, prises, participation...) et les trois méthodes d'enquête avec leurs partis pris.
![](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-51-32.png>https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-58-08.png) présente un modèle heuristique que nous avons élaboré pour outiller notre démarche d'enquête. Nous discutons dans cette section son intérêt tant pour l'analyse de nos résultats que comme moyen efficace de représentation à des fins de médiation.
![](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-51-37.png>https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-18-a-22-17-58.png) : première contribution empirique, cette étude montre comment l'IA est dépeinte dans la presse française. A travers une analyse quantitative des articles parus en France entre 2011 et 2021, nous aboutissons à une matrice des récits-types sur l'IA.
![](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-55-00.png>https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-12-a-11-42-29.png) de l'IA, organisés autour de 4 motifs principaux, témoignent de la pluralité des "préoccupations-en-actes" relatives à l'IA et en propose une cartographie. C'est la section la plus développée du site : on y trouve d'abord une synthèse des résultats de l'enquête collective menée avec 29 praticien.nes français; ensuite, pour chacun des 19 soucis identifiés, un accès aux matériaux de la recherche (une vidéo, une fiche récapitulative et des ressources documentaires) permet de remettre les soucis dans les voix des co-enquêteur.ices, restituant leurs perpectives plurielles.
![](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-51-46.png>https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-25-a-10-25-03-1.png) donne à voir la spécificités des soucis lorsque ceux-ci se jouent dans un cas d'application concret. Ici, il s'agit du projet *Foncier Innovant*, mené à la DGFiP pour automatiser la télé-détection de piscines à partir de prises de vues aériennes.

</small>

<br>
<br>
<br>
<br>


---


Cette étude a été réalisée entre 2021 et 2023 par l'équipe du médialab dans le cadre du projet international <a href="https://www.shapingai.org/" target="_blank">Shaping AI</a>.
<img src="https://www.shapingai.org/assets/images/logo.png" style="width:20%; text-align: right">

<br>
<br>
<br>

<small>  

**Les membres de l'équipe**
    Pauline Gourlet 
    Donato Ricci
    Maxime Crépel
    Maud Barret Bertelloni
    Axel Meunier
    Dominique Cardon
    Valentin Goujon


**Enquête menée avec 29 praticien.nes et avec le concours du Carrefour Numérique2 de la Cité des Sciences et de l'Industrie.**


**Crédits**
Edition : Pauline Gourlet
Illustrations : Pauline Gourlet
Site internet : l'atelier des chercheurs (Louis Eveillard et Pauline Gourlet)
Responsable de publication : Sylvain Parasie, médialab de Sciences Po
Contenu en licence CC-BY-SA
</small>

<br>
<br>

"""

[PAGE]
nom_de_page="Avoir prise..."
url="/#avoir-prise"
contenu="""

![](https://corpora.medialab.sciences-po.fr/contenus/mains.png)

<br>
<br>


# Avoir prise sur l'IA

---

**L’intelligence artificielle fait figure d’innovation de rupture.** 
Certains parlent même d’une quatrième révolution industrielle ([Schwab](https://www.dunod.com/entreprise-et-economie/quatrieme-revolution-industrielle), [l'UNESCO](https://fr.unesco.org/courier/2018-3/quatrieme-revolution)). Disruptive et en continuelle évolution, elle exigerait la révision des grilles d’analyse et des procédés classiques pour la décrire, la réguler et l’intégrer aux tissus de nos vies. Cette exceptionnalité de l’IA est à associer à ses dimensions planétaire et ubiquitaire, faisant apparaître comme insuffisante, voire anecdotique, toute tentative d’appréhension.

<br> 

L’extrait ci-contre, issu d’un workshop organisé dans le cadre de cette recherche, donne à voir une discussion autour de ce que serait **une  “bonne” attitude à adopter face à ce phénomène**. Alors qu'un participant spécule quant à la ![Extraits de dialogue issu d'un workshop du projet Shaping AI réunissant 22 des co-enquêtrice.eurs. Cité des Sciences et de l’Industrie, Paris (France), 14-15 juin 2022.](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-25-a-14-58-06.png>https://corpora.medialab.sciences-po.fr/contenus/suppression.png) de "tous les projets" d’IA, les réactions sont vives. Le bon geste serait-il finalement de “débrancher la technologie” et de vivre dans un monde sans IA ? 

<br>

Si cette proposition peut sembler excessive, fruit de l’émotion suscitée par une incapacité d’agir, une telle radicalité est pourtant mise en œuvre par les plus grands producteurs et acteurs de l’IA. En effet, en 2023, une lettre ouverte, signée par des chercheurs et intellectuels  renommés tels que Yoshua Bengio, Elon Musk, Steve Wozniak ou encore Yuval Noah Harari (ou Raja Chatila et Laurence Devillers par exemple, pour les acteurs français), appelle à mettre en ![Open letter - Pause Giant AI Experiments, Future of Life Institute, 2023](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-25-a-21-09-57.png>https://corpora.medialab.sciences-po.fr/contenus/fli-pause-giant-ai-experiments-an-open-letter.pdf.0.png.1600.jpeg?v=1695638634029) toutes les grandes expérimentations d’IA, le temps de prendre un peu de recul.

<br>

Tactique industrielle de communication — plus de controverses équivaut à plus de publicité — angoisses sincères ou fabrique utile du doute ? Indépendamment des motifs des signataires de cette lettre, on peut y lire énoncés distinctement trois principes importants : 
    - l’IA (“IA systems” ou “advanced AI”) désigne une entité agissante dans le monde, 
    - elle est puissante et représente une menace pour l’humanité, 
    - les personnes les mieux équipées pour évaluer et réguler les risques qu’elle pose sont les producteurs de cette technologie (en capacité de l’auditer), en dialogue avec des décideurs politiques et des régulateurs. 

Ces principes sont au fondement du courant “éthiciste” de l’IA. On en trouve un autre exemple dans un article plus ancien, co-écrit par Yoshua Bengio en 2019, qui en appelle à la morale des concepteurs de systèmes d’IA pour guider les choix de conception et éviter des risques majeurs pour “l’humanité" ([Luccioni et Bengio, 2019](https://arxiv.org/pdf/1912.11945.pdf)). Ce courant éthiciste s'incarne dans sa version française dans des initiatives comme le ["Serment d'Hyppocrate des data scientists"](https://dataforgood.fr/hippocrate/).

<br>

Cette menace globale exprimée par des experts et largement relayée par les médias fait émerger un sentiment d’impuissance et de perplexité. À bien des égards, ce récit nous place dans la position des singes face au célèbre ![Extrait de 2001, Space Odyssey, 1968](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-25-a-12-55-30.png>https://mediaproxy.salon.com/width/1200/height/675/https://media.salon.com/2013/07/2001_monolith.jpg) de *2001, L'odyssée de l'espace*. 

Dans cette étude, on désigne par *traitement monolithique* de l’IA, les récits qui la font exister comme phénomène univoque, global, à la fois puissant et menaçant, sans spécifier ni les systèmes techniques en jeu ni les agencements sociaux, politiques et économiques dans lesquels ils sont pris. Ce type de traitement a notamment pour effet d’invisibiliser les préoccupations et actions entreprises par certains acteurs pour résister ou faire bifurquer les trajectoires de développement de l’IA. De plus, il fait émerger une critique symétrique qui essaye de montrer que “l’IA n’existe pas” ([Jaton, 2021](https://journals.sagepub.com/doi/full/10.1177/03063127231194591#bibr38-03063127231194591)), qui ne nous laisse pas nécessairement plus en capacité d’appréhender ce qui est en jeu, même si elle possède une certaine puissance affective et mobilisatrice.

<br>

Pourtant, à bien regarder, on peut observer ici et là des manières d’agir et de participer à la formation de ces systèmes socio-techniques qui ne s’inscrivent pas dans cette binarité et qui négocient leurs formations au sein de situation, mettant en mouvement des assemblages complexes.

<br>
<br>


## Désexceptionnaliser l’intelligence artificielle
---

En adoptant une démarche empirique qui tente de suivre les systèmes techniques au plus près des processus qui leur donnent forme, on propose de sortir des traitements monolithiques focalisés sur l’(in)existence et les méfaits de l’IA pour décrire des genèses et des pratiques. Il s’agit de pister et rendre visible les nombreuses opérations par lesquelles des systèmes techniques dits d’IA prennent forme, agissent et affectent le monde. Cette approche empirique a pour effet de désexceptionnaliser l’IA en la resituant dans des histoires et des gestes concrets et oblige de revisiter à nouveaux frais les conflits et controverses qui émergent. 


Car l’IA ne fait pas non plus figure d’exception quant aux modes de gestion de ses controverses. Pour accompagner son développement, rassurer et désamorcer les conflits, les pouvoirs publics et les entreprises de “la tech” ont recours à des dispositifs participatifs délibératifs. On ne compte plus le nombre de consultations publiques, de chartes éthiques ou de sessions de design participatif qui ont fait discuter un public élargi pour mieux anticiper les risques et débattre des rapports IA-société (on peut en trouver un exemple dans la recommandation n°4 de l'[OPECST, 2017](https://www.senat.fr/salle-de-presse/communiques-de-presse/presse/cp20170329.html)). 

Cette manière de gouverner les problèmes liés à l'introduction d'une nouvelle technologie n’est pas nouvelle. Depuis les années 2000 en France (et plus largement en Europe), la voie de la participation et de la délibération, instanciée dans des dispositifs variés pour tout un tas d’innovations technologiques (forums de consensus, consultations, conventions…), s’est imposée comme une réponse pertinente pour prévenir les risques et problèmes éthiques induits par de les développements techniques. Les sciences sociales ont joué un rôle significatif, au côté des associations et des administrations, pour promouvoir ces modalités participatives, même si leur efficacité a été largement remise en cause par plusieurs travaux empiriques (pour une histoire de la “nébuleuse sciences-société”, voir [La Démocratie des Chimères](https://www.ehess.fr/fr/ouvrage/d%C3%A9mocratie-chim%C3%A8res), de Sara A. Aguiton). 

Chez les auteurs intéressés par ce tournant participatif dans les processus démocratiques, certains parlent d’*injonction à participer* ([Zask](https://www.editionsbdl.com/produit/participer-essai-sur-les-formes-democratiques-de-la-participation/)) ou de *participation-washing* (dans le cas de l’IA, voir par exemple les travaux de [Mona Sloane](https://arxiv.org/abs/2007.02423)).

> “Il arrive bien souvent que le résultat soit décevant, surtout lorsque participer se limite finalement à légitimer un dispositif existant, sans pouvoir ne se prononcer ni sur les motifs poursuivis ni même sur les décisions qui sont prises.”

—Joëlle Zask, 2018

<br>

Notre approche, pragmatiste et héritière d'une tradition participative dans les sciences sociales et le design, partage avec la conception délibérative de la participation un récent déplacement de focale : **de l’expression de volontés politiques individuelles à la formation de celles-ci** ([Manin](https://www-cairn-info.acces-distant.sciencespo.fr/le-tournant-deliberatif-de-la-democratie--9782724624908-page-9.htm)). Mais elle reprend à son compte les critiques qui ont été adressées à l'encontre d'une vision normative de la participation [on les trouve bien décrites chez Chilvers & Kearnes](https://journals.sagepub.com/doi/10.1177/0162243919850885)], ainsi que celles qui dénoncent une tendance au "participation-washing", et ce quelles que soient les intentions des concepteurs d'instances participatives. Plusieurs chercheurs en STS au début des années 2000, épousant le récit d'un tournant réflexif de la modernité (Ulrich Beck), ont tenté de développer une démocratie technique et ont pris un rôle de concepteurs d’instances délibératives et de médiateurs de débats. 

Ouvrir les arènes de discussion à des publics “profanes” (versus “experts”) pour pluraliser la définition des problèmes et accompagner leur prise en charge est pourtant une idée séduisante. Mais à bien considérer les dispositifs mis en œuvre,leurs inscriptions institutionnelles, matérielles et sociales et leur temporalité, on se rend compte qu'ils se retrouvent bien souvent à agir contre leur mission première de pluralisation et de prise en compte réelle des problèmes. Ils deviennent finalement des instruments du développement technique en prenant en charge et désamorçant les critiques. Plus précisément, les critiques portent sur au moins trois rôles joués par les dispositifs participatifs : un rôle d'autorisation (des expérimentations), un rôle de normalisation (des discours) et un rôle de fabriques de légitimation et d’acceptabilité sociale.

<br>

![Les chimpanzés du futur au pseudo Forum de la biologie synthétique, vendredi 26 avril 2013 par Pièces et main d’œuvre](https://www.piecesetmaindoeuvre.com/IMG/jpg/1-11-2d813.jpg)

Sara A. Aguiton, observant le champ naissant de la biologie de synthèse en France, a montré qu’au sein d’un dispositif de dialogue sciences-société, "les risques étaient construits comme des questions d’usages ou d’acceptabilité, si bien que les produits techno-industriels en eux-mêmes étaient toujours épargnés de l’analyse, de même que les rapports économiques et sociaux qui permettent leur production et ceux qui sont transformés par leur diffusion". Selon elle, les dispositifs de démocratie technique auraient en réalité comme tâche première de neutraliser les résistances et critiques perçues comme radicales et de prévenir les débordements, ce qui a pour effet de légitimer encore davantage l’innovation. Reprenant les conclusions de Marie-Angèle Hermitte, elle résume ainsi que les dispositifs participatifs qui visent à anticiper les risques liés aux développements technologiques reviennent à amnistier le coupable (les dégâts du progrès) en amont du crime.

> “En annonçant la conscience des risques, il avoue dès le départ que ça peut mal tourner, mais qu’il faut y aller. (...) Mais cette fois-ci, c’est assuré, on prêtera davantage attention. Preuve est d’ailleurs que l’on se préoccupe en amont. En ce sens, l’aveu porte moins sur les dommages d’hier que sur les controverses d’aujourd’hui. Ce glissement est essentiel à comprendre, car définir et réguler les dangers est toujours un moyen de gouverner d’autres phénomènes.”

— Sara A. Aguiton, La démocratie des chimères.

<br>

Cherchant à nous réapproprier la problématisation de l'IA et à construire des prises sur son développement, nous retiendrons trois éléments des travaux critiques sur les développements socio-techniques : 

• L’innovation d’aujourd’hui cherche à se distinguer du progrès d’hier en se présentant comme “plus responsable” et ceux qui la pousse se légitiment par la prise en charge des risques et des problèmes sociaux *(ici, le phénomène des “chartes éthiques de l’IA” en atteste largement)*.

• Les controverses sont l’occasion de reconfigurer les relations entre acteurs, notamment entre Etats, industries, et marchés. Elles sont aussi propices à l’instauration d’autres valeurs, politiques *(par exemple, on peut penser à la sécurité...)*, économiques *(ici, aux politiques sur les données...)*, ou sociales *(ici, aux réglementations sur les discours autorisés...)*. 

• L’acceptabilité sociale est la finalité centrale des acteurs qui encadrent le développement des technologies. Les réticences, résistances, remises en cause des projets et autres protestations sont largement invisibilisées ou écartées pour radicalité excessive.


<br>
<br>

## Le couple *soucis/prises* : repenser la participation à partir des pratiques situées
---

Notre approche propose de faire un pas de côté par rapport à des démarches classiques de participation en déplaçant le regard des instances de débat et du seul agir argumentatif vers l’agir en situation d’acteurs en prise avec l’IA, vers leurs pratiques concrètes au sein de leurs activités situées. D’une certaine manière, notre étude cherche à revisiter une question classique : **que veut dire *participer* aux devenirs des objets techniques, et en l'occurence, ceux de l'IA ?** Qui participe et de quelles manières ? Est-ce qu'il y a des manières plus souhaitables que d'autres, plus plurielles que d’autres ?

Comme le dit Chateauraynaud, nous pensons que c’est dans l’agir perceptuel, au contact des choses, que se situe le creuset de la fabrique des ouvertures d’avenir et nous lui empruntons le concept de **prise** :

> "A l’origine, la « prise », issue des travaux menés sur les ressorts perceptuels de l’action et du jugement, avait pour objet de remettre au cœur de la sociologie l’expérience dans le monde sensible.” (...) La prise n’est plus seulement conçue comme l’articulation d’un sujet et d’un objet, d’un projet et d’un monde, mais comme un travail continu des relations entre expériences passées (précédents), tensions actuelles (épreuves en contexte) et développements futurs (ouvertures d’avenir)."

—Chateauraynaud & Debaz, 2017

<br>
<br>

Prolongeant cette proposition de Chateauraynaud et Debaz, nous voyons un intérêt à diriger notre attention sur les manières dont les acteurs ont prise sur l’IA, ou au contraire, en sont dépourvus. Ici, nous mobilisons cette notion de prise pour rendre compte d’opérations concrètes mises en œuvre par des personnes qui tentent de faire évoluer une situation. Ces opérations sont conditionnées par les capacités d’agir des personnes et par les milieux dans lesquels ils opèrent, révélant en creux, par delà les dimensions psychologique et inter-personnelle, des éléments socio-historiques qui les permettent ou les empêchent. C’est pourquoi nous envisageons les prises comme un terrain privilégié pour l’analyse des trajectoires socio-techniques. 

Il s’agit alors d’enquêter et de décrire comment s’y prennent concrètement les personnes dans leurs tentatives de reconfiguration des situations dans lesquelles elles agissent. Ces tentatives témoignent d’un problème, d’un malaise ressenti au sein d’une expérience dont la source est plus ou moins bien identifiée. 

> “In ordinary language, a problem must be felt before it can be stated. If the unique quality of the situation is had immediately, then there is something that regulates the selection and the weighing of observed facts and their conceptual ordering.” 

— Dewey, Logics - 1938, p.70-71

Nous appelons **souci** le sentiment éprouvé au sein d'une activité répétée (une pratique) qui met en mouvement, en quête d’une situation préférable. Ambivalent, il renvoie à la fois à un problème (*“On a un souci”*), une sensation de tracas, une préoccupation (*“Je me fais du souci”*), mais aussi à quelque chose dont on prend soin, dont on a la charge et dont le devenir dépend de nos actions (*“j’ai le souci de bien faire”* ou *“je me soucie de la réussite de ce projet”*).

Le concept de **prise** s’articule ainsi dans notre approche à celui des **soucis** de praticien.nes. La mise en mouvement provoqué par un souci s’apparente à une forme d’enquête (au sens de Dewey) : on tâtonne, on cherche des moyens, des ressources et des appuis (des *prises*) pour reconfigurer la situation qui préoccupe et à travers cette enquête, l’objet du souci se forme. . En ce sens, les soucis sont un lieu de fabrique et de mise à l'épreuve des prises, qui donnent à voir les possibilités et les contraintes (matérielles, symboliques, sociales) des acteurs pris à partir des milieux qu’ils investissent. 

![extraits de nos entretiens, illustrations du concept de prise dans le récit rétrospectif de deux praticiens de l'IA.](https://corpora.medialab.sciences-po.fr/contenus/prises.png)

Considérées de façon systémique, dans leur dimension distribuée (socialement et temporellement), toutes ces opérations participent de la constitution et de la trajectoire de l’IA. **En prêtant attention aux soucis de praticien.nes de l’IA en France, notre recherche cherche ainsi à repérer et bien décrire les pratiques (dans leur pluralité) et les séries d’opérations et d’épreuves qui donnent forme à l'IA.**


Par rapport à des approches plus traditionnelles en sociologie des sciences, cette approche propose au moins **trois déplacements** :

**Un déplacement vers des praticien.ne.s soucieux.ses**
Là où les instances participatives cherchaient à faire discuter des non-experts (ou “profanes”), nous nous intéressons aux activités de praticien.nes “soucieux.ses”. La qualification de “praticien” met en avant la dimension expérientielle et praxéologique et ne définit pas d’activités particulières ou de milieux *a priori*. L’adjectif “soucieux” rend compte la dimension réflexive, manifestement en enquête et doutant de la bonne manière d’agir quant à un objet en formation. Un.e praticien.ne soucieux.se agit directement ou indirectement sur l’objet de l’enquête avec une forme de réflexivité quant aux opérations qu’il.elle déploie.

**Un déplacement vers des situations inscrites temporellement et socialement**
Ici, il ne s’agit pas d’anticiper des risques ou des problèmes à venir mais de partir du présent des expériences vécues pour étudier comment sont identifiés et pris en charge les éléments jugés problématiques au sein des situations. De plus, s’intéresser aux situations permet de prendre en compte la dimension nécessairement située et partielle d’une pratique, inscrite dans un milieu et des relations spécifiques et contrainte par des attitudes et des habitudes personnelles et collectives éprouvées. Au cours de l’enquête, beaucoup des soucis des praticien.nes co-enquêteur.ices semblaient concerner des objets “accessoires” à l’IA mais qui se sont en fait révélés constitutifs, d’où l’importance de rester ouvert à ce qui se présente concrètement au sein des activités situées.

 ![extraits d'entretien qui montre le type de glissements que l'on repère au contact des praticiens de l'IA.](https://corpora.medialab.sciences-po.fr/contenus/biais.png)

**Un déplacement vers l’analyse des “jeux de prises”**
Les deux extraits d'entretiens ci-contre illustrent la carrière du terme de “biais algorithmiques”. Ce déplacement de sens est caractéristique de ce que nous appelons les “jeux de prises”. En suivant la fabrique et la mise à l’épreuve de prises, il devient possible de détecter des “carrières”, c’est-à-dire la manière dont certaines prises circulent, sont re-mobilisées et éventuellement détournées de leurs finalités premières. Cette focale permet de rester attentif aux asymétries de prises et donne à voir comment certaines pratiques disposent de ressources inaccessibles à d’autres ou comment elles leur sont progressivement retirées. Ces “jeux de prises” sont au cœur de l’analyse des soucis des praticien.nes et constituent pour nous un moteur de la participation, un endroit à partir duquel repenser des instances efficaces de construction de prises communes (d’où le titre de cette publication “prises, emprises, déprises, reprises…”).



C’est à un exercice de zoom et de dézoom simultané qu’invite l’analyse des soucis. Tenir une attention soutenue aux petits gestes qui comptent tout en recomposant une trame cohérente, qui tente de faire cohabiter des mondes qui ne se fréquentent pas, pour mieux comprendre et décrire les interdépendances et les interactions qui forment l’IA aujourd’hui en France. Notre souhait est que cette approche soit générative de prises collectives efficaces pour faire importer une participation authentiquement plurielle.



<br>
<br>

## Jouer des échelles et enquêter collectivement : méthodes et partis pris 

---

![Les trois lentilles mobilisées dans notre recherche et leur articulation](https://corpora.medialab.sciences-po.fr/contenus/methodes-all.png)
Pour étudier un phénomène aussi hétérogène dans ses manifestations que ramifié spatialement, matériellement et historiquement, **nous avons combiné trois méthodes d'enquête qui offrent trois niveaux d'analyse, de la plus distante à la plus située**. Ajustées les unes par rapport aux autres, ces lentilles permettent de saisir la formation de l’IA depuis les “jeux de prises” et leur circulation depuis un instant T autour d'un système d'IA particulier aux imaginaires présents dans les récits qui font autorité.

*Une premier niveau d’analyse* (![Les trois lentilles mobilisées dans notre recherche et leur articulation](https://corpora.medialab.sciences-po.fr/contenus/medias.png>https://corpora.medialab.sciences-po.fr/contenus/methodes-medias.png)), mobilisant des méthodes numériques d’analyse de corpus textuels conséquents, a consisté à thématiser et cartographier les enjeux relatifs à l’IA présents dans les récits médiatiques vecteurs de critiques ou, au contraire, vecteurs de promesses. A partir d’un corpus de plus de 45.000 articles parus dans la presse écrite française (281 sources) entre 2011 et 2021, nous avons entraîné un modèle de traitement automatique du langage pour obtenir deux sous-corpus (comprenant 14.000 articles au total) : un sous-corpus d’articles “critiques”, mettant en avant les effets délétères de l’IA et un sous-corpus d’articles “positifs”, vantant les bienfaits de l’IA. Nous avons dans un second temps généré un réseau des thèmes présents, analysé leur tonalité, leur évolution dans le temps et repéré les entités mentionnées pour chacun de ces thèmes.

Cette plongée dans les récits médiatiques de l’IA nous a permis de repérer quatre récits-types, mettant en scène des types d’entités différentes et des relations spécifiques entre ces entités. Ces structurent narratives s’organisent dans une matrice bien utile pour comprendre l’emprise que ces récits exercent sur le cadrage des problèmes dans des situations concrètes.

<br>

*Un deuxième niveau d’analyse*, le plus conséquent et pivot dans notre approche, se concentre sur les ![Les trois lentilles mobilisées dans notre recherche et leur articulation](https://corpora.medialab.sciences-po.fr/contenus/pratiques.png>https://corpora.medialab.sciences-po.fr/contenus/methodes-pratiques.png). Au lieu d’observer des pratiques individuelles à la manière de l’ethnographie, nous avons organisé une enquête collective réunissant des *praticien.nes soucieux.ses* de l’IA (n=29) aux activités très diverses (data science, journalisme, droit, entreprenariat, recherche, fonction publique, art, activisme,…). Attentifs aux dynamiques de problématisation qui structurent le champ d’expériences des co-enquêteur.ices (Cefaï, 2012), nous avons conçu et testé un  dispositif qui remplit d’une part un rôle d’*intensification* des expériences vécues comme problématiques ou préoccupantes et d’autre part un rôle d’*explicitation* des opérations entreprises pour les transformer (ou dans certains cas, du sentiment d’impuissance de ne pas pouvoir le faire). La documentation et les témoignages récoltés à l’aide de ce dispositif nous ont permis de thématiser les soucis portés par les praticien.nes et de rendre compte de quatre grands motifs d'agir. Des petites vidéo, une par souci, donnent à entendre la voix des co-enquêteur.ices. Elles sont montées de manière à faire saisir la pluralité des perspectives et des prises disponibles pour un souci donné. 

En juin 2022, nous avons discuté collectivement au cours d'un workshop qui a réuni tou.tes les co-enquêteur.ices. Cette occasion a permis de préciser la description plurielle de certains soucis et de questionner la portée de notre dispositif d'enquête au regard de l'enjeu de réappropriation des problématisations de l'IA.

<br>

Enfin, *le dernier niveau d’analyse* s’intéresse à un ![Les trois lentilles mobilisées dans notre recherche et leur articulation](https://corpora.medialab.sciences-po.fr/contenus/cas.png>https://corpora.medialab.sciences-po.fr/contenus/methodes-cas.png), c’est-à-dire à la conception et à l’expérimentation concrète d’un système ayant recours à des techniques d’IA pour effectuer des tâches spécifiques au sein d'une situation donnée. Tirant parti de l’analyse des soucis des praticien.nes et de leurs convergences, nous avons fait le choix d'enquêter sur un cas dans l'administration publique, en l'occurence, la Direction Générale des Finances Publiques (DGFiP). Le choix du cas a reposé sur l’hypothèse qu’une description fine du fonctionnement des rapports soucis/prises depuis ce cas permettra de construire des prises transverses, mobilisables dans plusieurs situations, susceptibles d’inverser certains “jeux de prises”.

La DGFiP mène une expérimentation sur un système de reconnaissance d’images mis en œuvre sur des photographies aériennes. Cette expérimentation, nommée *Foncier Innovant*, a pour objectif d’aider au contrôle des fraudes sur la taxe foncière. Nous avons d’abord cartographié les entités prises et agencées au sein de cette expérimentation, documentées par d’entretiens avec une vingtaine de personnes et un important travail d’archives. Puis, dans l’esprit de la première enquête collective, nous avons réuni une dizaine de personnes concernées au premier plan par ce cas pour déplier, amender et expliciter les soucis et les prises à partir des perspectives de chacun.e.

<br>

A travers ces trois niveaux et leur articulation autour des pratiques, nous multiplions les sondes et parvenons à mieux saisir la formation de l’IA et de ses problèmes, depuis son *traitement monolithique* jusqu’à sa granularité la plus fine, au cœur même des *situations où elle s'expérimente*.



<br>
<br>

---

<small>Note : Chaque pièce iconographique choisie pour accompagner les textes de ce site, si elle n’est produite spécifiquement pour les besoins de cette recherche, participe de l’histoire de l’IA (d’une manière qui n’est pas toujours explicitée dans le texte pour des raisons de clarté), du dessin de neurone par S. Ramon y Cajal, jusqu’à la vague de surf, petit clin d’œil au texte de Deleuze sur les sociétés de contrôle).</small>


<br>
<br>
<br>
<br>


"""



[PAGE]
url="/#la-boucle"
nom_de_page="La boucle de l'IA"
contenu="""


![Jeu de la vie](https://corpora.medialab.sciences-po.fr/contenus/09-10-104p177-copy.gif)

<br>


# *Qui est pris dans la boucle ?* Représentations et conséquences

---

Une image vient immédiatement en tête quand on parle d'IA ou de machine learning : celle des réseaux neurones, que ce soit leur représentation historique ![Perceptron](https://corpora.medialab.sciences-po.fr/contenus/picture3.png) ou des versions plus récentes ![Neural Network Zoo, Asimov Institute](https://corpora.medialab.sciences-po.fr/contenus/neuralnetworkzoo20042019-1.png). 

Mais une autre image est couramment utilisée lorsqu'on parle de systèmes d'IA ou de systèmes algorithmiques : celle de "black box" ![Le Hemostat du cybernéticien W. Ashby Ross, premier appareil à avoir été qualifié de boîte noire. source : W. A. Ross, 1948](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-20-00-13.png>https://upload.wikimedia.org/wikipedia/commons/4/43/W._Ross_Ashby%27s_1948_Homeostat.jpg). 

<br>

## L’IA, une boîte noire ?

Qu'est-ce qu'une boîte noire ? Ce concept désigne la manière dont le travail scientifique ou technique est rendu invisible par son propre succès : 

<img src="https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-19-54-58.png" style="width:90%"></img>

<small> Latour, *L’espoir de pandore*, p. 304. </small>

Dans le domaine de l’IA en particulier, la notion de “black box” a été élargie pour désigner d'une part les difficultés d’interprétation et d’explication du fonctionnement des modèles d’IA, et d'autre part l'impossibilité de remonter aux données utilisées pour entraîner de grands modèles.
Par extension, ce terme est employé au regard des conséquences inattendues de ces systèmes lorsqu'ils sont déployés dans le monde. Franck Pasquale parle par exemple d'une ["société boîte noire"](https://www.hup.harvard.edu/catalog.php?isbn=9780674970847) qui, derrière la complexité technique chercherait à cacher la part de choix inhérente à toute décision.

En plus de l’opacité relative au fonctionnement technique à proprement parler, il semble difficile d’identifier les personnes et les activités responsables de la production de systèmes d’IA, “chacun situant l’algorithme juste en dehors de ses tâches de travail”, comme le montre [Nick Seaver](https://journals.sagepub.com/doi/full/10.1177/2053951717738104) dans ses études ethnographiques sur les algorithmes. On retombe ainsi sur l'idée d'un objet insaisissable, présent partout et nulle part.

<br>
<br>

## Une représentation élargie : l’approche des STS

L’inquiétude qu'éveille l'IA et les débats qui l'entourent ont suscité un renouveau des travaux en études des sciences et des techniques (en anglais, *science & technology studies* ou STS). 

L'approche  des STS consiste à tenter d'ouvrir la “boîte noire” de l’IA par un épaississement des descriptions socio-techniques pour étudier le fonctionnement d'objets techniques spécifiques, leurs modes de production, les cultures et les conflits qui s’y trament, la manière dont ils transforment les milieux dans lesquels ils s'insèrent. Les auteurs qui s'y rattachent s’appuient sur différentes conceptions et représentations des assemblages que forment les entités prises dans ces systèmes d’IA pour identifier des problèmes pertinents.

Par exemple, Nick Srniček a proposé d’analyser la production des modèles d’IA en distinguant quatres étapes dans la chaîne de travail de production de modèles : la collecte des données, leur nettoyage et étiquetage, la construction d'un modèle et son déploiement pour des usages spécifiques. Il souligne l’importance que cette focale élargie peut avoir pour la formulation des problèmes dont s’emparent les politiques publiques.
> “Tant que l’on ne change pas le regard sur l’IA et que l’on ne considère pas toutes les étapes de sa production, on restera focaliser sur des problèmes de données et de surveillance, alors que de nombreux enjeux se concentrent autour des équipements de calcul et des infrastructures (énergétiques, hydriques) qui permettent de les approvisionner.” 

<small>[article AOC, 2023](https://aoc.media/entretien/2023/07/14/nick-srnicek-on-peut-imaginer-un-agenda-radical-en-matiere-de-nouvelles-technologies/)</small>

<br>

A plusieurs égards, ce découpage n'est pas très éloigné de ceux présentés dans plusieurs articles académiques récents de chercheurs en IA, ![Cascades, 2021](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-18-a-17-11-47.png) ![Foundation Models, 2022](https://corpora.medialab.sciences-po.fr/contenus/photo-2023-09-18-17-08-55-1.jpeg) et on retrouve cette même préoccupation d'élargissement dans certaines représentations institutionnelles, comme l'[OCDE](https://www.oecd.org/publications/oecd-framework-for-the-classification-of-ai-systems-cb6d9eca-en.htm) ![OCDE Framework for the classification of AI systems - 2023](https://corpora.medialab.sciences-po.fr/contenus/OCDE.png). La multiplication de ces représentations dans différents milieux semble indiquer que cette focale élargie soit en passe de devenir plus communément établie.

<br>

Dans [Anatomie d'un système d’IA](https://anatomyof.ai/) de 2018, Kate Crawford et Vladan Joler ont proposé une représentation fouillée ![Anatomy of an AI system](https://corpora.medialab.sciences-po.fr/contenus/ai-anatomy-map.pdf.0.png.1600.jpeg?v=1695049162426) qui appréhende l’IA à partir de trois “processus d’extraction” nécessaires à son fonctionnement : les ressources matérielles, le travail humain et les données. Partant de l’enceinte connectée Echo de Amazon, ils décrivent à l’échelle planétaire l’imbrication des processus de transformation qui permettent de passer de matières premières à l’usage d'un gadget connecté. Une version synthétique ![Illustration Vladan Joler](https://corpora.medialab.sciences-po.fr/contenus/atlas-of-ai-projection.png) de cette même idée préside dans l'illustration de l'ouvrage [Atlas of AI](https://www.katecrawford.net/) de Crawford (illustrée également par Joler). Adoptant une approche systémique, ils se donnent ainsi pour objectif de fabriquer des représentations de type cartographique—un atlas, pour se repérer dans la géographie planétaire de l’IA. 

<br>
<br>

## La boucle de l'IA : une heuristique pour enquêter de manière située et plurielle

Poursuivant le même mouvement d'élargissement et à des fins d'outillage de notre enquête collective, nous avons développé une représentation heuristique ![la boucle](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-11-18-32.png>https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-20-58-08.png) à **quatre pôles**, qui part du monde pour y revenir.

Depuis le **monde** où les **données** sont extraites, la partie gauche de la boucle rend compte des pratiques relatives à la formulation des tâches que les **modèles** doivent accomplir et au développement de ces modèles. Cela comprend toutes les pratiques relatives au travail des données, à l'entraînement et l'évaluation des modèles, mais aussi celles relatives à l'ingénierie des systèmes, des réseaux et des infrastructures, leur déploiement et leur maintenance. Une part importante des pratiques juridiques et économiques de l'IA sont aussi fortement associées au pôle données. Le côté droit de la boucle, quant à lui, part des modèles pour circuler vers leur opérationnalisation dans des **instanciations**, c'est-à-dire des produits ou des interfaces numériques qui mettent en œuvre une version spécifique d'un modèle d'IA. Intégré à d'autres systèmes numériques et d'autres instruments, ces instanciations agissent dans le **monde**, au sein de situations concrètes qui se réorganisent.

La représentation circulaire souligne la coproduction, mutuelle et continue, du social et de la technique : elle met en avant une conception matérialiste et relationnelle des techniques. 


**Une conception matérialiste** : la constitution d'un objet technique se comprend d'abord matériellement, elle ne peut être appréhender par les seuls discours qui l’entourent ou par l’idéologie scientifique qui l’anime. Il s'agit ainsi de saisir l’IA à partir de tous les processus concrets qui participent de sa production et de son devenir, c'est-à-dire à partir des configurations et des dynamiques sociales, économiques, politiques, techniques et matérielles qui participent de son développement.

**Une conception relationnelle** : les objets techniques ne sont pas caractérisés par une identité stable et invariante, mais sont en constante transformation, depuis leur conception jusqu'à leurs devenirs, au sein de situations concrètes [(sur ce point, voir Didier Debaise)](https://www.cairn.info/revue-multitudes-2004-4-page-15.htm). Cela implique d'étudier les systèmes d’IA et leurs problèmes à partir des processus de production et de déploiement au sein de milieux spécifiques, en donnant de l'importance aux entités qui composent ces milieux et à leurs interactions.

![carte annotée](https://corpora.medialab.sciences-po.fr/contenus/layer-0.png)

Par rapport aux modèles proposés par Nick Srnicek ou Kate Crawford, cette représentation est envisagée comme un outil pour saisir l’IA à partir des situations, des pratiques et des milieux dans lesquels elle advient et par lesquels elle circule. Elle vise d'une part à **reconstituer l'ensemble des entités concernées par le développement d'un ou de plusieurs systèmes d'IA**, décrits à travers des témoignanges situés—et donc partiels—de personnes concernées par eux. D'autre part, elle tente de **rendre compte dans un même espace d'une pluralité de pratiques et de modalités opératoires donnant forme à l'IA**, mettant en lumière leur dynamiques et leurs conflits, permettant ainsi une mise en dialogue quant à l'ojet "IA" qu'elles font apparaître.

<br>
<br>


<small>

[Voir comment la boucle est utilisée dans l'enquête <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zM4.5 7.5a.5.5 0 0 0 0 1h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 1 0-.708.708L10.293 7.5H4.5z"/></svg>](/ShapingAI/#les-soucis)

</small>

<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
.

"""


[PAGE]
url="/#medias"
nom_de_page="Les récits de l'IA"
contenu="""
 
![coupures de presse](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-18-a-22-17-58.png)

<br>

# Approcher l’IA par l’analyse des récits médiatiques

---

> «Moi, le récit auquel j'ai participé en tant que journaliste, c’est celui de la puissance de l’IA et le fatalisme des hommes et femmes face à cette puissance.»

— Extrait d'entretien avec L., journaliste

<br>



Inspirés par les *media studies* et leurs études sur l’IA (Cools et al 2022 ; Chuan, Tsai et Cho 2019) et mobilisant des méthodes de cartographie, notre enquête sur la couverture médiatique des technologies d’IA analyse comment les médias participent à façonner l'opinion publique. Quel horizon d’attentes et quelles préoccupations établissent-ils concernant ces technologies ?

Nous avons étudié le type de récits médiatiques qui se déploient dans le contexte national français. Cette approche permet de contraster une vision monolithique de l’IA avec un ensemble plus composite de technologies de calculs qui se structurent autour de différents domaines d’application. Nous avons ainsi pu distinguer et qualifier des mise en récit différenciées de la part des médias et analysé leur performativité sur le développement de l'IA. 
Mais cette approche permet également d’identifier des cas de problématiques spécifiques au contexte français en restituant la pluralité des entités et des enjeux qui leurs sont associés afin de donner des plus de prises pour de futures enquêtes sur ces cas controversés.

Les résultats des analyses proposées dans les parties suivantes ont comme objectifs de comprendre :
-Comment a évolué la couverture médiatique de l’IA dans les 10 dernières années ?
-Quels sont les thèmes associés à ces technologies dans la presse française ?
-Quel type de cadrage est fait de ces technologies d’IA ?
-Quels agencements sociotechniques viennent alimenter les récits de critique et de promesse associés à l’IA ?
-Quels sont ceux qui sont spécifiques au contexte français et constituent des cas locaux ?

<br>

## Méthodologie

Pour analyser les enjeux présents dans les récits médiatiques, nous avons utilisé des méthodes quantitatives et cartographiques (Marres et Moats 2015 ; Venturini et Munk 2022) qui construisent des réseaux sémantiques.

Nous avons tout d'abord constitué un corpus de 45,608 articles de presse issues de 281 sources françaises (telles que disponibles sur Europresse), sur une période de dix ans (2011-2021). 
Ayant découverts que les médias amplifiaient les enjeux relatifs à l'IA en leur donnant une tonalité positive ou négative (Nguyen et Hekman 2022), nous avons entraîné un classifieur automatique par apprentissage supervisé pour trier d'un côté les articles qui mettent en avant les aspects positifs de l'IA et de l'autre, ceux qui en font une critique négative. 71% des articles (32 247 articles) sont qualifiés comme neutres car ils décrivent factuellement le contexte économique et organisationnel du déploiement des technologies d'IA et sont assez pauvres du point de vue de leurs enjeux. Le réseau sémantique des enjeux de l'IA est ainsi construit sur la base des co-occurences existantes dans un corpus de 13.161 articles de presse, vecteurs d'un discours de promesse ou de critique.

Cette méthode permet d’explorer deux sous corpus d’articles aux caractéristiques assez distinctes quant au traitement médiatique qui est fait des technologies d’IA. A partir des méthodes de traitement automatique du langage déployées, il s’agit de procéder à une analyse des thèmes portés dans la presse, de leur tonalité et des entités techniques, humaines, économiques mais aussi des enjeux soulevés dans la presse. Si l’analyse ne prétend pas être une photographie parfaitement représentative de la presse française, elle entend pourtant offrir des prises interprétatives quant aux grammaires de la critique et aux arguments de la promesse tels qu’ils sont déployés dans la presse et tendent à façonner la représentation de ces technologies dans l’espace public.

[Le détail du protocole méthodologique utilisé en PDF](https://corpora.medialab.sciences-po.fr/contenus/doc00-methodo-protocol-media-fr.pdf)

<br>
<br>

## Croissance de la couverture médiatique de l’IA
---

![Distribution du nombre d’articles en fonction du classifieur Fastext entre les catégories critique/menace (jaune), promesse/bénéfice (bleu) et neutre (gris) en haut. Ratio en pourcentage des articles critique et promesse en bas.](https://corpora.medialab.sciences-po.fr/contenus/fig01-demo.png)

La démographie globale du corpus d’articles permet d'observer la manière dont la presse française couvre depuis les dix dernières années le thème de l’IA. Tout d’abord, le classifieur permet en partie de rendre compte de la tonalité des articles sur l’ensemble de la période. Sur la totalité du corpus extrait (45 608 articles), on observe une part de 9,5% d’articles (4 261 articles) associés à un discours critique ou de menace lié à ces technologies. A l’inverse, 19,5% (8 900 articles) des articles sont associés à un discours de promesse technologique ou mettent en avant les bénéfices de ces technologies.  

La distribution globale du corpus montre une hausse progressive de la couverture médiatique de ce thème dans la presse française jusqu’en 2019 avant un déclin de la couverture médiatique. Alors qu’il y a peu de publications sur notre requête entre 2011 et 2014, le nombre de publications augmente significativement à partir de 2015 pour atteindre un pic au milieu de l’année 2019. La distribution dans le temps suit cette même courbe avec une couverture médiatique qui décroît légèrement à partir du courant de l’année 2019, qu’il s’agisse des articles associés aux récits de la promesse, aux récits critiques ou au reste du corpus. Le décrochage marqué au début de l’année 2020, si on peut supposer qu’il est en partie lié à la crise sanitaire du Covid19, semble antérieure à cette crise et se poursuit jusqu’en 2021. Peut-on y voir un signe d’essoufflement de la couverture médiatique du thème de l’IA ? Le battage médiatique sur les IA génératives (notamment avec l'apparition de ChatGPT) à la fin de l'année 2022 laisse imaginer que nous avons plutôt à faire à des cycles médiatiques, dont les intensités suivent les sorties de nouvelles démos ou produits.

En éliminant les articles catégorisés comme neutre, on constate que le ratio entre les articles négatifs et positifs reste relativement stable sur la période 2011-2021 et équivalent à la répartition globale, soit 1/3 d’articles catégorisés comme critique pour 2/3 d’articles catégorisés comme promesse. Ce résultat est intéressant car il rentre en contradiction avec des études précédentes et avec les entretiens que nous avons menés auprès de quelques journalistes, qui témoignaient d'un sentiment d'augmentation des sujets critiques des technologies d'IA ces dernières années. Mais cela peut en partie s'expliquer par la pluralité des sources dont proviennent nos articles, là où les autres études s'appuyaient sur des sources généralistes.

<br>
<br>

## Polarisation thématique de la promesse et de la critique de l’IA
---

![Réseau sémantique de cooccurrences des termes en fonction de la tonalité associé et au terme du réseau. En jaune les termes associés à la critique en bleu les termes associés à la promesse.](https://corpora.medialab.sciences-po.fr/contenus/fig02-global-network.png)

Le réseau sémantique basé sur l’analyse du texte des articles montre un ensemble de 11 grands thèmes cohérents thématiquement qui occupent des zones différentes dans le réseau. En projetant sur le graphe les fréquences relatives d’utilisation des termes du réseau en fonction des articles associés à la critique et la promesse on observe une polarisation importante de ces deux types de discours sur le graphe. Les termes associés à la critique occupent principalement la zone droite du réseau, à l’exception de quelques poches localisées dans le reste du graphe. La critique se concentre davantage sur les thèmes de l’éducation, de la justice, de défense et surveillance ou encore des enjeux plus globaux et centraux liés à l’éthique du développement de l’IA dans la société. A l’inverse, les termes du réseau de la partie gauche du graphe sont davantage associés à un discours de promesse concernant principalement les développements de l’IA dans la santé, l’art, la recherche ou encore le commerce et la finance. 


<br>

![Distribution des clusters en fonction du volume d'articles et de leur tonalité](https://corpora.medialab.sciences-po.fr/contenus/fig03-scaterplot-ton.png)

Au-delà de cette analyse visuelle générale de la topologie du réseau montrant une forme de polarisation entre critique et promesse, on peut également observer la distribution des clusters en fonction du volume d'article, ainsi que le ratio d’articles associés au discours de critique ou de promesses. Les 4 clusters Les plus associés à la critique sont AI_Society_Post Humanity, Education_Parcoursup_Matching Algorithm, Labour_Employment_HR et Law_Justice_Layers. À l'inverse les 4 clusters les plus associés à un discours de promesse sont Platform_Digital_Web Technologies, Health_Disease_Medical Pratictioner, AI_Research_Innovation et Finance_Business_Insurance. On retrouve bien ainsi la polarisation entre la partie droite du réseau orientée vers un discours critique et la partie gauche associer plus largement à un discours de promesse technologique. Il convient de noter également que parmi les clusters les plus volumineux en nombre d’article on retrouve les 3 principaux clusters qui dominent le corpus davantage associés à un discours de promesse portant sur les technologies des plateformes du Web, de la santé et de la recherche en IA.


<br>
<br>

## Quatre genres de récits médiatiques sur l'IA

---

![Matrice des récits médiatiques projetés verticalement sur un axe projection/réalisation et horizontalement sur l’axe de la tonalité critique/promesse](https://corpora.medialab.sciences-po.fr/contenus/matrice.png)

Poursuivant l'investigation de notre corpus, nous avons extrait et annoté manuellement les entités présentes dans chaque cluster de manière qualitative. Les catégories suivantes ont émergé à travers un processus de codage itératif : entités techniques, entités de données, personnes, personnalités publiques, entreprises, institutions et sujets. Bien que les clusters ne soient pas homogènes dans la façon dont ils rendent compte de l'IA, l'analyse des arrangements des entités dans chacun a révélé quatre récits typiques sur l'IA, c'est-à-dire **quatre genres**. Ces quatre genres sont organisés sur une matrice à deux axes, de la projection à la réalisation et du négatif au positif. 
 
**Le premier genre**, (quadrant en haut à gauche) ![Matrice des récits médiatiques projetés verticalement sur un axe abstrait/situé et horizontalement sur l’axe de la tonalité critique promesse](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-17-15-44.png>https://corpora.medialab.sciences-po.fr/contenus/genre1.png) présente l’agencement typique des thèmes centraux du réseau. Véhiculant des critiques, souvent sur un registre prospectif, ces récits insistent sur les risques potentiels, désignés de manière vague ("transhumanisme", "éthique"), que les technologies de calcul font courir à la démocratie et "l'humanité". Ce genre tend à établir une relation directe et déterministe entre une entité technique aux frontières floues désignée (« IA ») et des entités humaines englobantes comme l’humanité ou la société. Les acteurs sociaux restent assez abstraits, avec peu de référence aux environnements sociaux et politiques français et à leurs spécificités ; plutôt, des penseurs éminents ("Jeremy Rifkin"), des leaders politiques ("Macron") ou des institutions mondiales ("Église", "UNESCO") sont mentionnés, bien que souvent, les principaux actants ne soient pas des personnes mais la technologie elle-même ou des idéologies (telles que le modèle néolibéral intégré dans le développement de l'IA).

<br>

**Le second genre**, nommé promesses globales ![Matrice des récits médiatiques projetés verticalement sur un axe abstrait/situé et horizontalement sur l’axe de la tonalité critique promesse](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-17-15-44.png>https://corpora.medialab.sciences-po.fr/contenus/media-genre2.png) insiste sur les percées et les bénéfices des innovations de R&D en IA. On y trouve associées des entités techniques et de données assez spécifiques ("AlphaGo Zero", "stockfish", "réseaux neuronaux", "signal", "cerveau") à des chercheurs internationaux et français de premier plan dans des domaines allant de la physique aux sciences cognitives. Posant là encore une relation déterministe entre IA et humanité, ce genre a comme principal ressort narratif l'émergence d'une intelligence artificielle autonome, développée en laboratoire, capable de rivaliser avec l'intelligence humaine. Il a comme caractéristique de ne pas embarquer d’entités humaines hors du laboratoire ou alors uniquement dans leur existence mise en données. Sont alors mis en scène un représentant (un proxy) pour les deux parties (IBM Watson *versus* les champions Brad Rutter et Ken Jennings ou AlphaGo *versus* Lee Sedol). Bien que l'on note la présence de quelques structures commerciales françaises ("Hub France IA"), les principaux acteurs de ce genre sont les laboratoires de recherche de grandes entreprises informatiques ("Google", "OpenAI") - ou les start-ups qu'elles ont acquises - et les technologies qu'elles développent. Ils soutiennent ce récit à travers des démonstrations régulières et spectaculaires déployées dans des environnements similaires à des jeux ou simulés. 


<br> 
<br>
 
Face à ces genres qui projettent une relation directe entre "IA" et "monde" en reposant sur des entités aux contours mal définis ou archétypales, la partie inférieure de notre matrice présente au contraire des arrangements locaux et spécifiques. Elles se concentrent sur des technologies réellement déployées dans la société, qui organisent des problèmes locaux, engendrent des effets (dénoncés ou encensés) et mettent en scène des acteurs tangibles.

**Les expérimentations prometteuses (genre 3)** ![Matrice des récits médiatiques projetés verticalement sur un axe abstrait/situé et horizontalement sur l’axe de la tonalité critique promesse](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-17-15-56.png>https://corpora.medialab.sciences-po.fr/contenus/media-genre3.png) explorent l'arrangement de thèmes dans lesquels des récits détaillés sont construits autour de solutions innovantes et d'applications introduites sur le marché qui optimisent des activités spécifiques grâce aux technologies informatiques. Dans le cas de la santé, par exemple, une longue liste de praticiens individuels est mise en scène pour promouvoir les développements actuels de l'IA (principalement des dispositifs ou des produits de start-ups françaises), mettant en avant leurs avantages pour des individus spécifiques ("patients", "clients"). Il s'appuie sur les voix autoritaires de groupes bien définis de spécialistes (hôpitaux français et centres de recherche sous le contrôle d'institutions nationales), tout en spécifiant des entités de données ("taux de sucre", "insuline", "hormones") qui alimentent les modèles d'IA. Les avantages ainsi mis en avant de ces technologies sevrent aussi de justification face aux risques potentiels, notamment liés à la collecte, à l'utilisation et à la circulation des données médicales personnelles, gérées par de grandes entreprises de technologies de l'information.


Avec une attention similaire aux configurations locales spécifiques, mais axé sur les dénonciations réelles des effets négatifs de la technologie, **le dernier genre (controverses localisées)** ![Matrice des récits médiatiques projetés verticalement sur un axe abstrait/situé et horizontalement sur l’axe de la tonalité critique promesse](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-28-a-17-15-49.png>https://corpora.medialab.sciences-po.fr/contenus/media-genre4.png) offre des arrangements extrêmement riches et structurés. Les récits de ce genre déploient une mise en discussion d’expérimentations locales en France dans les domaines de la justice ou de l’éducation par exemple. Ils rendent compte des rares occasions de transformations politiques concrètes : mettant en scène des collectifs de personnes affectées, associées à des réseaux d'activistes, ils déplient les effets néfastes de la technologie informatique selon des perspectives incarnées et racontent les actions entreprises par ces personnes pour faire évoluer leurs situations (actions légales ou de pression sur l'opinion etc.). 

Par exemple, les controverses autour des technologies algorithmiques simples déployées dans le secteur de l'éducation en France—APB et Parcoursup—ont réussi à organiser un assemblage extrêmement riche et structuré d'une multitude d'entités techniques et d'acteurs concernés (comme en témoignent les extraits ci-contre). Les articles rendent compte des dynamiques et des reconfigurations entre ces entités, par exemple les relations entre créateurs de l'algorithme et le ministère de l'Enseignement supérieur, la demande d'ouverture du code de l'algorithme ou les  actions en justice contre le gouvernement, faisant valoir la loi pour une République numérique de 2016. Cette controverses a articulé autour des préoccupations et des implications pratiques du calcul des modèles algorithmiques et leurs concepteurs, des objectifs d'optimisation, des données utilisées par l'algorithme, des interfaces, des établissements, des victimes et leurs représentants (syndicats étudiants et des associations), ainsi que des agences gouvernementales et administratives.

On constate ainsi que le bas de la martice qui rend compte de systèmes qui se réalisent concrètement et font le récit de systèmes d'IA variés et situés, embarquent avec eux un réseau plus riche et hétérogène d’entités techniques, humaines, de données d’institutions, dessinant des enjeux plus fins que les récits médiatiques dominants. Ils offrent finalement plus de prises pour explorer la complexité des chaines sociotechniques nécessaires au déploiement de ces technologies et permettent un premier recadrage salutaires des problèmes publics de l'IA. 

<br>

## Synthèse de la performativité des quatre genres de récits médiatiques sur l'IA

Le haut de la matrice caractérise les **récits monolithiques**. Les deux genres, *Critiques abstraites* et *Promesses globales*, reconnaissent et diffusent l'existence d'une IA, technologie cohérente et puissante, qui perturbera considérablement la "société" et affectera "l'humanité", que ce soit positivement ou négativement. De plus, tous deux *projettent* des problématiques liées à l'IA, c'est-à-dire que les effets et les conséquences dans le monde sont ici spéculés, anticipés. Ils suscitent à la fois de l'anxiété et de la fascination, sentiments qui, se renforçant mutuellement, agissent sur le cadrage des problèmes et les manières de penser l'IA  avec force (Borup et al. 2006). Dans les récits critiques, les problèmes sont trop souvent abstraits et traduits en un ensemble de principes moraux (Jobin, Ienca, et Vayena 2019), ce qui fait écho aux réglementations "de principes" (Mittelstadt 2019), récemment critiquées, que l'on  retrouve notamment dans les nombreuses chartes éthiques. Une abstraction similaire se manifeste dans les promesses globales : une multitude d'objets technologiques sont prototypés dans lesquels les problèmes sont réduits à des processus de résolution de problèmes, abordés à travers des jeux et des simulations. Les démonstrations spectaculaires organisées par les big palyers de la tech ont surtout pour effet d'attirer les capitaux et de structurer les investissements. Dans ce contexte, la performance est liée à l'économie de la promesse (Joly 2010), légitimant le développement et l'introduction de l'IA dans la société.

Des acteurs humains hautement particularisés émergent lorsque les récits prennent en compte des situations où l'IA est réalisée, lorsqu'elle est intégrée dans des économies spécifiques, des environnements de recherche et industriels, des cadres juridiques et mise entre les mains d'un public. En bas de la matrice, les deux genres de récits fonctionnent de manière opposée, bien que mutuellement constitutifs. L'un vise à persuader l'opinion publique des impacts socio-économiques transformateurs des technologies computationnelles. Cette rhétorique est puissante pour impliquer et aligner les acteurs locaux et les ressources dans la réorganisation active de la vie sociale grâce au développement d'expériences, de prototypes, de versions alpha et de tests, transformant finalement le monde en laboratoire (Marres et Stark, 2020). Mais ces tests fournissent des terrains fertiles à l'émergence de problèmes situés et de controverses locales : ils créent des débordements et donnent naissance aux affaires que l'on observe dans le quatrième genre. Les expériences réelles posent des problèmes à ceux qui ne sont pas impliqués et qui ne bénéficient finalement pas de cette actualisation de l'IA, entraînant des contre-enquêtes qui interrogent le fonctionnement et la constitution des systèmes et d'autres contre-actions, telles que des procès ou des mobilisations.

![Synthèse de la performativité des récits médiatiques de l'IA](https://corpora.medialab.sciences-po.fr/contenus/matrix-2.png)

Les cadrages de l'IA et ses enjeux, tel que définis dans ces genres, sont largement contrôlés par les géants de la technologie et les acteurs médiatiques. Qu'ils mettent en scène l'IA comme une question globale (monolithe IA) ou comme des configurations spécifiques (situations d'IA), l'influence de ces récits est considérable : ils ont le pouvoir d'accorder ou non une existence à des entités et à des arrangements particuliers. 

Chaque genre développe sa propre agentivité à travers des opérations spécifiques : 1) une agentivité morale agissant principalement sur les processus normatifs, 2) une agentivité de légitimation démontrant la puissance de l'IA grâce à des expériences contrôlées, 3) une agentivité de persuasion alignant les acteurs grâce à des tests concrets, et enfin 4) une agentivité politique, contre-agissant à partir d'affaires spécifiques.

En lisant la matrice verticalement, l'analyse des genres suggère également que les enjeux liés à l'IA sont constitués et traités selon deux modalités principales : soit à travers des tests (dans des contextes contrôlés ou dans le monde), soit à travers la réglementation des technologies computationnelles (pour prévenir les risques ou condamner les effets nuisibles). Si la première modalité est principalement à l'initiative des producteurs ou investisseurs de systèmes d'IA, la deuxième engage des parties prenantes plus diverses et se développe principalement dans les arènes politiques. Ces deux modalités sont en concurrence et se configurent en continu dans une action réciproque, réduisant la trajectoire des développements de l'IA à une alternance binaire et asymétrique entre concepteurs et régulateurs, peu satisfaisante.

Ces récits largement répandus créent les principaux cadres qui rendent compte des questions liées à l'IA en France, structurant le domaine de l'IA et stabilisant sa "chose-ité" (Suchman 2023). Cependant, de telles conceptions prédéfinies et limitées offrent peu d'espace pour que d'autres acteurs participent et pour que des bifurcations authentiques adviennent dans le développement des technologies computationnelles. 

Comment développer de nouveaux cadrages et de nouvelles capacités d'agir sur la trajectoire de l'IA ?
<br>
<br>
<br>
<br>

<small>

[Voir la suite de l'enquête <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zM4.5 7.5a.5.5 0 0 0 0 1h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 1 0-.708.708L10.293 7.5H4.5z"/></svg>](/ShapingAI/#les-soucis)

</small>

<br>
<br>
<br>
<br>

"""


[PAGE]
url="/#les-soucis"
nom_de_page="Les soucis de l'IA"
contenu="""

<br>
<br>

![Dispositif d'enquête, composé d'une table de travail, où les documents sont analysés et discutés par les co-enquêteur.ices, surmontée d'une caméra et accompagné d'un écran](https://corpora.medialab.sciences-po.fr/contenus/soucis-intro.png)

# Les soucis de l'IA
---

## Enquête collective et dispositif d'attention

Résolument inscrite dans une sociologie pragmatique (voir par exemple [Cefaï et Terzi, 2012](https://books.openedition.org/editionsehess/19537)), cette enquête est envisagée comme un processus de *valuation* collective ([Musiani, 2011](https://journals.sagepub.com/doi/10.1111/j.1467-954X.2012.02056.x)), c’est-à-dire comme une activité qui revisite, discute, négocie, les valeurs en jeu dans les objets considérés—dans le cas qui nous occupe, il s’agit de chaînes socio-techniques. L’objectif de l’enquête est de ré-ouvrir les futurs sur le devenir de ces assemblages, grâce à un double mouvement : d’une part à travers la formation d’*objets communs*, générés au cours de la description fine de ce qui constitue ces chaînes à partir des pratiques, préoccupations et intérêts de chacun; et d’autre part, par une considération minutieuse des valeurs attribuées aux différentes entités identifiées et à leurs relations. C'est ce processus de valuation, opéré depuis plusieurs points de vue, que les soucis des praticien.nes de l'IA et co-enquêteur.ices de Shaping AI donnent à voir. 
<small>(pour plus de détail sur le concept de *souci*, lire la section [Avoir prise...](/ShapingAI/#avoir-prise).)</small>

> “Un « objet » n’est pas ce qui s’impose au même titre à tout le monde, mais ce qui sert de pivot à une pluralité d’expériences ultérieures. Plus la liberté et les opportunités d’expériences futures sont importantes, plus l’objet constitué est pertinent. (...) Les enquêtes sociales constituent en objet les relations sociales qui leur servent de matériau, la convergence entre activités différentes doit l’emporter sur leur identité.”

— [Joëlle Zask, 2004](https://books.openedition.org/editionsehess/11206?lang=fr)

<br>

**La méthodologie**

---

![Élements pris comme signes d'une forme de réflexivité des praticien.nes - à gauche, un tweet qui parle de la désertion d'un ingénieur data-scientist; à droite, la charte de contribution à la constitution du jeu de données francophone ouvert pour l'IA (PIAF), portée par Etalab.](https://corpora.medialab.sciences-po.fr/contenus/tweets.png)

<details>
<summary>L’enrôlement dans l'enquête de 29 "praticien.nes soucieux.ses"
</summary>

Au-delà de la situation géographique de leurs activités (situées en France), nous avons pris contact avec des personnes qui manifestaient un questionnement ou racontaient leurs tâtonnements face à l’IA, que ce soit dans leur approche du sujet ou sur des aspects concrets, comme l'illustre par exemple ce tweet : *“Hey, I’m conducting a survey to understand how data science teams work with sensitive data! Interested?”*), ainsi que les deux documents ci-contre. 

Nous nous sommes notamment aidés d'une veille reposant sur les connaissances diversifiées de l’équipe sur le sujet, d’une analyse systématique de comptes Twitter et des recommandations des praticien.nes déjà rencontré.es. Nous avons veillé à pluraliser les secteurs d’activités des co-enquêteur.ices : data-science, recherche (tant en maths, IA ou computer science qu’en SHS), journalisme, droit, art, administration publique, syndicalisme et activisme… Nous avons également appliquer ce critère de pluralité à d'autres dimensions : âge, genre, milieux, statuts professionnels, opinions affichées, … 

</details>

 ![Vue du dispositif d'enquête avec les documents accrochés au mur et la table de travail avec sa caméra zénithale. Carrefour Numérique 2, Cité des sciences et de l'industrie, Paris.](https://corpora.medialab.sciences-po.fr/contenus/photo-cite.png) 

<details>
<summary>Description du dispositif <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-search" viewBox="0 0 16 16">
*  <path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"/></svg>
</summary>

Nous avons conçu et testé un dispositif d’enquête qui cherche à **outiller deux opérations principales, la description et la valuation. Comment se rendre attentif à ce qui est, au réel des situations au sein desquelles on agit ? Comment prendre soin de leur description et se rendre sensible à ce que l’on ne dit pas d’elles, ce que l’on occulte ?** Les émotions sont de précieuses informatrices car il s’agit de suivre et d’apprécier la manière dont les différents éléments pris en compte nous affectent. 

Un premier principe du dispositif consiste ainsi à intensifier les expériences vécues pour faire apparaître une scène à décrire et de rendre saillant les aspects problématiques ou préoccupants. De plus, nous cherchions à expliciter les réactions provoquées par l’incertitude et les doutes ressentis, c’est-à-dire déplier les actions entreprises, spéculées ou empêchées dans la recherche d’une bonne conduite et d’en discuter leurs valeurs.

Concrètement, l’enquête collective s’est déroulée en cinq étapes, étalées sur 7 mois : 

**Discussion autour des parcours de vie** de chacun.e des 29 praticien.nes (environ 2h), au cours de laquelle étaient identifiées les expériences vécues dans lesquelles l’IA se concrétise et leurs enjeux. 


**Recherche documentaire**, conduite principalement en ligne. A partir des discussions biographiques, notre équipe a tenté de matérialiser les éléments mentionnés et d'en retrouver des traces tangibles (voir plus bas, le point sur l'archive). Nous avons collectés environ 45 documents par personnes.


**Formulation individuelle des soucis**. Au cours d'une deuxième rencontre à [la cité des Sciences et de l'Industrie](https://www.cite-sciences.fr/fr/au-programme/lieux-ressources/carrefour-numerique2/living-lab/residences-living-lab/shaping-ai), nous avons présenté à chacun.e des co-enquêteur.ices les documents collectés à partir de leur récit biographique. Étalés sur un mur, ces documents ont joué le rôle de support de mémoire mais a été également une aide à la thématisation des soucis. Au cours des entretiens (± 2h), les co-enquêteur.ices ont individuellement trié et sélectionné quelques uns de ces documents, pour formuler et expliciter des *soucis*. Placés sur une table montée d'une caméra, ils sont décrits, commentés ou analysés pour éclairer un ou des aspects des soucis thématisés.


**Composer des soucis**. Les enregistrements vidéo générés au cours des entretiens individuels ont été la matière première d'une analyse thématique des soucis des co-enquêteur.ices. Les manipulations et les gestes associés aux documents sont autant de ressources pour l'analyse que les commentaires oraux. L'analyse a abouti à la création de 19 films (entre 12 et 15 minutes chacun) qui présentent des "soucis collectifs". Ces compositions épaississent vidéo les problèmes de l'intelligence artificielle en montrant à la fois leur variété mais aussi leurs motifs en fonction des pratiques situées des acteur.rices. 

<small>A noter : L'ensemble des matériaux vidéo et documentaire est disponible depuis ce site (voir plus bas : la description des soucis).</small>


**Discuter collectivement pour identifier des problèmes publics et dessiner des prises communes**. A l'issue de ce travail d'analyse, l'intégralité des matériaux et des résultats a été remise en jeu avec les co-enquêteur.ices, au cours d'un workshop en juin 2022 à la Cité des Sciences et de l'Industrie. 23 des 29 co-enquêteur.ices se sont réunis pendant deux jours pour discuter des soucis thématisés et de leur effets en termes de réappropriation des manières de problématiser l'IA pour mieux agir sur ses trajectoires.

</details>

![travail de composition](https://corpora.medialab.sciences-po.fr/contenus/videos.png) 

<details>
<summary>Le rôle de la <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-camera-reels" viewBox="0 0 16 16">
  <path d="M6 3a3 3 0 1 1-6 0 3 3 0 0 1 6 0zM1 3a2 2 0 1 0 4 0 2 2 0 0 0-4 0z"/>
  <path d="M9 6h.5a2 2 0 0 1 1.983 1.738l3.11-1.382A1 1 0 0 1 16 7.269v7.462a1 1 0 0 1-1.406.913l-3.111-1.382A2 2 0 0 1 9.5 16H2a2 2 0 0 1-2-2V8a2 2 0 0 1 2-2h7zm6 8.73V7.27l-3.5 1.555v4.35l3.5 1.556zM1 8v6a1 1 0 0 0 1 1h7.5a1 1 0 0 0 1-1V8a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1z"/>
  <path d="M9 6a3 3 0 1 0 0-6 3 3 0 0 0 0 6zM7 3a2 2 0 1 1 4 0 2 2 0 0 1-4 0z"/></svg> dans le travail de composition
</summary>

L'explicitation des soucis à partir des documents a permis de reconstituer pour chacun des co-enquêteur.ices une série d'opérations concrètes au sein de leurs pratiques avec les affects associés aux processus de valuation en jeu. Le média vidéo donne toute leur place à ces affects, en restituant les étapes de raisonnement dans les voix des co-enquêteur.ices, avec leurs hésitations et leurs couleurs, leurs points d'appui et ce qui les empêche au sein de leurs activités.

A l'aide d'un logiciel de montage, les films pris au cours des entretiens ont été découpés et remontés pour composer les soucis collectifs, donnant à voir pour un même thème la pluralité des perspectives et des prises des co-enquêteur.ices. Ces vidéos sont le matériau de l'analyse : à la manière de la "grounded theory", nous avons cherché itérativement à saturer des thèmes émergents, en juxtaposant des morceaux choisis. Le travail de montage a consisté à faire se répondre des voix autour d'une même problématique, pour la densifier et la complexifier, en cherchant les contrastes et les nuances et en mettant le plus possible en avant la dimension pratique et les actions des acteur.rices.

<small>A noter : Les 19 films sont disponibles sur ce site (voir plus bas : la description des soucis, cliquer sur le détail pour chacun.</small>

</details>

![Distribution des 477 documents de l'archive par type de documents](https://corpora.medialab.sciences-po.fr/contenus/doc-icone.jpg>https://corpora.medialab.sciences-po.fr/contenus/archive.png) 

<details>
<summary> L'archive documentaire, archéologie des prises sur l'IA</summary>

Très utiles dans le travail de constitution des soucis collectifs, les documents ont servi à consolider les thèmes identifiés au cours de l'analyse des vidéos. Plus de 1000 documents ont été récoltés au cours de ce travail d'enquête : ils forment une archive précieuse, soigneusement labellisée. **477 documents, soit près de la moitié de cette archive, ont été associés par les co-enquêteur.ices à des soucis**. 

Ces documents sont centraux pour l'observatoire de la formation et de la circulation des prises, comme en témoigne la visualisation ci-contre. D'une part, ils sont des enregistrements d'actions passées et à ce titre, ils concrétisent des tentatives de prises par certains acteurs et révèlent des opérations spécifiques (visibles au travers des labels de la visualisation, comme par exemple, "tweet", "exposition", "maquette pédagogique" ou encore "tract"). 

D'autre part, les registres de ces documents, témoins de leurs inscriptions sociales et matérielles (par exemple, "sientifique", "pédagogique", "administratif"), font apparaître des médiations privilégiées par les praticien.nes pour agir. De plus, ces médiations mettent en lumière des liens historiques entre certaines pratiques et certains milieux. Elles permettent ainsi de pister la carrière de termes ou de manières de faire mais aussi de mettre à jour des succès de prises, voire des mécanismes d'emprise.

L'analyse de ces documents peut ainsi s'apparenter à une sorte d'archéologie des prises, qui tient compte autant des formats et médiations d'enregistrement que des opérations enregistrées. On constate par exemple que les praticien.nes mobilisent largement des documents issus de sources médiatiques (et dans une proportion importante, issus de la presse). Par ailleurs, les registres scientifique, administratif et analytique sont largement représentés, même si nous verrons que le recours à ces registres, contrairement au registre médiatique, dépend fortement du type des pratiques et des motifs qui les animent.

<small> A noter : cette matière documentaire est disponible, organisée et accessible depuis la description des soucis ci-dessous.</small>
</details>



<br>
<br>

**Les résultats**

---

<small>

1. Une première ligne de partage entre deux motifs du développement technologique : le test et la participation publique

2. Des soucis à 4 motifs (accès aux 19 soucis, avec le détail des vidéos et documents)

3. Discuter et éprouver les soucis collectivement

4. D'autres lignes de partage

</small>

---

## 1. Une première ligne de partage entre deux motifs du développement technologique : le test et la participation publique

![le développement de l'IA, entre tester et participer - Verbatim extraits des vidéos qui présentent ces deux soucis.](
https://corpora.medialab.sciences-po.fr/contenus/participer-tester.png)

Partons d'un cas concret, amené par un co-enquêteur.

En 2020, le Ministère de la Justice annonce l’expériementation d’un algorithme d’évaluation des préjudices corporels à partir d’un traitement automatisé des décisions de justice (DataJust), autorisé par un décret du Premier Ministre et de la Garde des Sceaux. Provoquant une levée de boucliers de la part des professionnels de la justice, cette initiative a été largement décriée et un recours en conseil d’Etat a même été déposé par plusieurs associations. Si le Conseil d’État a validé le décret, le projet d’expérimentation a finalement été abandonné par le Ministère lui-même, faute de capacités (techniques et humaines) pour le mettre en œuvre.

L’histoire de *DataJust* illustre bien les tensions qui existent entre la volonté de tester le potentiel d'innovations d'une part et d’autre part la prise en compte des préoccupations légitimes d'un public qui se sent concerné. Ce cas permet de saisir la dynamique des motivations et des intérêts croisés en jeu dans une situation de développement et fait apparaître l'interaction d'une trajectoire globale avec des contingences locales. 

Notre co-enquête montre que cette tension, manifeste dans la situation de DataJust, est un moteur du développement de l'IA. Deux soucis en rendent compte et dessinent une franche ligne de partage entre deux visions du développement technologique. D’un côté, est mis en avant le souci des *bonnes conditions et bonnes pratiques* d'expérimentation, de l’autre, s’exprime un souci *démocratique* avec une focale sur les asymétries de pouvoirs entre concepteurs, autorités de régulation et citoyens. Ces deux soucis sont construits en miroir, comme les deux faces d’une même pièce, tendues entre une logique d’expérimentation opposée à une participation publique. On retrouve ici la même opposition que dans la [matrice des récits médiatiques](/ShapingAI/#medias), vue précédemment.

<small>Accéder aux matériaux de ces deux soucis </small>
#### [Tester l'IA dans le monde](/ShapingAI/#tester)  |  [Participer à l'IA](/ShapingAI/#participer) 

Dans ces soucis, les co-enquêteur.ices détaillent les prises des uns et la manière dont certaines volontés s’exercent par-delà les protestations d’autres et parfois mêmes par-delà un refus clairement exprimé et largement relayé. Leurs descriptions insistent notamment sur la manière dont le droit commun est continuellement aménagé pour permettre aux entrepreneurs d’expérimenter. Face à l'ouverture d'opportunités de business, la mise en place de “gardes-fous” efficaces pour encadrer les tests semble passée au second plan, trop restrictive, trop coûteuse.

Là encore, l’IA ne fait pas figure d’exception, et de telles configurations asymétriques se répètent dans les développements récents de plusieurs technologies, engendrant des frustrations légitimes. Participer authentiquement aux choix techniques devient une revendication forte d’une partie de la société civile (voir par exemple [les débats sur la 5G dans la CCC](https://propositions.conventioncitoyennepourleclimat.fr/objectif/accompagner-levolution-du-numerique-pour-reduire-ses-impacts-environnementaux/)). Mais ces revendications semblent se focaliser pour le moment sur des arènes politiques, limitant ainsi fortement les marges opératoires et les prises possibles (à quelques exceptions près, voir la vidéo [Participer à l'IA](/ShapingAI/#participer)). Pendant ce temps, les démonstrateurs technologiques, rapidement produits à peu de frais, performent en continu des preuves de leur pertinence et infrastructurent leur devenir.


Il est important de noter que malgré cette opposition et de manière unanime, les co-enquêteur.ices de Shaping AI partagent le constat d’un “déficit de participation”. Ils s'accordent sur les effets problématiques voire délétères de certaines expérimentations, mises en œuvre avec peu de moyen de contrôle et sans qu'aucun mécanisme d'exercice démocratique ne soit prévu, au-delà des mécanismes laborieux de la représentation nationale. Cependant, beaucoup affirment se trouver démunis quant aux formes que pourrait ou devrait avoir un tel exercice démocratique—la participation publique telle que pratiquée par les institutions étant largement critiquée (sur ce point, voir également la section [Avoir prise...](/ShapingAI/#avoir-prise)). 

Comme les récits typiques analysés dans la presse, la configuration des rapports sociaux que la dualité entre tester et participer met en scène laisse insatisfait. Un renouvellement des approches sociologiques semble nécessaire et des travaux comme ceux de Noortje Marres proposent des pistes. Plaidant pour une [sociologie du test](https://onlinelibrary.wiley.com/doi/full/10.1111/1468-4446.12746) qui n'analyse pas les expérimentations de systèmes d’IA comme un passage du laboratoire au monde, mais au contraire, comme réalisant le social. Le social n’est donc pas le “contexte” du développement technologique, c’est le tissu social lui-même qui est mis au test par le développement technologique et il s’agit de comprendre comment il est affecté et transformé par lui, par les modalités et les formes de ces expérimentation. 

**Il apparaît donc que de nouveaux cadrages, c'est-à-dire des nouvelles manières de problématiser l'IA, sont nécessaires pour repenser la participation dans les logiques mêmes des tests qui s'opèrent dans le monde, avec des instances adaptées.**

Commencer à envisager des modalités de participation au sein même des expériementations demande alors de se pencher sur les spécificités des situations de développement et leurs enjeux. C'est ce que les soucis des praticien.nes, avec leurs tentatives et leurs doutes, se proposent de commencer à éclairer.


<br> 
<br>
<br>

---

## 2. Des soucis à 4 motifs  

![Les quatres motifs des soucis de l'IA en France, situés sur le modèle "La boucle de l'IA"](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-15-27-55.png)

Les 17 autres soucis qui ont émergé de notre anayse organise un espace des problèmes de l’IA à partir des activités situées des praticien.nes de l'IA. Cet espace fait apparaître **quatre grands motifs qui sous-tendent ces activités**. Reportés sur la boucle de l’IA, ces motifs fonctionnent comme des lignes de partage praxéologiques qui s’expriment dans les processus de valuation que les co-enquêteur.ices explicitent au cours de l’enquête. **Instituer l’IA, Fabriquer des systèmes, Appréhender l’IA et Disposer un milieu** :  ces motifs sont ce qui *in fine* importe et guide dans l’élaboration de prises. Ces motifs ne décrivent pas des simples intérêts ou idéologies, ils correspondent à des modes opératoires stabilisés dans des milieux spécifiques. 

![Espace des problèmes de l'IA : répartition des 17 soucis de l'IA par motif](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-15-19-54.png) <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-bar-right" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M6 8a.5.5 0 0 0 .5.5h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 0 0-.708.708L12.293 7.5H6.5A.5.5 0 0 0 6 8Zm-2.5 7a.5.5 0 0 1-.5-.5v-13a.5.5 0 0 1 1 0v13a.5.5 0 0 1-.5.5Z"/></svg> Carte des 17 soucis.

**Soucis composés** 
Chacun des soucis rend compte de voix qui expriment les différents motifs. Prenons l'exemple du souci ![Exemple de composition d'un souci - Verbatim issus de nos entretiens](https://corpora.medialab.sciences-po.fr/contenus/travailler-icone.png>https://corpora.medialab.sciences-po.fr/contenus/travailler.png) : la représentation ci-contre illustre que, bien que le souci du travail soit particulièrement prégnant dans les activités motivées par la fabrication de systèmes d'IA (mettant en avant la dimension d'intégration), d'autres activités partagent ce souci en l'abordant différemment et en y attachant des dimensions différentes (conception, résistance, appropriation).

**Les motifs inscrits dans l'archive**

Les documents mobilisés pour expliciter les soucis consolide notre catégorisation en quatre motifs, notamment au regard des registres privilégiés pour les traiter. Si le registre médiatique est présent dans l'ensemble des soucis, le registre scientifique est sans surprise particulièrement utilisé pour *instituer l'IA*, le registre analytique, lui, reposant sur des rapports, livres et essais d'experts, sert plutôt à bien *appréhender l'IA*, et enfin le registre administratif est dominant lorsqu'il s'agit de *fabriquer des systèmes*. Les soucis motivés par la disposition du milieu s'illsutrent quant à eux par le fait de ne privilégier aucun registre particulier.

![Documents mobilisés par les co-enquêteurs oragnisés par motifs et par date de publications.](https://corpora.medialab.sciences-po.fr/contenus/distribution-archive.png)

En considèrant la distribution temporelle de l'archive, on constate une augmentation récente et importante du nombre de documents, surtout depuis 2018. Cependant, aucun motif ne semble sur-représenté par rapport à un autre, même si on constate que les motifs de fabrication et de participation semblent se développer un peu plus tardivement que les autres, jusqu'à devenir aujourd'hui tout aussi denses. 

![les 4 documents mobilisés par le plus grand nombre de co-enquêteurs différents](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-14-38-26.png)

Enfin, en pistant les documents à travers les soucis, des résonnances apparaissent entre les motifs. Parmi les documents les plus cités par les co-enquêteur.ices, on trouve 2 textes de loi, l'un national et l'autre européen, un article scientifique marquant dans le récit de l'IA contemporaine, et un portefeuille de projets portés par la Direction Interministérielle du Numérique, sorte de démonstrateur de ce que peut l'IA pour l'action publique. On retrouve leur présence au sein de différents soucis, comme le montre le schéma ci-contre, ce qui permet de saisir comment certaines prises agissent au croisement de préoccupations variées. Ces circulations dessinent des lignes de force et des alliances entre pratiques et milieux, utiles pour saisir les rapports qu'organisent le développement de l'IA et leurs dynamiques.


<br>
<br>


### Description des soucis
---

<small>Déplier chacun des soucis pour obtenir le détail et accéder aux matériaux de l'enquête (vidéo, documents et synthèse).</small>

![Espace des problèmes de l'IA : répartition des 17 soucis de l'IA par motif](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-15-19-54.png)

### INSTITUTER L'IA

<small>
Un premièr motif correspond aux pratiques de celles et ceux qui cherchent à instituter l'IA dans le champ scientifique. De quoi se soucient les praticien.nes qui cherchent tout à la fois à repousser les limites de leurs connaissances actuelles, à préfigurer des applications pertinentes et à développer des bonnes pratiques ? Quelles résistances leur oppose-t-on et à quelles formes de justification ces résistances donnent-elles lieu ?
</small>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-geo-fill" viewBox="0 0 16 16">
*  <path fill-rule="evenodd" d="M4 4a4 4 0 1 1 4.5 3.969V13.5a.5.5 0 0 1-1 0V7.97A4 4 0 0 1 4 3.999zm2.493 8.574a.5.5 0 0 1-.411.575c-.712.118-1.28.295-1.655.493a1.319 1.319 0 0 0-.37.265.301.301 0 0 0-.057.09V14l.002.008a.147.147 0 0 0 .016.033.617.617 0 0 0 .145.15c.165.13.435.27.813.395.751.25 1.82.414 3.024.414s2.273-.163 3.024-.414c.378-.126.648-.265.813-.395a.619.619 0 0 0 .146-.15.148.148 0 0 0 .015-.033L12 14v-.004a.301.301 0 0 0-.057-.09 1.318 1.318 0 0 0-.37-.264c-.376-.198-.943-.375-1.655-.493a.5.5 0 1 1 .164-.986c.77.127 1.452.328 1.957.594C12.5 13 13 13.4 13 14c0 .426-.26.752-.544.977-.29.228-.68.413-1.116.558-.878.293-2.059.465-3.34.465-1.281 0-2.462-.172-3.34-.465-.436-.145-.826-.33-1.116-.558C3.26 14.752 3 14.426 3 14c0-.599.5-1 .961-1.243.505-.266 1.187-.467 1.957-.594a.5.5 0 0 1 .575.411z"/></svg> 
Définir l'IA </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#definir)

La question du périmètre de l’IA et de sa constitution est au cœur des débats des praticiens. Elle a des conséquences majeures, tant pour la reconnaissance de la discipline de l’IA que d’un point de vue juridique, économique ou culturel. De la défintion de l’IA, de sa constitutuon la plus restreinte à la plus élargie, découle également sa vulnérabilité à la critique. Les intérêts divergents des acteurs se matérialisent dans les géométries variables de l’objet IA qu’ils proposent.

**Documents emblématiques de ce souci**
- Proposition de réglement européen, AI Act (2021)
- Audition de l'OPECST (2017)
- Stratégie Nationale IA (2018)
- article ImageNet (2012)

</details>



<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-file-binary" viewBox="0 0 16 16">
*  <path d="M5.526 13.09c.976 0 1.524-.79 1.524-2.205 0-1.412-.548-2.203-1.524-2.203-.978 0-1.526.79-1.526 2.203 0 1.415.548 2.206 1.526 2.206zm-.832-2.205c0-1.05.29-1.612.832-1.612.358 0 .607.247.733.721L4.7 11.137a6.749 6.749 0 0 1-.006-.252zm.832 1.614c-.36 0-.606-.246-.732-.718l1.556-1.145c.003.079.005.164.005.249 0 1.052-.29 1.614-.829 1.614zm5.329.501v-.595H9.73V8.772h-.69l-1.19.786v.688L8.986 9.5h.05v2.906h-1.18V13h3z"/>  <path d="M4 0a2 2 0 0 0-2 2v12a2 2 0 0 0 2 2h8a2 2 0 0 0 2-2V2a2 2 0 0 0-2-2H4zm0 1h8a1 1 0 0 1 1 1v12a1 1 0 0 1-1 1H4a1 1 0 0 1-1-1V2a1 1 0 0 1 1-1z"/> 
</svg> 
Mettre en données le monde</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#data)

La nécessaire mise en données du monde et les difficultés qui lui sont associées (données de mauvaise qualité, recueil sans consentement, difficulté de suivi et d’identification des biais d’apprentissage, etc.) est un problème bien identifié de l’IA. En plus des aspects éthiques que cette traduction du monde en données implique, ce souci met en lumière les stratégies des acteurs pour parer aux limites que la création de dataset pose en termes scientifiques et à la génération de modèles généralisables. Les impacts sociaux sont pointés avec comme ultime question : faut-il toujours plus de données pour régler ces problèmes ?

**Documents emblématiques de ce souci**
- Stochastic Parrots
- Sensivic / sound Scanner
- Entrepôt des données de santé
- Triage 4.0
- La vie n'est pas donnée


</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-sliders2" viewBox="0 0 16 16">
*  <path fill-rule="evenodd" d="M10.5 1a.5.5 0 0 1 .5.5v4a.5.5 0 0 1-1 0V4H1.5a.5.5 0 0 1 0-1H10V1.5a.5.5 0 0 1 .5-.5ZM12 3.5a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5Zm-6.5 2A.5.5 0 0 1 6 6v1.5h8.5a.5.5 0 0 1 0 1H6V10a.5.5 0 0 1-1 0V6a.5.5 0 0 1 .5-.5ZM1 8a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2A.5.5 0 0 1 1 8Zm9.5 2a.5.5 0 0 1 .5.5v4a.5.5 0 0 1-1 0V13H1.5a.5.5 0 0 1 0-1H10v-1.5a.5.5 0 0 1 .5-.5Zm1.5 2.5a.5.5 0 0 1 .5-.5h2a.5.5 0 0 1 0 1h-2a.5.5 0 0 1-.5-.5Z"/> 
</svg> 
Modéliser</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#modeliser)

Comment bien concevoir un modèle ? Quelles relations entretiennent les modèles avec le monde ? Telles sont les questions au centre de ce souci, qui met en résonnance les travaux des chercheurs en mathématiques et en IA avec des points de vue critiques qui en discutent les limites. 

**Documents emblématiques de ce souci**
- Probabilistic Latent Semantic Indexing
- Objectivité, Lorraine Daston et Peter Galison
- The end of therory (article de Wired)
- Mitigating Unwanted Biases with Adversarial Learning
- On the opportunities and risks of Foundation Models


</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-database-dash" viewBox="0 0 16 16">
*  <path d="M12.5 16a3.5 3.5 0 1 0 0-7 3.5 3.5 0 0 0 0 7ZM11 12h3a.5.5 0 0 1 0 1h-3a.5.5 0 0 1 0-1Z"/>  <path d="M12.096 6.223A4.92 4.92 0 0 0 13 5.698V7c0 .289-.213.654-.753 1.007a4.493 4.493 0 0 1 1.753.25V4c0-1.007-.875-1.755-1.904-2.223C11.022 1.289 9.573 1 8 1s-3.022.289-4.096.777C2.875 2.245 2 2.993 2 4v9c0 1.007.875 1.755 1.904 2.223C4.978 15.71 6.427 16 8 16c.536 0 1.058-.034 1.555-.097a4.525 4.525 0 0 1-.813-.927C8.5 14.992 8.252 15 8 15c-1.464 0-2.766-.27-3.682-.687C3.356 13.875 3 13.373 3 13v-1.302c.271.202.58.378.904.525C4.978 12.71 6.427 13 8 13h.027a4.552 4.552 0 0 1 0-1H8c-1.464 0-2.766-.27-3.682-.687C3.356 10.875 3 10.373 3 10V8.698c.271.202.58.378.904.525C4.978 9.71 6.427 10 8 10c.262 0 .52-.008.774-.024a4.525 4.525 0 0 1 1.102-1.132C9.298 8.944 8.666 9 8 9c-1.464 0-2.766-.27-3.682-.687C3.356 7.875 3 7.373 3 7V5.698c.271.202.58.378.904.525C4.978 6.711 6.427 7 8 7s3.022-.289 4.096-.777ZM3 4c0-.374.356-.875 1.318-1.313C5.234 2.271 6.536 2 8 2s2.766.27 3.682.687C12.644 3.125 13 3.627 13 4c0 .374-.356.875-1.318 1.313C10.766 5.729 9.464 6 8 6s-2.766-.27-3.682-.687C3.356 4.875 3 4.373 3 4Z"/> 
</svg> 
Écologiser</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#ecologiser)

Tiraillés entre performance, économie ou justice, les praticien.nes font ici part de leurs difficultés d’arbitrage au regard des enjeux environnementaux et des pollutions engendrées par l’IA. En filigrane, la question de savoir ce qui compte dans la question écologique apparaît de façon vertigineuse : où s’arrête la chaîne de l’IA et ses effets ? 

**Documents emblématiques de ce souci**
- Anatomy of an AI system
- Conférence AI 4 Climate
- Towards the Systemic Reporting of the Energy and Carbon Footprints of Machine Learning
- Technocritiques, François Jarrige

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-mortarboard" viewBox="0 0 16 16">
*  <path d="M8.211 2.047a.5.5 0 0 0-.422 0l-7.5 3.5a.5.5 0 0 0 .025.917l7.5 3a.5.5 0 0 0 .372 0L14 7.14V13a1 1 0 0 0-1 1v2h3v-2a1 1 0 0 0-1-1V6.739l.686-.275a.5.5 0 0 0 .025-.917l-7.5-3.5ZM8 8.46 1.758 5.965 8 3.052l6.242 2.913L8 8.46Z"/>  <path d="M4.176 9.032a.5.5 0 0 0-.656.327l-.5 1.7a.5.5 0 0 0 .294.605l4.5 1.8a.5.5 0 0 0 .372 0l4.5-1.8a.5.5 0 0 0 .294-.605l-.5-1.7a.5.5 0 0 0-.656-.327L8 10.466 4.176 9.032Zm-.068 1.873.22-.748 3.496 1.311a.5.5 0 0 0 .352 0l3.496-1.311.22.748L8 12.46l-3.892-1.556Z"/> 
</svg> 
Institutionnaliser l'IA</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#institutionnaliser)

Machine Learning et deep learning : discipline académique "sérieuse" ou cuisine d'ingénieurs ? Les retours d'expériences et les analyses discutent la trajectoire d'une discipline en cours de stabilisation dans le paysage académique.

**Documents emblématiques de ce souci**
- La revanche des neurones (Cardon, Mazière et Cointet)
- ImageNet (2012)
- Statistical Modeling : the two cultures
- Les instituts 3IA (stratégie nationale IA)
- MOOC "Deep Learning" (CNAM)

</details>

<br>

### FABRIQUER DES SYSTÈMES

<small>
C'est une dimension moins développée dans la littérature scientifique sur l'IA à ce jour, pourtant la fabrication de systèmes comportent son lot de soucis spécifiques. Occupés à bien intégrer l'IA dans des systèmes d'instrument et des routines préexistantes, les praticien.nes sont confrontés à des questions de passage à l'échelle, de modèles d'affaire, d'infrastructures et de régulation, toutes critiques pour que ces systèmes existent durablement dans le monde. Ces efforts d'intégration, reflets de choix éthiques et politiques, font l'objet de vives controverses et occasionnent des affaires. Ces affaires révèlent à quel point ces pratiques, bien qu'elles aient parfois l'air accessoires ou secondes dans le développement de l'IA, en sont en réalité constitutives : elles l'infrastructurent. 
</small>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-person-bounding-box" viewBox="0 0 16 16">
*  <path d="M1.5 1a.5.5 0 0 0-.5.5v3a.5.5 0 0 1-1 0v-3A1.5 1.5 0 0 1 1.5 0h3a.5.5 0 0 1 0 1h-3zM11 .5a.5.5 0 0 1 .5-.5h3A1.5 1.5 0 0 1 16 1.5v3a.5.5 0 0 1-1 0v-3a.5.5 0 0 0-.5-.5h-3a.5.5 0 0 1-.5-.5zM.5 11a.5.5 0 0 1 .5.5v3a.5.5 0 0 0 .5.5h3a.5.5 0 0 1 0 1h-3A1.5 1.5 0 0 1 0 14.5v-3a.5.5 0 0 1 .5-.5zm15 0a.5.5 0 0 1 .5.5v3a1.5 1.5 0 0 1-1.5 1.5h-3a.5.5 0 0 1 0-1h3a.5.5 0 0 0 .5-.5v-3a.5.5 0 0 1 .5-.5z"/>  <path d="M3 14s-1 0-1-1 1-4 6-4 6 3 6 4-1 1-1 1H3zm8-9a3 3 0 1 1-6 0 3 3 0 0 1 6 0z"/></svg>
Optimiser </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#optimiser)

Les algorithmes des plateformes sont-ils optimisés pour nous ou contre nous ? Comment gagner en pouvoir d'agir quand on utilise ces systèmes ? Face à des risques individuels et collectifs de mieux en mieux connus, relatifs à la manipulation des comportements et à la captation de l'attention, plusieurs pistes de réponses tant juridiques que techniques sont discutés.

**Documents emblématiques de ce souci**
- La formes de choix, Linc/CNIL
- Votre attention s'il vous plaît, CNNum
- Frances Haugen appelle à une régulation de Facebook (New York Times)
- L'économie de l'attention saisie par le droit


</details>

<details>
<summary><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-hdd-network" viewBox="0 0 16 16">
*  <path d="M4.5 5a.5.5 0 1 0 0-1 .5.5 0 0 0 0 1zM3 4.5a.5.5 0 1 1-1 0 .5.5 0 0 1 1 0z"/>  <path d="M0 4a2 2 0 0 1 2-2h12a2 2 0 0 1 2 2v1a2 2 0 0 1-2 2H8.5v3a1.5 1.5 0 0 1 1.5 1.5h5.5a.5.5 0 0 1 0 1H10A1.5 1.5 0 0 1 8.5 14h-1A1.5 1.5 0 0 1 6 12.5H.5a.5.5 0 0 1 0-1H6A1.5 1.5 0 0 1 7.5 10V7H2a2 2 0 0 1-2-2V4zm1 0v1a1 1 0 0 0 1 1h12a1 1 0 0 0 1-1V4a1 1 0 0 0-1-1H2a1 1 0 0 0-1 1zm6 7.5v1a.5.5 0 0 0 .5.5h1a.5.5 0 0 0 .5-.5v-1a.5.5 0 0 0-.5-.5h-1a.5.5 0 0 0-.5.5z"/></svg>
Passer en production </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#produire)

Les ponts entre la recherche académique en IA et l'industrie sont nombreux et épousent différentes formes. Quelles sont les implications des transferts technologiques ? Peut-on être à la fois chercheur et industriel et comment ces différents rôles orientent les choix techniques qui sont faits au cours du développement des systèmes d'IA ? Ce souci pointe les différences fondamentales entre prototypage et production et décrit la manière dont les modèles d'affaire orientent les développements, parfois jusqu'à trahir les ambitions initiales des fondateurs.

**Documents emblématiques de ce souci**
- Liberté & Cie, Quand la liberté des salariés fait le succès des entreprises. (Getz et Carney)
- Les chercheurs de l'INRIA contre leur parton "startupper" (Médiapart)
- Start-up française, Santé et IA (BPI France)

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-person-workspace" viewBox="0 0 16 16">
*  <path d="M4 16s-1 0-1-1 1-4 5-4 5 3 5 4-1 1-1 1H4Zm4-5.95a2.5 2.5 0 1 0 0-5 2.5 2.5 0 0 0 0 5Z"/>  <path d="M2 1a2 2 0 0 0-2 2v9.5A1.5 1.5 0 0 0 1.5 14h.653a5.373 5.373 0 0 1 1.066-2H1V3a1 1 0 0 1 1-1h12a1 1 0 0 1 1 1v9h-2.219c.554.654.89 1.373 1.066 2h.653a1.5 1.5 0 0 0 1.5-1.5V3a2 2 0 0 0-2-2H2Z"/></svg>
Travailler avec de l'IA</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#travailler)

Le futur du travail est une préoccupation prégnante des débats actuels sur l'IA. Les voix ici  décalent la focale temporelle : l'accent est placé à la fois sur les transformations actuelles et sur le temps long, en rappelant comment les rapports sociaux et le travail ont été transformés  par les développements des systèmes d'information et de calcul. Quels sont les effets du découpage de la chaîne de travail tâches toujours plus petites et isolées ? Quels nouveaux rapports à la décision et l'expertise se développent et porteurs de quel sens au travail ? Enfin une critique des rapports de pouvoir est dressée à partir du mythe de la disparition du travail, qui ne date pas de l'IA.
 
**Documents emblématiques de ce souci**
- L'automatisation et le futur du travail
- Human Perceptron, RYBN
- En attendant les robots, Antonio Casilli
- Programme Open Law - travail d'annotation

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-ui-checks" viewBox="0 0 16 16">
*  <path d="M7 2.5a.5.5 0 0 1 .5-.5h7a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-7a.5.5 0 0 1-.5-.5v-1zM2 1a2 2 0 0 0-2 2v2a2 2 0 0 0 2 2h2a2 2 0 0 0 2-2V3a2 2 0 0 0-2-2H2zm0 8a2 2 0 0 0-2 2v2a2 2 0 0 0 2 2h2a2 2 0 0 0 2-2v-2a2 2 0 0 0-2-2H2zm.854-3.646a.5.5 0 0 1-.708 0l-1-1a.5.5 0 1 1 .708-.708l.646.647 1.646-1.647a.5.5 0 1 1 .708.708l-2 2zm0 8a.5.5 0 0 1-.708 0l-1-1a.5.5 0 0 1 .708-.708l.646.647 1.646-1.647a.5.5 0 0 1 .708.708l-2 2zM7 10.5a.5.5 0 0 1 .5-.5h7a.5.5 0 0 1 .5.5v1a.5.5 0 0 1-.5.5h-7a.5.5 0 0 1-.5-.5v-1zm0-5a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5zm0 8a.5.5 0 0 1 .5-.5h5a.5.5 0 0 1 0 1h-5a.5.5 0 0 1-.5-.5z"/></svg>
Instrumenter l'action publique </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#action-publique)

Sonder les soucis des développements de l'IA dans les administrations publiques est particulièrement intéressant pour deux raisons : 1) l'État remplit le double rôle de régulateur de l'IA et de concepteur/utilisateur et 2) les instruments de l'action publique révèlent autant qu'ils performent les politiques publiques. Sans autorité indépendante forte ou autre contre-pouvoir, ce double rôle s'avère dangeureux car les bénéfices projetés à utiliser des systèmes d'IA pour l'action publique peuvent encourager les pouvoirs politiques à autoriser certains développements, au risque de réduire les libertés fondamentales. D'autre part, les différentes administrations sont hétérogènes et leurs pratiques en termes d'instrumentation variables—certaines parlent de communs lorsque d'autres cultivent une culture du secret. Sont aussi questionnées ici les politiques publiques qui fixent le cap vers toujours plus de dématérialisation dans l'action et les services publics, faisant des données un actif stratégique et externalisant une partie non négligeable de ses missions.

**Documents emblématiques de ce souci**
- Loi pour une République Numérique (dite Loi Lemaire-2016)
- Intelligence artificielle et action publique - Etude du Conseil d'État
- Portefeuille de projets, LabIA - Étalab
- Changer de Cap, Dossier le contrôle de la CAF contre les droits
- Grand Plan d'investissement, Fonds pour la transformation de l'action publique

</details>

<br>

### APPRÉHENDER L'IA

<small>
La bonne appréhension, ou l'appréhension efficace, est un motif partagé celles et ceux qui tentent de décrire et/ou de réguler l'IA, et notamment les chercheurs en SHS, les juristes et les artistes. À quoi tient l'IA ? Qu'est-ce que l'IA fait à la société, aux rapports sociaux ? Quels rapports de pouvoir sont institués par sa constitution progressive ? En discutant les manières qu'ils ont d'appréhender l'IA, les praticien.nes déplient les dynamiques dans lesquels les processus de développement technologique sont pris. Pluralisant les perspectives, ils font apparaître un objet IA à géométrie variable, dont les différentes versions révèlent les fronts d'opposition et notamment une dialectique entre une vision critique (politique) et une vision centrée sur l’anticipation et la gestion des risques.
</small>

<details>
<summary><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-book" viewBox="0 0 16 16">
*  <path d="M1 2.828c.885-.37 2.154-.769 3.388-.893 1.33-.134 2.458.063 3.112.752v9.746c-.935-.53-2.12-.603-3.213-.493-1.18.12-2.37.461-3.287.811V2.828zm7.5-.141c.654-.689 1.782-.886 3.112-.752 1.234.124 2.503.523 3.388.893v9.923c-.918-.35-2.107-.692-3.287-.81-1.094-.111-2.278-.039-3.213.492V2.687zM8 1.783C7.015.936 5.587.81 4.287.94c-1.514.153-3.042.672-3.994 1.105A.5.5 0 0 0 0 2.5v11a.5.5 0 0 0 .707.455c.882-.4 2.303-.881 3.68-1.02 1.409-.142 2.59.087 3.223.877a.5.5 0 0 0 .78 0c.633-.79 1.814-1.019 3.222-.877 1.378.139 2.8.62 3.681 1.02A.5.5 0 0 0 16 13.5v-11a.5.5 0 0 0-.293-.455c-.952-.433-2.48-.952-3.994-1.105C10.413.809 8.985.936 8 1.783z"/></svg>
Réguler </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#reguler)

Interrogeant la protection des libertés publiques et l'encadrement des risques liés au déploiement de nouvelles technologies, ce souci pointe les limites et failles du droit. Ces remises en cause opposent ceux qui, du côté de l'application des normes, dénoncent les défaillance de l'effectivité des normes juridiques, à ceux qui, dressant le constat d'une crise plus large des institutions, remettent en cause le droit comme mécanisme de légitimation de progrès technologiques délétères. 


**Documents emblématiques de ce souci**
- Proposition de réglement européen sur l'IA (AI Act)
- Loi Informatique et Libertés
- Code is Law (1999)
- Consultation publique de la CNIL sur les caméras "intelligentes"

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrows-fullscreen" viewBox="0 0 16 16">
*  <path fill-rule="evenodd" d="M5.828 10.172a.5.5 0 0 0-.707 0l-4.096 4.096V11.5a.5.5 0 0 0-1 0v3.975a.5.5 0 0 0 .5.5H4.5a.5.5 0 0 0 0-1H1.732l4.096-4.096a.5.5 0 0 0 0-.707zm4.344 0a.5.5 0 0 1 .707 0l4.096 4.096V11.5a.5.5 0 1 1 1 0v3.975a.5.5 0 0 1-.5.5H11.5a.5.5 0 0 1 0-1h2.768l-4.096-4.096a.5.5 0 0 1 0-.707zm0-4.344a.5.5 0 0 0 .707 0l4.096-4.096V4.5a.5.5 0 1 0 1 0V.525a.5.5 0 0 0-.5-.5H11.5a.5.5 0 0 0 0 1h2.768l-4.096 4.096a.5.5 0 0 0 0 .707zm-4.344 0a.5.5 0 0 1-.707 0L1.025 1.732V4.5a.5.5 0 0 1-1 0V.525a.5.5 0 0 1 .5-.5H4.5a.5.5 0 0 1 0 1H1.732l4.096 4.096a.5.5 0 0 1 0 .707z"/></svg>
Performer le social </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#performer)

L’analyse historique et sociale des développements informatiques fait apparaître des visions du social qui ont présidé / président à la fabrication des techniques de calcul et qui y sont incorporées. Loin d’être cantonnées au milieu des *computer sciences*, ces visions imprègnent aussi les questions et débats des sciences sociales (cognition, socialisation, apprentissage, construction des représentations) et des sciences politiques (organisation politique, instruments d’état, rapports à la norme, etc.). L’expansion de l’automatisation peut aussi être comprise comme la tentation d’une personnalisation/ adaptation située de la prescription (juridique, de travail etc.) grâce au calcul—rattachable au concept de gouvernementalité et à l’expansion des bureaucraties.

**Documents emblématiques de ce souci**
- The Master Algorithm, P. Domingos
- Patterns of Life, Julien Prévieux
- IA et réforme de l'État : vers des bureaucraties sans humains ? Félix Tréguer
- Do categories have politics ? Lucy Suchman

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-crosshair" viewBox="0 0 16 16">
*  <path d="M8.5.5a.5.5 0 0 0-1 0v.518A7.001 7.001 0 0 0 1.018 7.5H.5a.5.5 0 0 0 0 1h.518A7.001 7.001 0 0 0 7.5 14.982v.518a.5.5 0 0 0 1 0v-.518A7.001 7.001 0 0 0 14.982 8.5h.518a.5.5 0 0 0 0-1h-.518A7.001 7.001 0 0 0 8.5 1.018V.5Zm-6.48 7A6.001 6.001 0 0 1 7.5 2.02v.48a.5.5 0 0 0 1 0v-.48a6.001 6.001 0 0 1 5.48 5.48h-.48a.5.5 0 0 0 0 1h.48a6.002 6.002 0 0 1-5.48 5.48v-.48a.5.5 0 0 0-1 0v.48A6.001 6.001 0 0 1 2.02 8.5h.48a.5.5 0 0 0 0-1h-.48ZM8 10a2 2 0 1 0 0-4 2 2 0 0 0 0 4Z"/></svg>
Critiquer</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#critiquer)

Quels sont les rôles possibles de la critique face aux dévloppements de l'IA ? Sur quelles bases produire une critique et avec quelle efficace ? Des productions de chercheurs et essayistes sont passées en revue et décrites du point de vue des lectures et des prises qu'elles proposent pour penser l'IA et au regard des effets qu'elles produisent. Et au-delà d'une production critique, comment mobiliser face aux enjeux que la critique révèle ?

**Documents emblématiques de ce souci**
- Data Feminism, C. d'Ignazio et L. Klein
- Algorithms of Oppression, S. Noble
- Merci de changer de métier, C. Izoard
- Agir dans un monde incertain, Callon, Lascoumes et Barthe

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-search" viewBox="0 0 16 16">
*  <path d="M11.742 10.344a6.5 6.5 0 1 0-1.397 1.398h-.001c.03.04.062.078.098.115l3.85 3.85a1 1 0 0 0 1.415-1.414l-3.85-3.85a1.007 1.007 0 0 0-.115-.1zM12 6.5a5.5 5.5 0 1 1-11 0 5.5 5.5 0 0 1 11 0z"/></svg>
Ouvrir les boîtes noires </summary>

#### [Voir la fiche de ce souci](/ShapingAI/#enqueter)

Comment mener des enquêtes sur les technologies en cours de développement ? L'IA étant décrite comme une boîte noire dont les processus de production et le fonctionnement sont opaques, des chercheurs et des artistes mettent au point de nouvelles manières d'enquêter sur les systèmes d'IA. Ces nouvelles méthodes ne poursuivent pas les mêmes objectifs : production de preuves, développement d'une contre-expertise, ouverture de nouvelles trajectoires de développement ou renouvellement des formes de relation aux dispositifs d'IA, les finalités abordées renouvellent le répertoire des modalités d'action avec ou contre les systèmes d'IA.

**Documents emblématiques de ce souci**
- Algotransparency
- Exposing AI, Adam Harvey
- Human Computers - timeline, RYBN
- Myriad Tulips, Anna Ridler
- Deep Visual Instruments, Mehmet Akten

</details>

<details>
<summary><svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-chat-right-dots" viewBox="0 0 16 16">
*  <path d="M2 1a1 1 0 0 0-1 1v8a1 1 0 0 0 1 1h9.586a2 2 0 0 1 1.414.586l2 2V2a1 1 0 0 0-1-1H2zm12-1a2 2 0 0 1 2 2v12.793a.5.5 0 0 1-.854.353l-2.853-2.853a1 1 0 0 0-.707-.293H2a2 2 0 0 1-2-2V2a2 2 0 0 1 2-2h12z"/>  <path d="M5 6a1 1 0 1 1-2 0 1 1 0 0 1 2 0zm4 0a1 1 0 1 1-2 0 1 1 0 0 1 2 0zm4 0a1 1 0 1 1-2 0 1 1 0 0 1 2 0z"/></svg>
Justifier </summary>
Ici un petit résumé et le lien vers le souci en question.

#### [Voir la fiche de ce souci](/ShapingAI/#justifier)

Comment sont décidés les développements de systèmes d'IA ? Comment arbitrer pour savoir si on doit ou non s'engager dans de tels projets ? Ce souci qui habite les praticien.nes lorsqu'ils participent au développement de systèmes d'IA contraste deux types de justifications : l'une morale et l'autre utilitariste. Une troisième voie pointe l'enjeu démocratique que pose ce souci, notamment en décalant la focale sur des dimensions politiques ou esthétiques.

**Documents emblématiques de ce souci**
- The City of Broken Windows, Hito Steyerl
- Portfolio de l'association Data for Good
- On the morality of AI, Luccioni et Bengio
- Ils ont quitté le secteur de la tech pour entreprendre dans le public - article sur les Entrepreneurs d'intérêt général (EIG)

</details>

<br>

### DISPOSER UN MILIEU

<small>
Les technologies d'IA n'adviennent pas dans un vide, elles prennent place dans des milieux qu'elles contribuent à transformer et qui les transforment à leur tour, dans une action réciproque. Ainsi certaines pratiques ont le souci d'aménager un milieu, en anticipation de ce couplage, pour lui projeter un sens. Le motif de disposition d'un milieu apparaît dans des activités qui ont trait à la formation de cultures et de normes communes, agissant comme vecteurs de sens et déterminants des développements futurs.
</small>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-fast-forward" viewBox="0 0 16 16">
*  <path d="M6.804 8 1 4.633v6.734L6.804 8Zm.792-.696a.802.802 0 0 1 0 1.392l-6.363 3.692C.713 12.69 0 12.345 0 11.692V4.308c0-.653.713-.998 1.233-.696l6.363 3.692Z"/>  <path d="M14.804 8 9 4.633v6.734L14.804 8Zm.792-.696a.802.802 0 0 1 0 1.392l-6.363 3.692C8.713 12.69 8 12.345 8 11.692V4.308c0-.653.713-.998 1.233-.696l6.363 3.692Z"/></svg>
Futurer</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#futurer)

Comment sont construits les récits qui mettent en scène l’intelligence artificielle ? Quels éléments sont mis en avant ? Et quels buts servent-ils ? Les rhétoriques de l’innovation mobilisées dans le cas de l'IA sont analysées du point de vue de leur performativité, à la fois comme stratégie d’enrôlement d'acteurs et de capitaux mais aussi comme moteurs des horizons de développement technologique. L'élaboration de récits plus critiques et de contre-récits, tentant de dessiner d'autres trajectoires, est un souci pour les praticien.nes.  


**Documents emblématiques de ce souci**
- La French Tech
- Work hard, Have fun, Make history - slogan Amazon
- Computing Machinery and Intelligence, A. Turing
- IA vecteur de simplicité et d'efficacité pour le service public
- L'IA AlphaGo bat une nouvelle fois le champion du monde de go (article Le Monde)

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-bank2" viewBox="0 0 16 16">
*  <path d="M8.277.084a.5.5 0 0 0-.554 0l-7.5 5A.5.5 0 0 0 .5 6h1.875v7H1.5a.5.5 0 0 0 0 1h13a.5.5 0 1 0 0-1h-.875V6H15.5a.5.5 0 0 0 .277-.916l-7.5-5zM12.375 6v7h-1.25V6h1.25zm-2.5 0v7h-1.25V6h1.25zm-2.5 0v7h-1.25V6h1.25zm-2.5 0v7h-1.25V6h1.25zM8 4a1 1 0 1 1 0-2 1 1 0 0 1 0 2zM.5 15a.5.5 0 0 0 0 1h15a.5.5 0 1 0 0-1H.5z"/></svg>
Valoriser</summary>
Synthèse des enjeux relatifs à la chaîne de valeur de la donnée, depuis leur création jusqu’à leur exploitation, avec une attention particulière sur les conditions de leur circulation et les frictions auxquelles elles peuvent donner lieu. Ce souci est marqué par des questions juridiques (régulations sur les données - européenne, française), économiques (GAFAM versus petites entreprises; public versus privé; communs numériques) et politiques (redistribution de la valeur; mandats et rôle de l’état…).

#### [Voir la fiche de ce souci](/ShapingAI/#valoriser)

Comment les chaînes de valeur des données qui se développent affectent les rapports sociaux ? Les reconfigurations engendrées par ces nouvelles chaînes de valeur (depuis la création des données jusqu’à leur exploitation) sont mises en débat, avec une attention particulière aux conditions de leur circulation et aux frictions auxquelles elles peuvent donner lieu. Ce souci est marqué par des questions juridiques (régulations sur les données - européenne, française), économiques (GAFAM versus petites entreprises; public versus privé; communs numériques) et politiques (redistribution de la valeur; mandats et rôle de l’état…).

**Documents emblématiques de ce souci**
- L'open data des décisions de justice
- Circulaire anti-Doctrine
- Partenariat entre l'AP-HP et le Health Data Hub
- Feuille de route 2020-2022 du Ministère de l'économie et des finances
- La plateforme d'une ville

</details>

<details>
<summary> <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-person-fill-gear" viewBox="0 0 16 16">
*  <path d="M11 5a3 3 0 1 1-6 0 3 3 0 0 1 6 0Zm-9 8c0 1 1 1 1 1h5.256A4.493 4.493 0 0 1 8 12.5a4.49 4.49 0 0 1 1.544-3.393C9.077 9.038 8.564 9 8 9c-5 0-6 3-6 4Zm9.886-3.54c.18-.613 1.048-.613 1.229 0l.043.148a.64.64 0 0 0 .921.382l.136-.074c.561-.306 1.175.308.87.869l-.075.136a.64.64 0 0 0 .382.92l.149.045c.612.18.612 1.048 0 1.229l-.15.043a.64.64 0 0 0-.38.921l.074.136c.305.561-.309 1.175-.87.87l-.136-.075a.64.64 0 0 0-.92.382l-.045.149c-.18.612-1.048.612-1.229 0l-.043-.15a.64.64 0 0 0-.921-.38l-.136.074c-.561.305-1.175-.309-.87-.87l.075-.136a.64.64 0 0 0-.382-.92l-.148-.045c-.613-.18-.613-1.048 0-1.229l.148-.043a.64.64 0 0 0 .382-.921l-.074-.136c-.306-.561.308-1.175.869-.87l.136.075a.64.64 0 0 0 .92-.382l.045-.148ZM14 12.5a1.5 1.5 0 1 0-3 0 1.5 1.5 0 0 0 3 0Z"/></svg>
Individuer</summary>

#### [Voir la fiche de ce souci](/ShapingAI/#individuer)

Description d’une danse, d’un mouvement de va-et-vient, entre la production de dispositifs algorithmiques et la production des subjectivités à travers l’appropriation des ces dispositifs. Les notions d’autonomie (tant comme concept juridique que philosophique) et de normativité sont centrales et mettent l'accent sur la constitution des milieux d'individuation par la technique.


**Documents emblématiques de ce souci**
- Avis N°3 du Comité National Pilote d'Éthique du Numérique : Agents conversationnels
- Comment le droit numérique peut-il réguler la crise de l'attention (colloque)
- Sensivic (fiche produit d'un sound scanner)
- Algoglitch
- Period-tracking app are not for women

</details>

<br>
<br>
<br> 
<br>

![Images du workshop - Juin 2022, cité des sciences et de l'industrie, Carrefour Numérique2](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-06-a-16-43-36.png)

## 3. Discuter et éprouver les soucis collectivement

---


En juin 2022, un workshop a réuni les co-enquêteur.ices de Shaping AI pendant deux journées. Cette session de travail collectif a été l'occasion de présenter les soucis pour discuter leur découpage et leur pertinence.

**Quel décalage proposent les soucis par rapport aux problèmes publics de l'IA ?
De quels effets sont-il porteurs quant au renouvellement des formes de participation au développement de l'IA ?**

Au cours de cette session et avec ces questions en tête, les co-enquêteur.ices ont retravaillé par groupe de 3 et sous forme de vidéo, 7 des 19 soucis, choisis collectivement ![Les 7 soucis travaillés pendant le workshop avec les co-enquêteur.ices](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-29-a-09-59-47.png). Ce choix témoigne de l'importance des enjeux présents dans ces 7 soucis par rapport à l'ensemble de la cartographie. Tous les motifs sont représentés dans cette sélection, même si on constate une sur-représentation du motif "instituer l'IA". 
Non présent sur la carte, le souci de la participation a aussi fait l'objet d'une réécriture intéressante, soulignant la nécessité de repenser les rapports entre calculs, calculateurs et calculés. 

Le processus d'élaboration de ces nouvelles versions a permis d'éprouver, amender, affiner et densifier encore les problèmes de l'IA, confrontant des perspectives plurielles. Donnant lieu à de riches discussions, parfois aussi à de vives oppositions, les co-enquêteur.ices ont pu mettre à l'épreuve les prises avec lesquelles ils et elles forment l'IA au quotidien, ouvrant la voie à des alliances et des ouvertures souhaitables.

<small> Note : Une analyse fine de la reformulation des soucis est en cours de préparation dans le cadre du travail de thèse d'Axel Meunier.</small>

<br>
<br>
<br>

## 4. D'autres lignes de partage
---

Les matériaux recueillis et les arguments développés par les co-enquêteur.ices se prêtent à d'autres analyses, qui, bien qu'elles ne font pas l'objet de cette publication, pourraient être s'avérer génératives dans d'autres contextes (par exemple, de médiation). 

On remarque par exemple que les perspectives des co-enquêteur.ices sont fortement divisés en fonction du type de rapports qu'ils font importer dans leur processus de valuation. Nous avons  entamé un travail pour qualifier et représenter ces rapports. ![Types de rapports qui importent dans les proessus de valuation](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-16-56-10.png>https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-16-56-10.png). Dans cette représentation, les paires oppposées travaillent par antagonisme.

Cependant, si ce type de représentation permet une lecture d'ensemble intéressante, celle-ci n'est pas à confondre avec le plan des développements concrets. Contrairement aux soucis et aux prises qu'ils laissent poindre, il paraît difficile d'activer une telle analyse sur les représentations et les valeurs des acteurs pour penser des formes de participation différentes aux développements de l'IA.

<br>

<small>

[Lire l'étude de cas <svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-right-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zM4.5 7.5a.5.5 0 0 0 0 1h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 1 0-.708.708L10.293 7.5H4.5z"/></svg>](/ShapingAI/#cas)

</small>


<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>
<br>

.
"""

[PAGE]
url="/#cas"
nom_de_page="Un système d'IA"
contenu="""

![Document d'arpentage](https://corpora.medialab.sciences-po.fr/contenus/document-d-arpentage.jpeg)

<br>
<br>

# Enquêter à partir d'un cas : IA, territoire et fiscalité

<br>

> Aujourd'hui, on a des géomètres qui vont sur le terrain et qui font un lever précis du bâtiment, dans une interaction entre l'agent et le terrain. Demain, c'est un mode de représentation à partir de l'exploitation des prises de vue aériennes.  Donc là c'est vraiment deux modes de représentation qui viennent s'opposer. 

— F., chef du Bureau du Cadastre

---

<br>

Nous poursuivons l'enquête en analysant finement les soucis liés aux transformations générées au cours de la conception et l'introduction d'un système d'IA spécifique dans un cas précis : le recours à l’intelligence artificielle (IA) dans les opérations de mise à jour du cadastre et du calcul de l’impôt. Instrument foncier et fiscal de premier ordre, le cadastre est un mélange d’opérations topographiques et administratives sans cesse revisitées, co-constitutives des manières de tenir compte du territoire et de son occupation. Depuis la Révolution et Napoléon, le dessin du cadastre est réalisé, non sans mal, à partir d'un arpentage systématique de toutes les communes de France, opéré par des géomètres. Aujourd’hui, la Direction Générale des Finances Publiques (DGFiP), héritière de ce mandat, décide d’utiliser des techniques de reconnaissance d’image automatisées sur des photos aériennes ![Entraînement et tests d'un modèle de détection de formes automatisée sur une image aérienne](https://corpora.medialab.sciences-po.fr/contenus/detection.png). 

**Quelles nouvelles opérations, entités et agencements sont mis à l’épreuve quand ces techniques automatisées tiennent compte du territoire ? Quels soucis émergent de ces transformations pour les praticien.nes impliqué.es ?**

<br>

## Le projet *Foncier Innovant* au Bureau du Cadastre

Au printemps 2023, les agents des Finances Publiques en charge du recouvrement des taxes foncières se préparent : le nombre de contentieux à traiter risque bien d’exploser du fait d’une expérimentation à grande échelle d’un système de détection automatisée de piscines ![Capture d'écran de l'interface de détection - vue vectorielle / vue image aérienne](https://corpora.medialab.sciences-po.fr/contenus/pastille-piscine.png). Ce système est réputé d’une aide efficace pour repérer les cas de fraude et améliorer les bases de données du fisc, mais les contribuables pourraient bien être nombreux à contester la présence d’une piscine dans leur jardin. De telles erreurs de prédictions se nomment des faux positifs dans le jargon de la science des données. Au même moment, les porteurs du projet semblent confiants et dressent déjà un bilan qui ne laisse place à aucune remise en cause. Forts des premiers retours sur 9 départements, ils entendent bien pousser l’expérimentation plus loin, en détectant d’autres objets tels que des bâtiments isolés ou des extensions de bâti, avec en ligne de mire la mise à jour automatique des plans cadastraux.

Jusqu’à aujourd’hui, le dessin des bâtiments et autres objets sur les plans cadastraux relevait des missions et de la compétence de géomètres, fonctionnaires de la fonction publique, présents dans tous les départements et rattachés aux trésoreries. Organisant leurs tournées quotidiennes à partir des informations transmises aux mairies par les contribuables, les géomètres pratiquent des levées de terrain. Ces mesures précises permettent de reporter au plan les constructions nouvelles et de tenir à jour les données du cadastre. Ils utilisent des outils de mesure numériques, parmi lesquels des GPS, des télémètres laser et des applications numériques qui ont remplacé progressivement les chaînes d’arpentage, le papier et le crayon. 

Le projet baptisé *Foncier Innovant* porté par Bercy et financé par la DITP (Direction interministérielle de la Transformation Publique) est une initiative pensée dans une large série de trasnformations des pratiques du Trésor Public. Son objectif est de transférer l’essentiel de cette mission de mise à jour des données cadastrales à un système automatisé. Sur la base de réseaux de neurones entraînés à reconnaître certains objets sur des photos aériennes, ce système pointe aux géomètres les incohérences dans les bases de données du fisc, à l’aide de pastilles. L’expérimentation de ces nouvelles techniques, sans concertation ni formation préalable des personnels, provoque la crispation des agents—et en premier lieu, des agents géomètres—relayée par l’ensemble des syndicats de la Direction générale des Finances publiques.

Le chef du Bureau du Cadastre en convient, il s’agit d’un changement profond qui demande une réorganisation des missions et des services : 

“On est un peu sur une *révolution*, sur une transformation profonde de nos missions et de nos métiers. Et tout ça à un instant T, on fait tout en même temps. En fait, la dématérialisation, le recours à l'IA—ou à une technologie innovante au sens large—pour identifier les biens qui doivent faire l'objet d'une nouvelle évaluation, les biens qui doivent faire l'objet d'une représentation graphique sur le plan… tout ça arrive au même moment. Et donc socialement, sociologiquement, ça a des impacts assez massifs sur l'organisation du travail, sur les missions au quotidien. Et tout ça arrive, entre guillemets un peu brutalement.” 

<br>

### Méthodologie d'enquête 

Une première phase d'enquête à consister à réunir de la documentation disponible sur le projet ainsi qu'à mener une série d'entretiens avec des personnes directement concernées. Parmi elles, nous pouvons citer les porteurs de projet à la DGFiP, des représentants syndicaux, des agents-géomètres, ainsi que des personnes travaillant à l'IGN et à la CNIL.
En complément, nous nous sommes également entretenu avec des personnes travaillant sur des objets proches et notamment des juristes et chercheurs en STS.

Ces éléments nous ont permis de dresser une cartographie des entités assemblés et de saisir les dynamiques de leurs interactions.

Poursuivant notre effort participatif, nous avons réuni 10 praticien.nes concerné.es lors d'un workshop qui s'est déroulé fin novembre 2022. L'objectif de ce workshop était double. D'une part, il s'agissait de discuter des soucis que cette chaîne socio-technique fait émerger du point de vue des différentes parties prenantes. D'autre part, nous souhaitions que cette discussion aboutisse à l'identification d'un travail collectif pour tenter de faire évoluer les situations problématiques identifiées.


<br>
<br>

## Décrire la chaîne socio-technique du projet *Foncier Innovant*
---

Le projet *Foncier Innovant* est décrit par ses concepteurs comme une optimisation du processus de détection des constructions ou aménagements non déclarés, à lutter plus efficacement contre les anomalies déclaratives et répondre ainsi aux principes d'équité et de justice fiscale des citoyens.
Le schéma ci-dessous donne une représentation des tâches et du fonctionnement du système ![Slide issue d’une présentation officielle du projet Foncier Innovant. Séminaire IA, « Imagerie aérienne et report au plan » organisé par la délégation à la transformation numérique de la direction générale des Finances publiques (DTNum), 29 juin 2022.](https://corpora.medialab.sciences-po.fr/contenus/capture-de-cran-2023-09-26-a-20-00-13.png>https://corpora.medialab.sciences-po.fr/contenus/design-process.png), tel que le concoivent les porteurs du projet. 

Ce modèle de tâches réduit la complexité de la chaîne socio-technique nécessaire pour que le système existe à six étapes principales, faisant intervenir un agent machine pour la détection puis un agent humain pour la vérification. 
![Slide issue d’une présentation officielle du projet Foncier Innovant. Séminaire IA, « Imagerie aérienne et report au plan » organisé par la délégation à la transformation numérique de la direction générale des Finances publiques (DTNum), 29 juin 2022.](https://corpora.medialab.sciences-po.fr/contenus/comparaison-agent-IA.png) 
Cette simplification permet d'évaluer la pertinence du système socio-technique en comparant seulement la performance à la sortie : est-ce que les tâches de détection sont exécutées de façon satisfaisante par la machine, quand on compare les résulats entre une opération manuelle et une opération automatique ? 


Or, ce seul critère de performance est insatisfaisant pour évaluer ce système. **Il convient de prendre en compte l'ensemble de la chaîne soci-technique induite par un tel déploiement pour juger des transformations qu'il provoque.** Ainsi, à l'aide de nos entretiens et d'une base documentaire variée, nous avons tenté de repeupler toute la chaîne en nous aidant là encore du modèle de la boucle des pratiques de l'IA. 

Ce travail de reconstitution permet de mettre au jour la grande complexité qui préside à la mise en place d'un projet de ce type au sein d'une administration publique comme la DGFiP. 
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-bar-right" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M6 8a.5.5 0 0 0 .5.5h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 0 0-.708.708L12.293 7.5H6.5A.5.5 0 0 0 6 8Zm-2.5 7a.5.5 0 0 1-.5-.5v-13a.5.5 0 0 1 1 0v13a.5.5 0 0 1-.5.5Z"/></svg>![documents récoltés au cours de l'enquête](https://corpora.medialab.sciences-po.fr/contenus/documents01.png) Au-delà du travail technique sur les modèles et leur performance, on retrouve des processus législatifs, économique et politiques qui demandent l'engagement de nombreux acteurs et un contexte propice, rendu possible par des processus d'infrastructuration et d'acculturation au long court.
<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-bar-right" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M6 8a.5.5 0 0 0 .5.5h5.793l-2.147 2.146a.5.5 0 0 0 .708.708l3-3a.5.5 0 0 0 0-.708l-3-3a.5.5 0 0 0-.708.708L12.293 7.5H6.5A.5.5 0 0 0 6 8Zm-2.5 7a.5.5 0 0 1-.5-.5v-13a.5.5 0 0 1 1 0v13a.5.5 0 0 1-.5.5Z"/></svg>![documents récoltés au cours de l'enquête](https://corpora.medialab.sciences-po.fr/contenus/documents02.png) Souvent sous-considéré, une dimension importante est relative à l'intégration de ce système dans des chaînes opératoires déjà instrumentées, transformant à la fois le travail des agents mais également les relations entre l'administration et ses administrés. 


<br>

### La carte de la chaîne socio-technique du projet *Foncier Innovant*
![Carte](https://corpora.medialab.sciences-po.fr/contenus/carte-dgfip-DEF-05.png)

La carte touffue des entités assemblées dans cette chaîne, qui s'élabore au fur et à mesure de l'enquête, sert une fois encore plutôt de point de départ pour éprouver les soucis que ces nouveaux assemblages génèrent. Que déplacent-ils ? Quelles dynamiques sont mises en œuvre et qui affectent-elles ?
C'est ce que le volet participatif de cette enquête à tenter d'éclaircir.

> On voit bien qu'il y a tout un écosystème qui se développe, dont le but est de changer en fait des relations existantes par d'autres.

– H., journaliste

<br>
<br>
<br>

![workshop](https://corpora.medialab.sciences-po.fr/contenus/layer-1.png)

## Les soucis des praticien.nes concerné.es
--- 

Chacun des praticien.nes présent.es lors du workshop a fait valoir des soucis associés au projet *Foncier Innovant* depuis un prisme singulier. Pour mettre à jour ces prismes et bien saisir les préoccupations de chacun, nous avons d'abord posé la question : comment en est-on arrivé là ? C'est-à-dire, quels sont les évènements marquants et signifiants qui font que le projet *Foncier Innovant* existe aujourd'hui ? Des lignes de temps sont alors apparues sur des empans temporels très différents et avec des saillances contrastées. 

### Synthèse des prismes des praticien.nes :
- Modernisation de l’action publique
- Théorie politique et fonction publique
- Economie politique de la donnée et digital labour
- Politiques publiques environnementales
- Techniques d’ingénierie géomatique
- État et numérique

<br>

![carte annotée](https://corpora.medialab.sciences-po.fr/contenus/layer-0.png)
A partir de la reconnaissance de ces différents prismes, les soucis de chacun ont été dépliés dans un dialogue par binôme, avant d'être discutés collectivement. La carte a servi de médiation à la fois pour identifier et densifier les éléments problématiques et pour restituer les soucis.

<br>
<br>

### Le souci du travail
---
![Entreprise sous-traitant l’annotation de données, Tana, Madagascar - Crédits : Clément Le Ludec, Maxime Cornet, 2022](https://corpora.medialab.sciences-po.fr/contenus/click-workers.png)


- Pas de disparition mais un déplacement et une invisibilisation du travail
• rapport d'exploitation d'une main d'œuvre étrangère peu qualifiée
• qualité du travail d'annotation et l'élaboration d'une vérité terrain robuste

> On peut faire l'hypothèse que la qualité, elle vient aussi d'une qualité des conditions de travail. Donc en fait, ce souci, il est à la fois en termes de conditions de travail, mais aussi d'un point de vue technique.

– C., sociologue

"Ces éléments là, on les a aussi identifiés lorsqu'on a déployé le projet et on s'est dit : mais comment on va répondre à ces sujets là qui sont extrêmement prégnants ? Et est ce que nous, on peut y répondre en interne ?"
– F., chef du bureau du cadastre


> Finalement, entre les agents de la DGFiP et les travailleurs de Madagascar, il y a un enjeu de rendre visible cette chaîne, de rendre visible le process. 

- L'exclusion des travailleurs dans les processus de conception (opacité des processus de développement et des choix de conception)
- Transformations des missions et perte de sens au travail

> Ce qui est vachement compliqué pour nous, c'est de voir ce qu'on fait actuellement comme boulot dehors. Est-ce qu'on doit continuer à être sérieux ? À respecter les tolérances ? Vu qu'ils veulent nous remplacer par des machines qui ne marchent pas très bien, derrière il y aura du plan de qualité et des choses de très mauvaise qualité. On est en train de douter du sens de notre travail.

– B., géomètre

> Quels sont les rapports de pouvoir qui sont naturalisés par l'intelligence artificielle ? Qui sont pris comme évident parce que allant avec l'intelligence artificielle qui doit être mise en place ? Nous, à l’IGN, il y a l'idée que l'intelligence artificielle sert de justification au fait qu'on va pouvoir diminuer des effectifs et donc qu'elle sert d'instrument à ça. 

– M., cadre à l'IGN

<br>
<br>

### Le souci des savoirs critiques et de la souveraineté de l'état
---

> Il y a l'idée que si on ne met l'IA pas en place, nous administration, alors d'autres le feront à la place de l'administration avec un rapport de pouvoir qui est la menace plus ou moins forte d'externalisation. Et donc un risque de disruption : qu'un autre acteur prenne complètement la place de la puissance publique.

– M., cadre à l'IGN

<br>
<br>


### Le souci du monde-laboratoire
---

> Si on fait un peu l'autopsie de ce cas là, finalement, on en vient rapidement à se demander pourquoi il y a un modèle d’IA dans ce cas d'application. (...)  Les données aériennes de l'IGN qui sont produites tous les quatre ans, elles sont traitables à la main en fait, assez rapidement et pour beaucoup moins que 20 millions. (...) Est ce que ce n'est pas un truc qui s'auto-justifie ? Est ce que toute cette construction là ne tient pas plus au fait de justifier le modèle que réellement d'aller taxer des piscines ? Et donc, est ce que ce n'est pas juste parce que c'est un cas d'application simple à mettre en avant ? 

— M., sociologue

<br>
<br>

### Le souci de la relation à l'usager
---
![](https://corpora.medialab.sciences-po.fr/contenus/carte-dgfip-data-valo.png .png)
**L'usager de la donnée**

On parle de nouveaux "couloirs de valorisation de la donnée".

“À la DGFIP, on était souvent des producteurs un peu brut de la donnée. (...) 
Je m'interrogeais assez peu sur pourquoi j'acquiers et comment je peux améliorer cette acquisition et comment je peux mettre en qualité la donnée, comment je peux la valoriser, la croiser. C'est un peu des questions nouvelles que l'on se pose.”
(F., chef de bureau du cadastre)


![](https://corpora.medialab.sciences-po.fr/contenus/contentieux.png)
**L'usager contribuable**

- diminution de la relation directe aux contribuables
• fermeture de nombreuses trésoreries 
• arrêt de la participation des géomètres aux commissions communales des impôts directs
 
- le contribuable-contributeur
- visibilisation du service public

“Et ça permettait aussi aux propriétaires de voir qui on était, parce qu'il y en a qui ne comprenaient pas pourquoi on passait. Et je prévenais la commune qui faisait un affichage. On prévenait les communes à peu près quinze jours avant d'y aller et après on allait tout mesurer. Si les gens avaient des doutes, on montrait notre carte professionnelle, mais globalement, on était plutôt bien accueillis chez les particuliers. Et puis, ils aiment bien quand ils comprenaient qu'on leur montrait. Vous voyez, votre maison n'est pas sur le plan, on vient juste la mesurer pour qu'elle y soit et on repart. On n'est pas rentré, enfin on rassurait.”

- renversement de la charge de la preuve ?


"""

[PAGE]
url="/#participer"
nom_de_page="Souci 0.1"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Participer à l'IA

>“Et de voir ceux qui parlent au nom d'un problème et travaillent à constituer le problème.” 

— D., Sociologue

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<br>

### Résumé.
Comment avoir prise sur le développement des technologies d'intelligence artificielle ? Ce souci montre à quel point les instances actuelles sont insatisfaisantes et révèle les difficultés de penser des mécanismes au delà de ceux de la représentation ou de la consultation à des fins de régulation.

### Thèmes abordés.

**Instances de démocratie technique** Injonction à faire de la participation publique et des consultations publiques pour impliquer des citoyens dans les décisions de développement au-delà des mécanismes déjà en place comme le Parlement ou le Sénat. Mais depuis la convention citoyenne pour le climat, vu comme du “participation washing”. La question de l'expertise nécessaire pour participer est soulevée.

**Fabriquer des publics** Médiations pour rendre sensible aux calculs (sensibilité peu élevée). Devenir porte-parole d'une cause est un travail de ventriloquie : il faut travailler à constituer le problème avant qu’il puisse exister et être porté.

**Relations sciences-société** Débats et dispositifs avec la société civile (forum de consensus etc.) : quelle posture des sciences sociales ?

**Empowerment** Il faut qu'un maximum de gens soient capables de fabriquer et développer les techno pour plus de démocratie. Incubateur d’initiatives citoyennes ou asso comme Data for Good ? Quid de ces initiatives si elles ne vont pas dans le sens des politiques mises en œuvre par le gouvernement (empêcher les oppositions par le truchement des financements notamment).

**Désertion et luttes** La désertion professionnelle (lieux de travail / lieux de pouvoir) est revendiquée comme une voie désirable par certains ingénieurs ou jeunes professionnels qui refusent de participer par leur travail au développement de ces technologies, voyant que leurs actions sont limitées par un cadre et leur revendication non prises en compte. La lutte (action directe, sabotage matérielle, etc.) est envisagée devant l’inefficacité et l'inaudibilité des discours d'opposition.

**Crise démocratique** Au-delà de la seule question de l'IA, une sérieuse défaillance des institutions est pointée comme problème majeur, rendant les développements de technologies d'information, coercitives en plus d'être polluantes, préoccupantes.

**Développer des rapports sensibles à la technologie** pour agir : mais limites → part actionnable concrètement au sein de communautés de pratiques ? Prise de vitesse par les géants (GAFAM)...

<small>

**Entités mentionnées**
textes, juristes, experts, questionnaire, représentation citoyenne, Parlement Européen, spectateur novice, médiation, collectif, quotidien professionnel, hiérarchie, visibilité, prises, citoyens, recherches en sciences sociales, Latour, JB Fressoz, conférences de consensus, Ulrich Beck, instances de démocratie technique, réflexivité, modernes, CNIL, débat, communiqué, rapport, consultation, processus de légalisation, accompagnatrice de l’innovation, cycle néo-libéral, La Quadrature du Net, luttes, personnes précarisées, notations, discours politique, technophobes, élite éclairée, sensibilité au calcul, troubles, problèmes publics, groupes d’utilisateurs, institutions, associations, porte-parole, ventriloque, accélérateur d’initiatives citoyennes, wikis, blogs, communautés de pratiques, GAFAM, design fiction

</small>

<iframe src="https://player.vimeo.com/video/720020019?h=f54e634a3b" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

---
Une deuxième version a été créée lors du workshop de Juin 2022

---

### Les documents (58)
##### 0

"""

[PAGE]
url="/#tester"
nom_de_page="Tester l'IA dans le monde"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Tester l'IA dans le monde

> “Il y a toujours un cadre expérimental qui permet de lever les barrières.”

— E., Journaliste

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---
<iframe title="vimeo-player" src="https://player.vimeo.com/video/720019742?h=1cdca0e2bb" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>


### Résumé.
L'IA se réalise à travers des expérimentations concrètes qui prennent place dans le monde et alignent des acteurs variés aux motivations convergentes. Une puissante force de convergence semble résider dans la recherche de moyens de contrôle et de répression plus efficaces, ce qui amène à remettre en cause certaines libertés publiques fondamentales. Par ailleurs, pour se déployer, les expérimentations ont besoind d'aménager des cadres réglemetaires qui dérogent au droit commun, ce qui appelle à une extrême vigilance et nécessite des contre-pouvoirs avec des moyens d'évaluation importants, qui à ce jour font défaut. De nombreux praticien.nes, cherchant à alerter sur ces dangers, sont inquiets de voir ces questions méprisées.

### Thèmes abordés.

**Expérimentation a priori; encadrement a posteriori** La fabrique de la loi trop lente par rapport à la fabrique de prototypes. Justification pratique : il est préférable de de tester pour bien encadrer avec une prise en compte des situations spécifiques par le développement agile (production de connaissances utiles à l’élaboration de régulations).

**Stratégies d’enrôlement par la sécurité et le contrôle** Lobby puissant à partir de besoins sécuritaires, policiers ou budgétaires. Ces portes d'entrée sont efficace et permettent de suspendre le droit commun et d'utiliser des régimes d'exception pour stabiliser une industrie (exemple des JO ou du COVID). Utilisation de l’open data pour analyse des besoins comme stratégie enrôlement. Risques importants d’effets-cliqué (l’exception devient la règle) et de la banalisation de techniques/lois liberticides. La répression de la fraude est aussi une application qui aligne de nombreux acteurs. 

**La réglementation européenne répond à une logique de mise en conformité / produits défectueux (case-based)** : elle soutient le développement et la régulation d’un marché intérieur (orienté produits), avec une tendance à pousser l’innovation européenne pour concurrencer les autres puissances.

**Droit souple (pro-innovation) et autorité administrative indépendante** Respect des droits fondamentaux tant que cela n’élimine pas le business. Il faut une autorité avec des moyens pour contrôler, réglementer, accompagner. Trop de régulation risque de freiner l’IA ?

**Modalités d’expérimentation** : évènements (hackathon), formation et animation de communautés, preuves de concept, démos. il y a eu d'importants processus d'évangélisation dans les administrations ou les entreprises avec des rôles dédiés (ex. EIG). Questions des ressources humaines importantes pour passage à l’échelle. 

**Droits de regard et recours** : Difficultés d’accès à l’information quant au développement / expérimentations de systèmes d’IA (opacité administrative / secret des affaires) et il y a un besoin de répertorier les initiatives. Le parlement doit donner son aval pour qu'une expérimentation puisse déroger au droit, suivi d'un décret si modifications de la loi. Citoyens ont aussi des droits de recours, mais difficiles à mettre en œuvre. La CNIL a des difficultés pour traiter les dossiers et ne rend des avis souvent seulement consultatifs.

**Question de l’évaluation des projets d’IA** : à qui cela bénéficie, comment on évalue les coûts et bénéfices ? Qui doit être associé à la chaîne de conception et d’évaluation ? Une fois les projets lancés, il semble qu’ils ne soient jamais remis en question de toute façon. → effet cliqué

<small>

**Entités mentionnées**
le droit, caméras, mecs dans la sécurité, PSU, mecs à capuche nord-africains, maire, bus, vélo, carrefour, Suez, administrés, JO2024, Cédric O, Parlement Européen, état d’urgence, UE, Think H+, hackathon, ministère de la Justice, EIG, Parlement (Ass. Nationale), APB/Parcoursup, citoyens, INSEE, DGFiP, Lemaire, agent.es, CNIL
</small>

<br>

### Les documents (52)
##### 3.2


"""



[PAGE]
url="/#definir"
nom_de_page="Définir l'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Définir l'IA

> “Il y a un peu de tricherie dans la constitution publique de l'IA qui profite à tout le monde.”

— D., sociologue

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720016297?h=2816a0d5a9" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
La question du périmètre de l’IA et de sa constitution est au cœur des débats des praticiens. Elle a des conséquences majeures, tant pour la reconnaissance de la discipline de l’IA que d’un point de vue juridique, économique ou culturel. La constitution de l’IA en définit les prises potentielles également et donc sa vulnérabilité à la critique. Les intérêts divergents des acteurs se matérialisent dans les géométries variables de l’objet IA qu’ils proposent.

<br>

### Thèmes abordés.

**Débat scientifique sur l’objet**, limité ou non à l’apprentissage automatique ? Rejoue la controverse symbolique / connexionniste de manière actualisée (de toute façon, le ML/DL s’intègre à des algorithmes et autres logiques (théorie des jeux, SMA, systèmes experts…). Risque de déception (nouvel hiver ?) si limité à seulement apprentissage automatique.

**Entretien de la confusion pour financements** La confusion entre IA connexionniste et symbolique a été entretenue notamment par les institutions de recherche par rapport aux pouvoirs publics (notamment pour des questions de financement). Aussi dans les réponses d’appel à projets etc. buzzword IA utilisé pour remporter des appels. A créé un décalage de perception important. 

**Imaginaires de l’IA** puisent dans l’IA symbolique (ancienne IA): imaginaire plus fourni (films, science-fiction)  et réflexions/médiatisation (même juridiques) encore dirigées par les concepts symboliques (ontologie de la machine etc.)

**Une notion qui fait débat en droit et qui a des effets** Lois et réglement IA (UE) s’appuient sur des définitions extensives. Définition des systèmes à haut risques (réglementation contraignante) âprement négociée. Nécessité de cohérence entre les notions définies dans les différents textes. Lobbys importants (business + nationaux) pour influencer le travail de rédaction du texte européen. Réglementation sectorielle préférée par beaucoup d’acteus (invalidation de l’objet IA).

**Approches critiques pour se débarrasser de cet objet** Nommer autrement (ex. pattern recognition / économie de la donnée), se débarrasser des récits antiques. Redéfinir en situant historiquement, ce qui permet une critique différente en élargissant la focale de ce qui est en jeu (forme d’organisation des sociétés complexes / informatisation).

**Volet industriel/économique peu mis au centre** alors que premier : Internet est devenue une industrie totale et globale. Somme d’objets qui s’aggrègent avec le temps pour former une “économie des données”.

<br>

<small> 

**Entités mentionnées**
Assemblée Nationale, IA Act, House of Mirrors (exposition), Légifrance, IA à haut risque, IA symbolique, IA connexionniste, DITP, DGS, web 2.0

</small>

<br>

### Les documents (26)
##### 1.1


"""

[PAGE]
url="/#data"
nom_de_page="Mettre en données le monde"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Mettre en données le monde

> “Pour moi, un changement d'échelle, c'est en soi un changement de sujet.”

— S., éditrice et membre d'Open Law

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720018171?h=94b2e66687" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
La nécessaire mise en données du monde et les difficultés qui lui sont associées (données de mauvaise qualité, recueil sans consentement, difficulté de suivi et d’identification des biais d’apprentissage, etc.) est un problème bien identifié de l’IA. En plus des aspects éthiques que cette traduction du monde en données implique, ce souci met en lumière les stratégies des acteurs pour parer aux limites que la création de dataset pose en termes scientifiques et à la génération de modèles généralisables. Les impacts sociaux sont pointés avec comme ultime question : faut-il toujours plus de données pour régler ces problèmes ?
<br>

### Thèmes abordés.

**Travailler avec des grands volumes de données** De nouvelles techniques d’IA s'élaborent (stochastic gradient descent / adversarial) et tentent de remédier à la reproduction des biais statistiques du dataset. La performance des modèles semble être dépendante du volume de données. Mais acquérir toujours plus de données est-il la bonne solution ? Cette direction apporte son lot de nouveaux soucis (problèmes d’optimisation, surveillance, gouvernance par la donnée etc.)…

**Rapport à la généralisation** Il existe une croyance selon laquelle plus le jeu de données est gros, plus le modèle va bien généraliser :  si il y a peu de données en fait, on a peu de moyens de contredire une certaine règle qui ne serait pas générale. Une voie alternative de recherche s'intéresse aux biais inductifs d’apprentissage et aux propriétés des collections de documents avec une focale sur la causalité plutôt que la corrélation. 

**Extraction, exploitation et circulation des données** par les plus en capacité de le faire, sans nécessairement savoir la qualité des données, leur provenance, leur mode de production etc.  Certains travaillent à des manières plus constructives de faire des jeux de données (participative, contrôlée, documentée…). Les question de documentation et de consentement sont centrales. 

**Logique de tests, accélération et effets délétères** Des expérimentations sont menées trop vite dans la vraie vie sans vérification ou attention soutenue aux données. Cela entraîne des discriminations sociales et effets concrets sur la vie des gens (ex. triage 4.0). Faut-il récolter plus de données pour éviter les effets de bord des systèmes d’IA ? Quelle est la solution au mauvais calcul ? Est-elle technique (plus de données, des techniques plus optimisées) ou politique ? 

**Génération de données** comme solution pour augmenter les petitx volume de données (ex. jeux de données non-alignés, données synthétiques, etc.) Mais l'application des modèles entraînés sur des données synthétiques sur des données réelles ne donnent pas des résultats toujours satisfaisants. Importance de valider les modèles sur des données réelles (données synthétiques, données contrôlées (propres) et données réelles (sales)).

**Problèmes politiques de la catégorisation** Réductionnisme et fixation. Comment adapter et interprétater les catégories en fonction du contexte ? Comment laisser ouvert et négociable la définition des catégories?

**Relocalisation, mise au service de communautés** Peut-on envisager des développement à petites échelles et situés, sur des données maîtrisées de bout en bout avec une élaboration concertée des tâches et objectifs ?


<br>

<small> 

**Entités mentionnées**
ADN, communautés, calcul, catégories, Etats-Unis, africains-américains, Kate Crawford, Data Feminism, documents, modèles, corrélation, causalité, dataset, chercheurs, chien, chat, sport, poids du réseau, biais, adversaire

</small>

<br>

### Les documents (45)
##### 1.2

"""

[PAGE]
url="/#modeliser"
nom_de_page="Modéliser"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Modéliser

> “Il n'y a pas de modèle qui imbrique le monde.”

— K., artiste

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720012499?h=3746eed9f8" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Comment bien concevoir un modèle ? Quelles relations entretiennent les modèles avec le monde ? Telles sont les questions au centre de ce souci, qui met en résonnance les travaux des chercheurs en mathématiques et en IA avec des points de vue critiques qui en discutent les limites. 

<br>

### Thèmes abordés.

**Prendre le modèle pour le monde (ou la carte pour le territoire)** Illusion de la représentation et risques à penser qu’un modèle mathématique produit avec le réel un ensemble de relations harmonieuses. Causalité versus Corrélation : les corrélations permettent de mieux prédire et la causalité permet de mieux généraliser. Fin de la théorie comme slogan qui porte à confusion. Il n’y pas de modèle qui imbrique le monde et on a besoin d'ausculter les modèles lorsqu’ils interagissent avec le monde..

**Formalisme des mathématiques et de la modélisation** jeu qui s’affranchit du monde réel pour poser ses propres contraintes, maîtrisées (cf. jeu d’échecs, Alpha Go). Recherche de l’élégance, dirigée par la forme. Fuite des problèmes compliqués / du réel. Questions applicatives et risques/décalages non prises en compte ou seulement tardivement. 

**Statistique des modèles versus machine learning** Partir d’hypothèses sur les données pour construire un algorithme ou au contraire j’étudie l'algorithme et les données ne sont plus des variables aléatoires mais sont déterministes (points et non distribution).

**Les effets des classifications dans le réel** Conséquences dans des applications de la vie de l’automatisation des classifications et évolution/négociation des catégories (ex. de la chaise - le sol devient chaise si on s’assoit dessus ?). Traduction par des recherches sur dimensionnalité et normalité : adaptation aux contextes et calcul par rapport aux variations passées.

**Avantages et limites des modèles** Un système automatisé détecte toujours de la même façon, très efficace et puissant lorsque appliqué à des domaines restreints, mais incapacité à sortir du contexte. Modèle fonctionne dans un certain cadre avec des hypothèses de départ. Prédictions très aléatoires lorsque sortie du domaine et variations du contexte. Difficultés pour dire si on est confiant sur les sorties du modèle.


<br>

<small> 

**Entités mentionnées**
modèles, algorithmes, étudiants, Oxford, réel, notions, équations, scientifiques, polarisation, dimensions, catégories, système de combat, avion/drône, Daston, santé, artiste, humains, data scientists, contexte, marchés financiers

</small>

<br>

### Les documents (37)
##### 1.3

"""

[PAGE]
url="/#ecologiser"
nom_de_page="Écologiser l'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Écologiser l'IA

> “On va se dire : c'est une seule personne, elle utilise 100 GPU...”

— A., chercheur en IA

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720018824?h=074189ee25" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Tiraillés entre performance, économie ou justice, les praticien.nes font ici part de leurs difficultés d’arbitrage au regard des enjeux environnementaux et des pollutions engendrées par l’IA. En filigrane, la question de savoir ce qui compte dans la question écologique apparaît de façon vertigineuse : où s’arrête la chaîne de l’IA et ses effets ? 

<br>

### Thèmes abordés.

**Que doit prendre en compte une approche écologique de l’IA ?** De la consommation énergétique à la chaîne complète de production (depuis les mines jusqu’aux décharges), les praticien.nes discutent ceux sur quoi elles ont la main : 1) la conso des modèles, 2)  la question des infrastructures techniques (cloud, serveurs…), 3) la santé et la justice des humains et de l’environnement.

**Rapport coûts / bénéfices et arbitrages** Comment savoir et décider, arbitrer entre développer ou ne pas le faire ? Les questions sont traitées à partir des différents environnements de travail (GAFAM, recherche, administrations, start-up, usines) et de vie ce qui amène des réponses différentes. Des micro-gestes (prendre l’avion pour aller en conférence) aux politiques publiques.

**Enjeux de valeurs** Notions d'ouverture (open source) et de démocratisation comme justification et moyens d'arbitrage.

**Limites de production (de données, de micro-puces) et souveraineté numérique**

**Gestions de contraintes techniques au quotidien** limites de mémoire, droit des données perso., doctrine CLOUD, dimensionnement des serveurs…

**Sensibiliser aux enjeux environnementaux du numérique** Question de mesures : construction d’indicateurs et de bonnes pratiques. Dommage car trop peu valorisé dans la recherche académique ou l’indicateur premier reste la performance.



<br>

<small> 

**Entités mentionnées**
Alexa, geste, énergie, minerai, infrastructure, travail, décharges, semi-conducteurs, performance, GPU, humain, CO2, terminaux, bande passante, Claude Shannon, industrie, Meta, licence, serveurs, DINUM, Etalab, Cloud, Hub, Health Data Hub, OVH, AP-HP, cluster, AI4Climate, chercheurs, Processed World, ouvrières latinos, Technocritiques

</small>

<br>

### Les documents (34)
##### 1.4

"""
[PAGE]
url="/#institutionnaliser"
nom_de_page="Institutionnaliser l'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Institutionnaliser l'IA comme discipline

> “La seule chose que vous savez, c'est qu'il y a un modèle qui est certainement responsable de ça.”

— P., chercheur en statistiques computationnelles

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720018961?h=cb8de0eb0e" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Machine Learning et deep learning : discipline académique "sérieuse" ou cuisine d'ingénieurs ? Les retours d'expériences et les analyses discutent la trajectoire d'une discipline en cours de stabilisation dans le paysage académique.

<br>

### Thèmes abordés.

**Un changement de paradigme** de la culture des modèles à la culture des algorithmes : partir de jeux de données pour rechercher un modèle mathématique qui explique sa création et maximiser des fonctions de ressemblance, au lieu de partir d’hypothèses mathématiques. Changement du rapport au calcul : pas vu comme une suite d’opérations logiques mais de distribution de forces entre des nœuds. Choc de 2012 — d’abord avec une épreuve dans le monde de l’image, avec l’arrivée de ImageNet, entérine et légitime ce renversement du rapport entre les deux cultures, malgré les critiques qui restent fortes chez certains mathématiciens et statisticiens.

**Consolidation progressive de méthodes à partir de plusieurs champs disciplinaires (applications)** : méthodes (réseaux de neurones ou pas) finalement peu centrales dans la construction de l’IA par rapport à la force de l’image d’intelligence. Notamment dans le
Transformations des formations et embauches : nombreux sont les chercheur.euses qui, déjà en poste, ont vu se développer les techniques d’IA et se sont formés sur le tard via des MOOCs (Stanford, MIT, FUN…). Mais lors des embauches, les

**Le deep learning, beaucoup de "cuisine" évaluée à la performance** Difficultés liées à l’explicabilité de ce que font les algorithmes. Itérations un peu à l’aveugle et partages de résultats empiriques dans les communautés de recherche.

**Transformations des pratiques académiques vers des pratiques d’ingénierie** Diffusion de librairies off the shelf, valorisation de nouveaux outcomes (logiciels, librairies, code, jeux de données…), déplacement nécessaire des manières de reviewer / évaluer. Va avec des postes d’ingénieur de recherche prisés (culture/mémoire institutionnelle, bonnes pratiques) et formation des doctorants à ces bonnes pratiques.

**La culture des institutions de recherche standardise les approches d’IA** culture du formalisme et de l’élégance et développement de gros modèles, challengeant du point de vue mathématiques. Peu de places aux discours et pratiques alternatives, plus légères ou situées.


<br>

<small> 

**Entités mentionnées**
statistiques computationnelles, mathématiques, modèle, données, probabilités, Rumelhart, Hinton, gradient stochastic, Rosenblatt, calcul, distribution, forces, nœuds, sérieux, équations, cultures (de recherche), hypothèses, algorithme, machine learning, PhD students, ingénieurs de recherche, écoles/formations, tests, logiciel, collègues, reviewers, inférence, zeitgeist, grosses têtes de laboratoires, Nature/Science, PI, Github, codes, formats, projets, IRCAM, INRIA, élégance, puissance

</small>

<br>

### Les documents (43)
##### 1.5

"""


[PAGE]
url="/#optimiser"
nom_de_page="Optimiser les sytsèmes d'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Optimiser les sytsèmes d'IA

> “Aujourd'hui, ce dont nous sommes exclus, c'est d'être présents dans ces systèmes.”

— H., journaliste

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720019131?h=1f0f6b9a63" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Les algorithmes des plateformes sont-ils optimisés pour nous ou contre nous ? Comment gagner en pouvoir d'agir quand on utilise ces systèmes ? Face à des risques individuels et collectifs de mieux en mieux connus, relatifs à la manipulation des comportements et à la captation de l'attention, plusieurs pistes de réponses tant juridiques que techniques sont discutés.


<br>

### Thèmes abordés.

**Conséquences des techniques d’optimisation des performances des algorithmes** Conception de fonctions d’utilité, fonctions objectif, et de calcul des coûts pour maximiser les résultats des algo, notamment algo de recommandation (de Maps à YouTube et TikTok). Calcul jamais simple ou trivial : implique beaucoup de choix dans la définition des critères pertinents (écologiques, économiques, sociales…). Mesurer l’écart entre deux algorithmes en soit peut être modélisé mathématiquement selon des méthodes différentes qui chacunes ont des implications et incorporent des orientations.

**Les critères d’optimisation dépendent des modèles d’affaires des plateformes/réseaux sociaux** business modèles reposent sur la nécessité de capter l’attention et d’inciter, avec un aspect adversarial et une tendance à diriger vers des contenus sensationnels/impressionnants. Inquiétudes assumées lorsque produits / services étrangers (surtout chinois) mais peu remis en question lorsque occidental.

**Redonner du pouvoir d’agir aux utilisateurs** Nécessité de sensibiliser → avoir conscience de la contrainte qui s’exerce sur les utilisateurs. 
• Intervenir par le design → enjeux des dark patterns et de la non-efficacité de la mise en conformité car non respect des droits des utilisateurs dans les interfaces elles-mêmes (cf. la forme des choix du LINC). Pouvoir d’agir se joue à l’endroit du design des interfaces autant que dans les normes juridiques. Enjeux aussi de co-design, implication des utilisateurs dans la conception des services et interfaces (“pas pour nous, sans nous”).
• Intervenir par des régulations → Notion de jouabilité ou droit au paramétrage : pouvoir tester et choisir les paramètres de calcul pour les services. Question de la portée de ces droits (cf. droit à la portabilité)

**Micro-targeting / personnalisation** Diminution de la liberté d'opinion, de conscience, de culture des gens qui sont visés par le service, sorte de pluralisme diminué. Implications individuelles mais aussi collectives, par exemple l’orientation politique.

**Responsabilisation des opérateurs** Mettre en place des audits sur les mécanismes de captation de l’attention et faire des politiques publiques de l’attention. Quid de l’attention collective et des enjeux politiques ? Notion juridique de loyauté (dommage collectif) pourrait trouver à s’appliquer ici, aussi pour les processus collectifs, en réponse à des techniques d’incitation / nudge automatisé.



<br>

<small> 

**Entités mentionnées**
fonction objectif, réseaux sociaux, algorithme, Youtube, TikTok, droits fondamentaux, utilisateur, Facebook, la Fing, attention protection officer, LINC (CNIL)

</small>

<br>

### Les documents (27)
##### 3.3


"""


[PAGE]
url="/#produire"
nom_de_page="Passer en production"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Passer en production

> “Ça c'est le moment critique qui fait qu'on se spécialise.”

— C., chercheur en IA, start-upper

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720019237?h=416a0c384c" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Les ponts entre la recherche académique en IA et l'industrie sont nombreux et épousent différentes formes. Quelles sont les implications des transferts technologiques ? Peut-on être à la fois chercheur et industriel et comment ces différents rôles orientent les choix techniques qui sont faits au cours du développement des systèmes d'IA ? Ce souci pointe les différences fondamentales entre prototypage et production et décrit la manière dont les modèles d'affaire orientent les développements, parfois jusqu'à trahir les ambitions initiales des fondateurs.

<br>

### Thèmes abordés.

**Tension entre travail de recherche (générique) et développement de produits (spécifique)** Motivation à travailler sur des mathématiques et des modèles poussés multi-usages, avec des applications dans domaines très variés. Relation ambigue entre généralisation et performances spécifiques : les deux aspects se nourrissent dans l’IA (“Avec des problèmes concrets on arrive à faire les bons algorithmes. Avec les bons algorithmes on résoud les problèmes.”). 

**Choix d’une spécialisation et modèle d’affaires** Les choix sont guidés par les opportunités d’affaires qui se présentent et la définition/conception progressive d’un produit. Témoignages de démarrages de startup autour d’algo qui pouvaient servir à plein de use-cases et explicitations des décisions itératives vers une restriction de plus en plus forte des domaines d’activité (spécialisation). Pose la question des recrutements (profils complémentaires qui petit à petit orientent l’ADN de la boîte).

**Plateformes de partage de modèles entraînés** Ouverture du code permet la réutilisation et la “démocratisation”.

**Division de la chaîne de production** Difficultés pour “petits” players ou administrations d’aller au bout de la production - POC ou début de production mais pas de produit véritablement finalisé. Etalab avec le programme EIG démarre des chaînes de production au sein des administrations mais nécessité ensuite d’internaliser des équipes pour poursuivre la production et maintenir. Dans beaucoup de cas, nécessité d’avoir un tiers privé qui opère pour le compte des administrations (qui achètent des licences ou autre). Les montages avec les universités fonctionnent beaucoup comme ça : les labos développent les modèles, des entreprises se créent et se saisissent de la technologie pour la “packager” aux besoins d’une administration / d’un ministère.

**L'offre des start-ups face à celles de grands groupes** Travail important pour convaincre des  clients (notamment acteurs publics, ex. hopitaux) car services chaque fois spécifiques. 

**Relations étroites entre monde académique et monde économique** Beaucoup de chercheurs lancent des startups à partir de leurs recherches (spin-off). Les universités et écoles ont des incubateurs spécialisés (cf. Agoranov). Dans l'échantillon de co-enquêteur.ices, la moitié ont un pied dans la recherche et un pied dans l’industrie.

**Effets de modes et cycles de “produits” en vogue** Tension entre le secret des affaires et la culture de publication de la recherche, qui rend obsolète certaines techniques - car elles ne doivent leur valeur qu’à leur secret (ex. sentiment analysis sur Twitter).
<br>

<small> 

**Entités mentionnées**
Facebook AI Research (FAIR), chercheurs, industries pharma, hopitaux, Agoranov, Start-ups, EIG, étalab, Cour de Cassation, Hugging Face, ministère de la Recherche, argent, Louis Vuitton, l’Armée, NavalGroup, Terega, iAdvize, algorithmes (online learning), domaine/spécialité, ingénieurs, clients, investisseurs, pôle marketing, corrélation, performances, modèles d’affaires, Palantir

</small>

<br>

### Les documents (39)
##### 3.1


"""


[PAGE]
url="/#travailler"
nom_de_page="Travailler avec l'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Travailler avec l'IA

> “À partir du moment où la machine devient plus rapide que les humains, à ce moment là ils sont mis au rebus.”

— K., artiste

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720018455?h=240141e50b" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Le futur du travail est une préoccupation prégnante des débats actuels sur l'IA. Les voix ici  décalent la focale temporelle : l'accent est placé à la fois sur les transformations actuelles et sur le temps long, en rappelant comment les rapports sociaux et le travail ont été transformés  par les développements des systèmes d'information et de calcul. Quels sont les effets du découpage de la chaîne de travail tâches toujours plus petites et isolées ? Quels nouveaux rapports à la décision et l'expertise se développent et porteurs de quel sens au travail ? Enfin une critique des rapports de pouvoir est dressée à partir du mythe de la disparition du travail, qui ne date pas de l'IA.

<br>

### Thèmes abordés.

**Tâches laborieuses tout au long de la chaîne et dégradation du travail** 
- pour le data scientist, 3 postes perçus → collecte et définition du dataset, définition de l’architecture, et définition des paramètres d’optimisation.
- L’humain dans la boucle dans l’implémentation : celui qui en dernier ressort valide ou invalide la sortie de la machine. Importance pour des questions de responsabilité.
- Tâches d’annotation : tâches plus ou moins compliquées (du captcha à la rédaction), souvent déplacé dans des pays avec main d’œuvre moins chère. Cas des annotations participatives (avec ou sans rétribution - en mode commun ou en mode travail)

**Beta-test et entraînement des algo** Tâches de vérification et de recalibrage / ré-entraînement. Homogénéisation des missions, qui deviennent des missions de bureau (peu de terrain et de mobilisation du corps). Dans la phase de déploiement, les tâches relatives aux systèmes d’IA se superposent à celles déjà effectuées (et qualité plus faible).

**Prisme de la théorie politique classique et exploitation** Main d’œuvre précarisée avec développements d’instruments de contrôle / managériaux (Amazon : “work hard, have fun, make history” ou classes d’ouvriers / de consommateurs / de patrons). Peu de diversité des profils dans les équipes d’IA (hommes blancs très diplômés). Glissements : suppression de catégories d’emplois moins qualifiés au profit de moins d’emplois très qualifiés. Dévalorisation du travail : Dépend du contexte (ex. aviation : environnement déjà très contraint) - techniques d’enrôlement auprès de travailleurs déjà dévalorisés/précarisés (ex. sécurité / CSU)…

**Pas de remplacement du travail, mais déplacement** Tant dans les types de tâches / transfo des missions et des statuts que géographiquement. Disparition des métiers fait partie de l’imaginaire, mais il y a juste un déplacement de la force de travail. Célébration de la machine pour invisibiliser le travail qui s’est déplacé. Quid de la technicité qui ne sera plus maîtrisée / perte de savoir-faires critiques ?

**Gain de temps et/ou manque de personnel** Rhétorique de l’efficacité et de l’objectivité (face à subjectivité humaine) et IA comme instrument pertinent sur certains types de tâches (reconnaissance, contrôle,...). Rhétorique dans certains champs d’activité du manque de main d’œuvre pour développements de systèmes d’IA (médecine, agriculture…)

**Reconsidération de l’expertise** Si l’IA ne “remplace pas” le travail humain, il le met en tension et le transforme (encore plus vrai avec les IA génératives ?). Impose une forme de réflexivité et re-négociation collective des tâches ? L’expertise et les prises de décision se déplacent elles-aussi des agents/opérateurs vers les développeurs et data scientists qui scriptent les algo (et vérouillent souvent les possibles).

**Resituer dans une histoire longue du travail en informatique** Figure du Magicien d’Oz (figure encore très présente en IHM / Computer sciences). Début du XIXe siècle, salles de calculs avec calculateurs humains, avec une forte rationalisation/division du travail (opérations de base versus grands mathématiciens). Puis comparaison de la rapidité d’exécution avec les premiers ordinateurs. Voir l'AI non pas comme un outil d'émancipation ou un outil de réflexion sur l'intelligence mais au contraire un outil disciplinaire dans le cadre très restreint du travail. Progrès n’est pas compris dans le sens du progrès social ou de la qualité des services rendus (publics ou privés) mais du progrès technique.

**Médiations et traductions à retracer (STS)** Comment le travail des humains est sollicité, produit, enregistré, transformé, catégorisé, mis dans un espace de calcul qui a des ambitions très spécifiques… Il ne s’agit pas de dire qu’il n’y a pas d’IA parce qu’il y a du travail humain caché (Casilli).

**Rapports de force avec les hiérarchies très asymétriques** Seuls arguments consentis portent sur les biais. Pas de connaissance des projets, pas d’implication des agents ni de co-conception et outils livrés du jour au lendemain. Organisations syndicales écartées et argument du TINA. Rhétorique du progrès fonctionne à plein avec accompagnement au changement, souvent fait par des cabinets de conseil. Les directions cherchent à expliquer / accompagner les agents, vus comme rétifs au changement mais pas du point de vue de l’amélioration des missions de service public (dans le cas du public) → du point de vue de la modernisation de l’action publique (cf. FTAP).


<br>

<small> 

**Entités mentionnées**
Wiener, von Neumann, grands mathématiciens, data scientists, chercheurs, calculateurs humains, mechanical Turk, Magicien d’OZ, ENIAC, Casilli, la force de travail, mecs de la sécurité, géomètres, hiérarchie, agent.es (catégories A, B, C), Amazon, ouvriers, consommateurs, DGFiP, service public, hommes blancs diplômés, médecins, pneumologues, une IA, humain, citoyens

</small>

<br>

### Les documents (36)
##### 3.4


"""


[PAGE]
url="/#action-publique"
nom_de_page="Instrumenter l'action publique"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Instrumenter l'action publique

> “Ils en profitent pour mettre un article sur l'échange généralisé de données entre administrations..”

— E., journaliste spécialisé (affaires publiques et numérique)

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720019889?h=d92cf3029c" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Sonder les soucis des développements de l'IA dans les administrations publiques est particulièrement intéressant pour deux raisons : 1) l'État remplit le double rôle de régulateur de l'IA et de concepteur/utilisateur et 2) les instruments de l'action publique révèlent autant qu'ils performent les politiques publiques. Sans autorité indépendante forte ou autre contre-pouvoir, ce double rôle s'avère dangeureux car les bénéfices projetés à utiliser des systèmes d'IA pour l'action publique peuvent encourager les pouvoirs politiques à autoriser certains développements, au risque de réduire les libertés fondamentales. D'autre part, les différentes administrations sont hétérogènes et leurs pratiques en termes d'instrumentation variables—certaines parlent de communs lorsque d'autres cultivent une culture du secret. Sont aussi questionnées ici les politiques publiques qui fixent le cap vers toujours plus de dématérialisation dans l'action et les services publics, faisant des données un actif stratégique et externalisant une partie non négligeable de ses missions.
<br>

### Thèmes abordés.

**Développement de l’informatique et automatisation des fonctions administratives** 
Histoire longue de l'évolution conjointe entre informatique et administration publique, nouvel épisode avec l'IA et le big data : aux USA / Europe et en France, développement similaire au sein des administrations. Dynamiques conjointes et mondialisées : Open Data & Open Gov Partnership.

**La mise en valeur de la donnée (production, exploitation, circulation)** Ouverture des données par l’administration, pour elle-même (instrument d’action publique) et mise en valeur / consolidation des bases de données. Nomination d’un administrateur général des données en 2014 et évangélisation avec des démonstrateurs pour convaincre les administrations du potentiel de l’exploitation de leurs données (création d'étalab). La question de la circulation des données entre administrations est un enjeu au centre préoccupations.

**Développement du secteur privé** Beaucoup de contrats entre état et boîtes privées dont certaines font à la fois le diagnostic, la prospective et les prestataires de service. 
Externalisation des projets, financements par projets (cabinets de conseil, labo de recherche) : manque de moyens humains, difficulté à recruter des profils compétents dans les administrations. 

**Déplacement du travail et logique de réduction de coûts** Au sein de la fonction publique suppression de postes de catégories B&C (sous-traitance à l’étranger / main d’œuvre à faible coût) et embauches de catégorie A. Rôle important de la DITP dans le portage de projets pour coordonner des développements et efforts qui vont dans le même sens (déploiement numérique à grande échelle, innovation etc.). Approche par à coups plutôt que de longue durée (travail d’intégration et maintenance non prise en compte). Administrations pas encore matures, équipes très petites et dynamiques fragiles (même DINUM). 

**Pas de concertation ni de co-conception avec les agents** Lancement des projets par les équipes de direction et peu de concertation avec les équipes déjà en place (que ce soit dans les DSI ou dans les équipes métier). Opacité et mise à l’écart des agents (qu’il s’agit de rassurer ou à qui il faut mieux expliquer que c’est dans leur intérêt) et des organisations syndicales.

**Concilier les tensions entre vie privée et sécurité** Réflexion éthique aide à anticiper (notamment rôle du LINC). La CNIL a été pointée par le Conseil d’Etat pour devenir une autorité de régulation, et rendre des avis contraignants, en plus de son rôle de contrôle de conformité. Difficultés car peu de moyens humains et financiers. Les autres enjeux (sociaux, politiques) de ces nouveaux instruments sont éludés (inégalités face au service public, déplacement des missions et du travail, dégradation des services publics, perte de sens…).

**Niveau industriel du numérique dans l’état aujourd’hui - état avancé de dématérialisation** Difficultés de contestation (prétextes positifs, cf. lutte contre le non-recours), process streamlinés et peu de prises. Tuyauterie robuste et rapports de force asymétriques. Logiques de réduction de coûts / réduction d’effectifs, inefficace en pratique et précarisation des plus pauvres. Méconnaissance des situations particulières pour se focaliser sur des actions de contrôle à distance (fraude, vérif…).

**Opacité administrative et pas de doctrine d’évaluation des projets d’IA dans l’état** En plus d’une absence de partage d’information sur les expérimentations, pas d’évaluation coûts / bénéfices. Demandes CADA obstruées. Une fois les projets lancés, ils ne soient pas remis en question.


<br>

<small> 

**Entités mentionnées**
Etalab, Mike Flowers, NYC Mayor Office, Barack Obama, Open Gov. Partnership, DITP, ANTS, EDF, empreintes digitales, Etat, Ficoba, loi 3DS, DGFiP, 300 ETP, travailleurs du clic à Madagascar, sénatrice (Pas de Calais), agent.es, CADA, LINC, CNIL, Ministère de l’économie et des finances, Conseil d’Etat, DDTM, DINUM, Cabinets de conseil, circulaire du premier ministre, Administrateur Général des données, Henri Verdier, Data scientists, administrations publiques, Chief data officer, Hollande.
</small>

<br>

### Les documents (67)
##### 2.5


"""


[PAGE]
url="/#performer"
nom_de_page="Performer le social"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Performer le social

> “Il y a bien un esprit dans le calcul.”

— D., sociologue

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720016449?h=3ff1e7e15a" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
L’analyse historique et sociale des développements informatiques fait apparaître des visions du social qui ont présidé / président à la fabrication des techniques de calcul et qui y sont incorporées. Loin d’être cantonnées au milieu des *computer sciences*, ces visions imprègnent aussi les questions et débats des sciences sociales (cognition, socialisation, apprentissage, construction des représentations) et des sciences politiques (organisation politique, instruments d’état, rapports à la norme, etc.). L’expansion de l’automatisation peut aussi être comprise comme la tentation d’une personnalisation/ adaptation située de la prescription (juridique, de travail etc.) grâce au calcul—rattachable au concept de gouvernementalité et à l’expansion des bureaucraties.

<br>

### Thèmes abordés.

**De la consultation à l’injonction (ou gouvernementalité)** Que ce soit dans l’édiction de normes individuelles en fonction des capacités ou dans la réalisation de tâches de travail, l’IA est vue comme pouvant permettre ou interdire (prescrire) des conduites en situation (à un niveau micro/individuel/personnalisé). 

**Formes désirables du social préfigurées dans les techniques de ML** Le choix des paramètres des calculs, son organisation et les dispositifs qui l’encadrent mettent en avant, en plus des choix de leurs concepteurs, une représentation de la forme désirable du social (ex. Page Rank et l’autorité). Alibi pour acceptation sociale (ex. IA et Santé), mais pas la question du niveau de technicisation et ses implications en termes d’organisation politique et sociale.

**Controverse symbolique / connexionniste et le rapport aux situations et aux représentations** Dans la controverse symbolique / connexionniste, on se demande si la machine raisonne à partir de fonctions logiques (programmées par un concepteur démiurge) ou si elle vit avec un environnement qui lui permet de réajuster ses modèles d’action (apprentissage de l’écart entre projection et monde pour corriger / boucle de rétroaction permanente). Rejoint un débat ontologique en SHS et les questions de socialisation et d’apprentissage.

**Constructions et évaluations de modèles mathématiques, vers du comportementalisme** A partir de l’algorithmique financière et de l’étude des marchés, tentative de plus en plus vers l’analyse des comportements avec l’organisation de compétitions qui réunissent chercheurs (maths, stats…).
Rapport entre recherche d’automatisation et transformation / invisibilisation du travail : histoire qui remonte à Babbage et turc mécanique, qu’on retrouve aujourd’hui avec les pseudo-IA. IA s’inscrit dans une histoire du travail avec la création d’un nouvel espace disciplinaire du travail. Tensions depuis le début de la cybernétique entre une vision utilitariste (idéalisée - VonNeumann) et une vision consciente des dangers d’exploitation (Wiener). Projet politique de la cybernétique.

**Co-évolution de l’informatique et des états modernes** Au service des besoins de la bureaucratie et son expansion. Homologies entre imaginaire politique de la révolution industrielle et fabrication de ces technologies. Co-constitutif des états modernes (cf. USA / exigences constitutionnelles demandent une grande capacité de calcul et de gestion de l’information). Informatique comme mode de gouvernement impersonnel nécessaire aux bureaucraties → bon angle pour une critique politique de ces systèmes.


<br>

<small> 

**Entités mentionnées**
John Agar, Babbage, Turc mécanique, USA (état fédéral), Wiener, Von Neumann, Suchmann, Flores, Winograd, mamie, les statistiques, GPS, ouvriers, techniciens, Kaggle, Page Rank, Google, chercheur en sciences sociales, Boltanski, STS, concepteurs, pionniers de la cybernétique, la machine, Malchiel, Wall Street Journal, singe, traders, mathématiciens, statisticiens, la bourse, magicien d’Oz, sténographes, Mazel, Delphine Gardey, Weber, Harendt, Castoriadis, l’école de Francfort.
</small>

<br>

### Les documents (41)
##### 2.1


"""
[PAGE]
url="/#critiquer"
nom_de_page="Critiquer"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Critiquer

> “Toute connaissance est intriquée avec le dispositif qui produit cette connaissance.”

— H., designer-chercheur

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720016616?h=6e75ff1655" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Quels sont les rôles possibles de la critique face aux dévloppements de l'IA ? Sur quelles bases produire une critique et avec quelle efficace ? Des productions de chercheurs et essayistes sont passées en revue et décrites du point de vue des lectures et des prises qu'elles proposent pour penser l'IA et au regard des effets qu'elles produisent. Et au-delà d'une production critique, comment mobiliser face aux enjeux que la critique révèle ?

<br>

### Thèmes abordés.

**D’une critique correctrice à une critique fondamentale** Un chantier pour les STS et études critiques : montrer en quoi les technologies sont toujours le produit de systèmes de pouvoirs et rappeler les contingences qui font l’ordre dans lequel on est. Ce n’est pas un problème de réflexivité mais de luttes politiques qui ont été invisibilisées et qui donnent l’impression d’une trajectoire lisse et non-contingente. Etudier les modes d’action des luttes passées pour mesurer le décalage dans les possibilités actuelles d’action militante (sabotage matériel, etc.). Mais attention aux effets “double-click” et aux rapprochements qui feraient l’impasse des médiations.

**Collusion entre intérieur et extérieur** Dénonciations et critiques faites par des personnes participant à la fabrication des systèmes. En même temps, difficulté voire impossibilité de connaître les détails des systèmes car opacité très forte.

**Tentatives pour produire des effets différents** Recommandations pour permettre des observatoires de ces technos avec trois adresses différentes : à l'état (observatoire), aux plateformes (contraintes d’ouverture et d’accès) et aux utilisateurs. Proposition de plus d' enseignements de SHS dans les formations d’ingénieurs. 

**Problèmes de traduction entre mondes et inefficacité ou travestissement des critiques** (cf. de la critique politique au développement personnel). Difficultés au vue des asymétries de prises et rapport de force. Pensée féministe propose de transformer la relation autoritaire aux technologies - les penser à partir de ce qu’elles produisent comme effets (soigner ou au contraire, abîmer).

**Former de nouveaux objets** Contester l’existence de l’IA, raconter des contre-récits, montrer des choses invisibles - à partir de l’information disponible. Être conscient du prisme et du dispositif qu’on met en place pour étudier, observer, raconter ces technologies.

**Difficultés pour mobiliser autour de ces enjeux** Discours critique (notamment par les media studies) omniprésent et fatiguant, peu intéressant quand il y a absence des chaînes de traduction - possiblement puissant lorsqu’elles sont décrites. 



<br>

<small> 

**Entités mentionnées**
Carly Kind, STS, Fressoz, Latour, informaticiens, ethicistes, activitstes, media studies, Zuboff, D’Ignazio/Data Feminism, Statactivism, femmes racisées, industries, GAFAM, danah boyd, Timnit Gebru, Catherine Malabou, Turing, Etat, utilisateurs, plateformes, ingénieurs, les autres, Félix Tréguer, Facebook, Zuckerberg, le Times, dispositifs

</small>

<br>

### Les documents (46)
##### 2.2


"""
[PAGE]
url="/#enqueter"
nom_de_page="Ouvrir les boîtes noires"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Ouvrir les boîtes noires

> “Ces petits glitchs qui permettent aussi de voir comment ça fonctionne.”

— M., journaliste et curatrice

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720018065?h=c842ccdf74" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Comment mener des enquêtes sur les technologies en cours de développement ? L'IA étant décrite comme une boîte noire dont les processus de production et le fonctionnement sont opaques, des chercheurs et des artistes mettent au point de nouvelles manières d'enquêter sur les systèmes d'IA. Ces nouvelles méthodes ne poursuivent pas les mêmes objectifs : production de preuves, développement d'une contre-expertise, ouverture de nouvelles trajectoires de développement ou renouvellement des formes de relation aux dispositifs d'IA, les finalités abordées renouvellent le répertoire des modalités d'action avec ou contre les systèmes d'IA.

<br>

### Thèmes abordés.

**Expérimentations techniques pour développer une approche critique** Les expérimentations permettent d’ouvrir les boîtes noires et de révéler des fonctionnements en générant de la connaissance intermédiaire. Donner à voir le en cours d’expérimentation, avec tous les glitchs, précieux car révélateurs de logiques, et itérations.

**Construction de preuves** Stratégies d’objectivation du fonctionnement des algorithmes en vue de dénoncer leurs partis pris.

**Les artistes porteurs de contre-expertises et de contre-récits** Les artistes s’intéressent souvent avant les autres à des sujets difficiles/rébarbatifs car très techniques. Ils•elles ont une sorte de radar pour des sujets aux interstices (non traités par ailleurs), susceptibles de faire émerger des problèmes publics. Sorte de “Forensic du futur” ? (ex. extraction audio via Youtube)

**Refaire manuellement pour éprouver les choses en jeu** révèle l’énorme travail laborieux et invisibilisé et les choix sous-jacents, rendre sensible à ce qui est en jeu. Interventions du corps pour faire ressentir et voir les manières dont il est mobilisé.

**Humour** Mises en scène absurdes ou bouffonnes pour démystifier et raconter autre chose de ces machines que le récit de la singularité.

**Sensibiliser / mobiliser** Faire comprendre ce que les systèmes ont d’adversarial. Dire autrement / nommer autrement et faire de la médiation qui mettent en jeu d’autres récits ou imaginaires pour faire sentir où sont les enjeux.



<br>

<small> 

**Entités mentionnées**
artistes, Anna Riedler, Memo Akthen, RYBN, GANs, réseau de neurone, modèle, Guillaume Chaslot, Youtube, Google, McLuhan, tulipe, classification/classer, annotations, Mechical Turk, grosses companies, extractions, étudiante en art/design, glitchs, robots, Simone Giertz, compétition, PAcT, UNESCO, danseurs, corps, perceptron, Franck Gilbreth, Etienne Jules Marey, micro-travailleur

</small>

<br>

### Les documents (40)
##### 2.3


"""

[PAGE]
url="/#justifier"
nom_de_page="Justifier les projets d'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Justifier les projets d'IA

> “Quels projets on accepte, et surtout quels projets on n'accepte pas de faire ?”

— F., data scientist

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720018602?h=9e98132f4a" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Comment sont décidés les développements de systèmes d'IA ? Comment arbitrer pour savoir si on doit ou non s'engager dans de tels projets ? Ce souci qui habite les praticien.nes lorsqu'ils participent au développement de systèmes d'IA contraste deux types de justifications : l'une morale et l'autre utilitariste. Une troisième voie pointe l'enjeu démocratique que pose ce souci, notamment en décalant la focale sur des dimensions politiques ou esthétiques.

<br>

### Thèmes abordés.

**Intérêt général** Négociation de l’interprétation de la notion d’intérêt général. Aider les citoyens… Est-ce que travailler avec l’armée va dans le sens de l’intérêt général ? Aller contre l’état, proposer des alternatives aux initiatives étatiques ?
Pas facile de répondre pour les agent.es de l’administration qui font du contrôle et qui se voient dôtés d’outils toujours plus efficaces de surveillance. 

**Visions (contre) techno-solutionnistes** On ne va pas résoudre nos problèmes sociétaux avec cette technologie. Rendre sensible à ça par des procédés artistiques par ex. Montrer d’autres esthétiques, cosmologies, modes d’existence pour décaler la manières dont les problèmes sont posés (cf. Hito Steyerl) ? Peut-être qu'il y a certains secteurs qui devraient rester en dehors de ces champs d'application. Mettre ça en débat.

**Qui décide ? De quels besoins part-on ?** Problème de démocratie dans les choix de développement, car instances de décision réservées et pas de gouvernance partagée / arènes de débat sur ces questions. (Exemple d’entreprises libérées qui proposent une gouvernance collective, mais difficultés à arbitrer et finalement décisions sont prises par qqun.es.)

**Questions morales et éthiques** Reconnaissance partagée que l’IA serait dangereuse. Comment départager le bien du mal (bien agir/mal agir) ? Interaction entre décisions éthiques et possibilités de croissance / marchés. Est-ce que ces questions doivent être prises en charge par les personnes individuellement au sein de leur activité ou discutées / arbitrées collectivement ? 

**Critère d’ouverture (open source, partage) et de collaboration / participation** La circulation et le réemploi est-il un critère valable, suffisant ?

**Interroger les justifications et les arbitrages derrière les projets** Proposition d’avoir des agent.es référents pour juger de l’opportunité de développer des systèmes d’IA dans tels ou tels cas. Ne pas développer l’IA pour elle-même ou pour avoir des financements ou grimper dans une organisation (se rendre visible/innovant). Valorisation personnelle ? question de l’intéressement personnel (portfolio, réseaux…). Mais si on ne le fait pas…. Quelqu’un d’autre, un autre pays, une entreprise privée, etc.

**Entre surveillance et utilité** Arbitrages difficiles entre la nécessité de récolter beaucoup de données (privacy/surveillance) et l’intérêt de monitorer certains phénomènes (politiques, sociaux etc.)

**Quelles garanties** pour le respect des droits fondamentaux et des libertés publiques ? 


<br>

<small> 

**Entités mentionnées**
les armées, intérêt général, code, data for good, open source, ministère de l’intérieur, outil, bénévoles, étudiants, startuppeurs, Etalab, ressource, usager, administration, agents publics, data scientists, inspecteur, référents, artisans, hauts fonctionnaires, besoins, problèmes, consultation, équipes, petit patron, jeux de données publics, choix, éthique, droit de refus, combattant, euros, débat/vote, boîtes françaises, le bien/le mal, morale, politique, habitants, travailleurs, force de l’ordre, entropie, philosophies de vie.

</small>

<br>

### Les documents (31)
##### 3.5


"""

[PAGE]
url="/#reguler"
nom_de_page="Réguler l'IA"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Réguler l'IA

> “Qui va s'assurer que les garanties apportées dans la loi sont bien appliquées en pratique ?”

— F., chercheur et militant

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720020132?h=278b2a9429" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Interrogeant la protection des libertés publiques et l'encadrement des risques liés au déploiement de nouvelles technologies, ce souci pointe les limites et failles du droit. Ces remises en cause opposent ceux qui, du côté de l'application des normes, dénoncent les défaillance de l'effectivité des normes juridiques, à ceux qui, dressant le constat d'une crise plus large des institutions, remettent en cause le droit comme mécanisme de légitimation de progrès technologiques délétères au service du capitalisme mondialisé. 

<br>

### Thèmes abordés.

**Evaluer le coût des conséquences de la mise en place des innovations technologiques ?** Faut-il faire une évaluation des risques ou qualifier ces machines en droit ? débat en droit sur la posture d’évaluation des risques comme une approche néo-libérale au lieu de prendre en compte la réalité ontologique des machines.

**La promesse des réformateurs, évolution du cadre juridique (affirmation des libertés publique)** En 1978, loi Info. et libertés, encadrements des risques liés au développement de l’informatique (nécessaire au développement d’une nouvelle économie). Etait peut-être sincère à l’époque mais disparition progressive des positions techno-critiques et inconséquences de nos politiques. Aujourd’hui libertés publiques mentionnées uniquement pour la forme mais pas prises au sérieux.

**Le droit semble une entreprise de légitimation** pour poser les conditions d’acceptabilité sociale des développements technologiques. Mobiliser le droit pour défendre les libertés : tentative échouée de la Quadra. (notamment sur la VSA, processus de légalisation progressif de toute manière). Nécessité de trouver d’autres modes d’action.

**Effectivité de la norme** Problèmes tant dans les interfaces (dark pattern / écologie de l’attention + privacy) que dans le contrôle (mal assuré de la CNIL). Propositions d’associations d’acteurs plus variés pour des études d’impact et consacrer de nouveaux droits aux utilisateurs (droit au paramétrage…) et les rendre effectifs (notamment by design.) Mise en conformité difficile et peu anticipée (encore moins son contrôle ?) notamment du fait de la multiplication des textes. 

**Remise en cause du progrès** Quel niveau de technicisation de nos sociétés ? Qui décide ? (low-tech, auto-détermination, etc.). Ne pas se limiter à considérer les risques mais remise en cause plus fondamentale du modèle de société induit par les développements techniques.

**Enjeux plus politiques que juridiques** Le droit “fonctionne”-t-il ? Défaillance pas dans les textes mais dans leur application. Norme rédigée sous pression du débat souvent superflue (besoin de maturation) et inflation des textes juridiques (quand souvent des textes protègent déjà). Par contre, code is law, importance de la norme technique.



<br>

<small> 

**Entités mentionnées**
François Sureau, Quadrature du Net, élite technocratique, innovation, CNIL, Comité National pilote d’éthique du Numérique, Alain Supiot, institutions européennes, HAL, 2001 l’Odyssée, RGPD, juristes, Carrefour, Lawrence Lessig

</small>

<br>

### Les documents (45)
##### 2.4


"""

[PAGE]
url="/#futurer"
nom_de_page="Futurer"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Futurer

> “Le futur en 2019, c'était un chien intelligent.”

— L., journaliste tech

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720019625?h=638206eda7" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Comment sont construits les récits qui mettent en scène l’intelligence artificielle ? Quels éléments sont mis en avant et quels imaginaires participent-ils à former ? Dans quels buts ? Les rhétoriques de l’innovation mobilisées dans le cas de l'IA sont analysées du point de vue de leur performativité, à la fois comme stratégie d’enrôlement d'acteurs et de capitaux mais aussi comme moteurs des horizons de développement technologique. L'élaboration de récits plus critiques et de contre-récits, tentant de dessiner d'autres trajectoires, est un souci pour les praticien.nes.

<br>

### Thèmes abordés.

**Rhétorique de la promesse produite en continu par les innovateurs** Ancrer son succès dans son histoire personnelle (mythologie personnelle), chercher des inspirations (bio-mimétisme, brevets…) et savoir s’entourer. Proposer un pitch qui résonne avec des problèmes rencontrés pour créer le désir.

**Faire l’actualité (présence en salon, démo, nouvelles features, financements…)** Des évènements tech sont organisés (VivaTech en France par ex.) et les journalistes tech sont utilisés par les PR des entreprises pour diffuser leur rhétorique de la promesse (salons, interviews de top innovateurs…). Les pouvoirs politiques se servent aussi des médias à des fins économiques pour promouvoir la dynamique de ce secteur nationalement. Les industries, en partenariat avec les états, cherchent à créer l’actualité en mettant en avant des chercheurs star et en ouvrant à grand bruit des centres de recherche et développement. 

**Souveraineté** Contradiction entre un discours politique sur la souveraineté et un soutien important financier aux GAFAM en France.

**Médiatisation des affaires** Transformation du type d'information autour de 2015 : Enjeux sociaux deviennent plus présents (depuis l’affaire Snowden…) dans les médias avec une série de lanceur.ses d’alerte.

**Oppositions traitées comme un manque de connaissances avec nécessité de pédagogie** dans le monde du travail (face aux agent.es et aux praticiens qui émettent des critiques) et dans la réception grand public. Les controverses sont tuées dans l’œuf sous prétexte de méconnaissance et de non-expertise, les solutions étant présentées comme faisant gagner du temps et de l’argent (plus simple, plus efficace et human-in-the-loop). Les questions politiques sont éludées.

**Difficultés à se débarrasser des “grands récits”** (humain versus machine, prométhée…) pour construire une critique opérante : intérêt à resituer les développements actuels dans une histoire longue pour voir les récurrences dans les discours d’opposition. Le récit devient problématique, stratégie des promoteurs de l’IA - on est noyé par le nombre de récits produits.


<br>

<small> 

**Entités mentionnées**
journalistes, start-uppers, juristes, Apple, GAFAM, Ridley Scott, VivaTech, Apple Keynote, IGN, DGFiP, Orwell, Uber, FAIR, Boston Dynamics, Macron, Le Figaro, la Nature, les oiseaux, pom-pom girl, buzzwords, licornes françaises, newsletter, agent.es (fonctionnaires), les machines, Hollywood

</small>

<br>

### Les documents (46)
##### 4.3


"""

[PAGE]
url="/#valoriser"
nom_de_page="Valoriser"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# Valoriser

> “Les données, c’est le nerf de la guerre.”

— N., chercheuse en imagerie médicale

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720019462?h=617c834c88" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Comment les chaînes de valeur des données qui se développent affectent les rapports sociaux ? Les reconfigurations engendrées par ces nouvelles chaînes de valeur (depuis la création des données jusqu’à leur exploitation) sont mises en débat, avec une attention particulière aux conditions de leur circulation et aux frictions auxquelles elles peuvent donner lieu. Ce souci est marqué par des questions juridiques (régulations sur les données - européenne, française), économiques (GAFAM versus petites entreprises; public versus privé; communs numériques) et politiques (redistribution de la valeur; mandats et rôle de l’état…).

<br>

### Thèmes abordés.

**L’open data bénéficie à ceux en capacité d’exploiter les données** malgré une rhétorique de transparence/ouverture, ce qui est recherché par les politiques publiques de la donnée est la création de valeur (en faire un “actif stratégique”) et le développement d’entreprises (start-ups, PME, GAFAM). L’extraction de données et la création de valeur arrive souvent à l’insu des producteurs de données (ex. vidéos amateurs sur YouTube).

**Frictions pour l’accès aux données** 
- Le cas de la recherche médicale : les cliniciens gardent les données pour faire eux-mêmes de la recherche OU les données sont protégées par le RGPD/privacy
-Le cas de l’open data des décisions de justice : administration en retard sur le calendrier d’ouverture (loi Lemaire 2016). Circulaire Doctrine : résistance de l’administration / demandes d’accès aux décisions autorisées si une par une (pas l’ensemble) → protection de la vie privée + bonne administration de la justice.

**L’ouverture des données de l’administration** L'initiative Etalab a impulsé à partir de 2014 une culture de la donnée et de sa chaîne de valeur dans les administrations (data.gouv, API, évangélisation avec démonstrateurs et cas…) et pointé la nécessité de mettre les données à disposition pour servir à la fois les administrations et les usagers de la donnée. Mésusages beaucoup discutés (par ex. dans le domaine de la justice), proposition d’utiliser le design fiction pour spéculer.

**Externalisation des services publics et utilisation des données publiques** critique de la délégation des services publics à des entreprises privées qui revendent des données publiques. Manque de moyens dans les services informatiques des administrations et dénonciation de la participation des agents du SP au développement de systèmes algorithmiques privés (dans des montages avec des conditions de travail non conformes au droit français - cf. Madagascar).
Pour les entreprises, si les administrations sont contraintes à fournir de l’Open Data propre et exploitable, elles peuvent se concentrer sur leur valeur ajoutée.

**Réglementation relatives aux données par les textes européens** Tentative de mise en concurrence des détenteurs de données (grosses industries numériques et administrations) (ex. altruisme des données dans le DGA ou Digital Market Act) sans remettre en question le droit de la concurrence. Multiplication des textes législatifs et réglementaires européens qui tournent tous autour de la question des données (gouvernance, exploitation, circulation, protection…). Harmonisation et clarté compliquée et à regarder en parallèle de la réglementation IA.

**Vers de nouveaux modèles d’affaires et associations d’acteurs** le modèle du partenariat public-privé (PPP) et de la “data philanthropy” semble muter et s’orienter vers la constitution de communs numériques (avec des données détenues par les acteurs publics et la mutualisation d’infrastructures). Cela pose des questions de responsabilité et de pérennité. Ils sont encore peu développés dans la communauté IA (trop académique / business ?).


<br>

<small> 

**Entités mentionnées**
Youtube; cliniciens; chercheurs en IA; startups; administrations; DGFiP; fonctionnaires; Etalab; Doctrine; éditeurs juridiques; Open Law; Commission Européenne

</small>

<br>

### Les documents (48)
##### 4.2


"""

[PAGE]
url="/#individuer"
nom_de_page="S'individuer"
invisible_dans_menu="true"
contenu="""

<br>
<br>

# S'individuer

> “Une nouvelle forme de gouvernementalité qui fonctionne à l'autonomie.”

— D., sociologue

<br>

<small>

[<svg xmlns="http://www.w3.org/2000/svg" width="16" height="16" fill="currentColor" class="bi bi-arrow-left-circle" viewBox="0 0 16 16"><path fill-rule="evenodd" d="M1 8a7 7 0 1 0 14 0A7 7 0 0 0 1 8zm15 0A8 8 0 1 1 0 8a8 8 0 0 1 16 0zm-4.5-.5a.5.5 0 0 1 0 1H5.707l2.147 2.146a.5.5 0 0 1-.708.708l-3-3a.5.5 0 0 1 0-.708l3-3a.5.5 0 1 1 .708.708L5.707 7.5H11.5z"/></svg> Retour à la liste des soucis](/ShapingAI/#les-soucis)

</small>

---

<iframe title="vimeo-player" src="https://player.vimeo.com/video/720016134?h=d8110d3e5d" frameborder="0" allowfullscreen="allowfullscreen" width="90%" style="aspect-ratio: 16/9"></iframe>

**Résumé**
Description d’une danse, d’un mouvement de va-et-vient, entre la production de dispositifs algorithmiques et la production des subjectivités à travers l’appropriation des ces dispositifs. Les notions d’autonomie (tant comme concept juridique que philosophique) et de normativité sont centrales et mettent l'accent sur la constitution des milieux d'individuation par la technique.


<br>

### Thèmes abordés.

**La normalisation des comportements** induite par les recommandations des machines : Suivre les recommandations de la machine peut conduire à une normalisation des comportements, ce qui soulève des préoccupations quant à la perte d'autonomie de l'individu. Le traitement massif des données peut entraîner des changements comportementaux au sein d'une population, soulevant des préoccupations sur les conséquences de l'utilisation de technologies telles que les capteurs d'anormalité sonore dans l'espace public.

**La redéfinition du sujet de droit et de la notion d'autonomie** Les interactions numériques remettent en question la conception traditionnelle du sujet de droit en tant qu'être rationnel, mettant en évidence les usages et les interactions numériques qui peuvent limiter l'autonomie et la rationalité des individus.

**Les impacts des algorithmes sur la perception de soi/de la réalité et les normes sociales** Les algorithmes automatisent et amplifient les critères de beauté injustes (ou autres discriminations), ce qui peut affecter la perception de soi et renforcer les normes sociales. Des mouvements tels que les influenceuses body positive cherchent à contester ces normes.

**L'IA et l’intime** Avec le déploiement de l'IA, il est nécessaire de réfléchir à l'établissement de nouveaux droits fondamentaux, tels que le droit à la protection de l'intégrité psychique, compte tenu de la capacité des systèmes à permettre une forte introspection et immersion dans l'intimité.

**L’appropriation individuelle grâce à l’entraînement des algorithmes ou à “la jouabilité”** plutôt que d’attendre un travail politique et juridique, certain.es internautes se débrouillent et entraînent les algos des plateformes.

**La production de nouveaux sujets** La théorie “des effets forts des technologies” est une théorie des dominants ? Dans la pratique, les gens ne sont pas dupes et s’approprient les technologies. Cela dit, les systèmes algorithmiques produisent bien des sujets (impatients, désireux de relations sociales, habitués à des services à la demande…), qui nécessitent de la personnalisation et précision de calculs. Elles marchent à l’autonomie pour nous gouverner. A défaut de les défaire totalement, il faut déterminer les applications qui peuvent être nocives.



<br>

<small> 

**Entités mentionnées**
juristes; internautes; utilisateurs de plateforme; influenceurs; jeunes filles; grosse femme noire; chirurgien; journaliste; designers (UX / artistes); milieu tech; industries

</small>

<br>

### Les documents (28)
##### 4.1


"""


